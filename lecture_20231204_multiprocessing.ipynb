{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Создание многопоточных приложений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данной лекции мы посмотрим как работать с многопоточностью.\n",
    "\n",
    "Иллюстрации к теоретическому введению [здесь](https://drive.google.com/file/d/1TiN8I_UysXw3z9Ylja-e4DgFRtuicYU5/view?usp=sharing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подключаем нужные библиотеки\n",
    "import multiprocessing \n",
    "import threading\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pymorphy2\n",
    "\n",
    "import queue\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте просто попробуем запустить два потока, которые будут выводить каждый свое значение.\n",
    "\n",
    "Для создания потока используется `threading.Thread`, в параметр `target` передается функция, которая будет выполняться в этом потоке. Для того, чтобы поток начал выполняться, необходимо вызвать функцию `start`. Если необходимо дождаться окончания выполнения потока, вызывается функция `join`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Func 1 says  1\n",
      "Func 1 says  1\n",
      "I can fly!\n",
      "Func 1 says  101\n",
      "Func 1 says  101\n",
      "Func 1 says  201\n",
      "Func 1 says  201\n",
      "Func 1 says  301\n",
      "Func 1 says  301\n",
      "Func 1 says  401\n",
      "Func 1 says  401\n",
      "Func 1 says  501\n",
      "Func 1 says  501\n",
      "Func 1 says  601\n",
      "Func 1 says  601\n",
      "Func 1 says  701\n",
      "Func 1 says  701\n",
      "Func 1 says  801\n",
      "Func 1 says  801\n",
      "Func 1 says  901\n",
      "Func 1 says  901\n",
      "Process 1 is finished\n",
      "The work is done\n",
      "Time estimated  5.186389923095703\n"
     ]
    }
   ],
   "source": [
    "def func1():\n",
    "    var1 = 0\n",
    "    for i in range(1000):\n",
    "        var1 += 1\n",
    "        if (i % 100) == 0:\n",
    "            print(\"Func 1 says \", var1)\n",
    "        time.sleep(random.random()/100) # засыпаем на случайный промежуток времени.\n",
    "            \n",
    "def func2():\n",
    "    var2 = 0\n",
    "    for i in range(1000):\n",
    "        var2 += 2\n",
    "        if (i % 100) == 0:\n",
    "            print(\"Func 2 says \", var2)\n",
    "        time.sleep(random.random()/100+0.003) # засыпаем на случайный промежуток времени.\n",
    "            \n",
    "t1 = time.time()\n",
    "\n",
    "# создаем, а потом запускаем потоки.\n",
    "pr1=threading.Thread(target=func1)\n",
    "pr2=threading.Thread(target=func2)\n",
    "pr1.start()\n",
    "pr2.start()\n",
    "print(\"I can fly!\")\n",
    "\n",
    "pr1.join()\n",
    "print(\"Process 1 is finished\")\n",
    "pr2.join()\n",
    "print(\"The work is done\")\n",
    "\n",
    "t2 = time.time()\n",
    "print(\"Time estimated \", t2-t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для создания процесса используется `multiprocessing.Process`, принимающий в параметр `target` функцию, которая будет выполняться в этом потоке. Для того, чтобы процесс начал выполняться, необходимо вызвать функцию `start`. Если необходимо дождаться окончания выполнения потока, вызывается функция `join`. Если процесс не будет переходить в режим ожидания, он выполнится от начала и до конца при вызове функции `start`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Func 2 says  2\n",
      "Func 1 says  1\n",
      "I can fly!\n",
      "Func 1 says  101\n",
      "Func 2 says  202\n",
      "Func 1 says  201\n",
      "Func 1 says  301\n",
      "Func 2 says  402\n",
      "Func 1 says  401\n",
      "Func 2 says  602\n",
      "Func 1 says  501\n",
      "Func 1 says  601\n",
      "Func 2 says  802\n",
      "Func 1 says  701\n",
      "Func 1 says  801\n",
      "Func 2 says  1002\n",
      "Func 1 says  901\n",
      "Func 2 says  1202\n",
      "Process 1 is finished\n",
      "Func 2 says  1402\n",
      "Func 2 says  1602\n",
      "Func 2 says  1802\n",
      "The work is done\n",
      "Time estimated  8.116339206695557\n",
      "CPU times: user 20.8 ms, sys: 43.5 ms, total: 64.3 ms\n",
      "Wall time: 8.12 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "t1 = time.time()\n",
    "\n",
    "# создаем, а потом запускаем потоки.\n",
    "pr1=multiprocessing.Process(target=func1)\n",
    "pr2=multiprocessing.Process(target=func2)\n",
    "pr1.start()\n",
    "pr2.start()\n",
    "print(\"I can fly!\")\n",
    "\n",
    "pr1.join()\n",
    "print(\"Process 1 is finished\")\n",
    "pr2.join()\n",
    "print(\"The work is done\")\n",
    "\n",
    "t2 = time.time()\n",
    "print(\"Time estimated \", t2-t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь попробуем сделать тоже самое, но для одной и той же переменной - две функции будут увеличивать значение одной переменной по очереди."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Func 2 says  2\n",
      "Func 1 says  1\n",
      "Func 1 says  101\n",
      "Func 2 says  202\n",
      "Func 1 says  201\n",
      "Func 2 says  402\n",
      "Func 1 says  301\n",
      "Func 2 says  602\n",
      "Func 1 says  401\n",
      "Func 2 says  802\n",
      "Func 1 says  501\n",
      "Func 2 says  1002\n",
      "Func 1 says  601\n",
      "Func 2 says  1202\n",
      "Func 1 says  701\n",
      "Func 2 says  1402\n",
      "Func 1 says  801\n",
      "Func 2 says  1602\n",
      "Func 1 says  901\n",
      "Func 2 says  1802\n",
      "Time estimated 5.170403003692627\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "Loki = 0\n",
    "\n",
    "def func1():\n",
    "    global Loki\n",
    "    for i in range(1000):\n",
    "        Loki += 1\n",
    "        if (i % 100) == 0:\n",
    "            print(\"Func 1 says \", Loki)\n",
    "        time.sleep(random.random()/100) # засыпаем на случайный промежуток времени.\n",
    "            \n",
    "def func2():\n",
    "    global Loki\n",
    "    for i in range(1000):\n",
    "        Loki += 2\n",
    "        if (i % 100) == 0:\n",
    "            print(\"Func 2 says \", Loki)\n",
    "        time.sleep(random.random()/100) # засыпаем на случайный промежуток времени.\n",
    "            \n",
    "# создаем, а потом запускаем потоки.\n",
    "pr1=multiprocessing.Process(target=func1)\n",
    "pr2=multiprocessing.Process(target=func2)\n",
    "pr1.start()\n",
    "pr2.start()\n",
    "\n",
    "pr1.join()\n",
    "pr2.join()\n",
    "t2 = time.time()\n",
    "print(\"Time estimated\", t2-t1)\n",
    "print(Loki)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выглядит так, как будто каждый процесс работает со своей собственной переменной. Да, это так, это ведь независимые процессы, они выполняются каждый на своей копии GIL и комплекте переменных.\n",
    "\n",
    "Теперь попытаемся сделать всё тоже самое, но на потоках, выполняющихся в рамках одного процесса, но в разных потоках."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Func 1 says  1\n",
      "Func 2 says  3\n",
      "Func 2 says  5\n",
      "Func 1 says  495\n",
      "Func 2 says  497\n",
      "Func 2 says  512\n",
      "Func 2 says  996\n",
      "Func 2 says  1000\n",
      "Func 1 says  1017\n",
      "Func 2 says  1479\n",
      "Func 1 says  1507\n",
      "Func 2 says  1527\n",
      "Func 2 says  1980\n",
      "Func 2 says  2008\n",
      "Func 1 says  2019\n",
      "Func 2 says  2449\n",
      "Func 2 says  2516\n",
      "Func 1 says  2575\n",
      "Func 2 says  2929\n",
      "Func 1 says  3029\n",
      "Func 2 says  3049\n",
      "Func 2 says  3456\n",
      "Func 1 says  3507\n",
      "Func 2 says  3556\n",
      "Func 2 says  3931\n",
      "Func 1 says  4039\n",
      "Func 2 says  4053\n",
      "Func 2 says  4461\n",
      "Func 2 says  4514\n",
      "Func 1 says  4553\n",
      "Time estimated  5.13910174369812\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "Loki = 0\n",
    "\n",
    "def func1():\n",
    "    global Loki\n",
    "    for i in range(1000):\n",
    "        Loki += 1\n",
    "        if (i % 100) == 0:\n",
    "            print(\"Func 1 says \", Loki)\n",
    "        time.sleep(random.random()/100) # засыпаем на случайный промежуток времени.\n",
    "            \n",
    "def func2():\n",
    "    global Loki\n",
    "    for i in range(1000):\n",
    "        Loki += 2\n",
    "        if (i % 100) == 0:\n",
    "            print(\"Func 2 says \", Loki)\n",
    "        time.sleep(random.random()/100) # засыпаем на случайный промежуток времени.\n",
    "            \n",
    "# создаем, а потом запускаем потоки.\n",
    "pr1=threading.Thread(target=func1)\n",
    "pr2=threading.Thread(target=func2)\n",
    "pr3=threading.Thread(target=func2)\n",
    "pr1.start()\n",
    "pr2.start()\n",
    "pr3.start()\n",
    "\n",
    "pr1.join()\n",
    "pr2.join()\n",
    "pr3.join()\n",
    "\n",
    "t2 = time.time()\n",
    "print(\"Time estimated \", t2-t1)\n",
    "print(Loki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Func 1 says  1\n",
      "Func 2 says  2\n",
      "Func 2 says  2\n",
      "Func 2 says  202\n",
      "Func 2 says  202\n",
      "Func 1 says  101\n",
      "Func 2 says  402\n",
      "Func 1 says  201\n",
      "Func 2 says  402\n",
      "Func 2 says  602\n",
      "Func 2 says  602\n",
      "Func 1 says  301\n",
      "Func 2 says  802\n",
      "Func 2 says  802\n",
      "Func 1 says  401\n",
      "Func 2 says  1002\n",
      "Func 2 says  1002\n",
      "Func 1 says  501\n",
      "Func 2 says  1202\n",
      "Func 2 says  1202\n",
      "Func 1 says  601\n",
      "Func 2 says  1402\n",
      "Func 2 says  1402\n",
      "Func 1 says  701\n",
      "Func 2 says  1602\n",
      "Func 1 says  801\n",
      "Func 2 says  1602\n",
      "Func 2 says  1802\n",
      "Func 2 says  1802\n",
      "Func 1 says  901\n",
      "Time estimated  5.212342977523804\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "Loki = 0\n",
    "\n",
    "def func1():\n",
    "    var1 = 0\n",
    "    for i in range(1000):\n",
    "        var1 += 1\n",
    "        if (i % 100) == 0:\n",
    "            print(\"Func 1 says \", var1)\n",
    "        time.sleep(random.random()/100) # засыпаем на случайный промежуток времени.\n",
    "            \n",
    "def func2():\n",
    "    var2 = 0\n",
    "    for i in range(1000):\n",
    "        var2 += 2\n",
    "        if (i % 100) == 0:\n",
    "            print(\"Func 2 says \", var2)\n",
    "        time.sleep(random.random()/100) # засыпаем на случайный промежуток времени.\n",
    "            \n",
    "# создаем, а потом запускаем потоки.\n",
    "pr1=threading.Thread(target=func1)\n",
    "pr2=threading.Thread(target=func2)\n",
    "pr3=threading.Thread(target=func2)\n",
    "pr1.start()\n",
    "pr2.start()\n",
    "pr3.start()\n",
    "\n",
    "pr1.join()\n",
    "pr2.join()\n",
    "pr3.join()\n",
    "\n",
    "t2 = time.time()\n",
    "print(\"Time estimated \", t2-t1)\n",
    "print(Loki)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Когда-то давно, такой код обязательно вызвал бы исключительную ситуацию. Но сейчас GIL сам блокирует нужные переменные, не позволяя разным процессам обращаться к ним одновременно. В итоге всё работает именно так, как хотелось бы.\n",
    "\n",
    "Помимо этого, обратите внимание, что время выполнения в обоих случаях примерно одинаково. Это связано с тем, что большую часть времени поток дремлет. Подобное поведение характерно для потоков, которые ожидают внешних результатов. Однако если создать высоконагруженный поток, станет очевидно, что потоки являются \"легкими потоками\", то есть не выполняются параллельно, а синхронизируют свою работу средствами Питона. При этом процессы выполняются в самом деле параллельно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started\n",
      "finished\n",
      "CPU times: user 1.77 s, sys: 0 ns, total: 1.77 s\n",
      "Wall time: 1.77 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "m_size = 200\n",
    "\n",
    "def mult_matrix():\n",
    "    print(\"started\")\n",
    "    m1 = np.random.randn(m_size, m_size)\n",
    "    m2 = np.random.randn(m_size, m_size)\n",
    "    m3 = np.zeros((m_size, m_size))\n",
    "    for i in range(m_size):\n",
    "        for j in range(m_size):\n",
    "            s = 0\n",
    "            for k in range(m_size):\n",
    "                s += m1[i, k] * m2[k, j]\n",
    "            m3[i, j] = s\n",
    "        \n",
    "    print(\"finished\")\n",
    "    \n",
    "mult_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started\n",
      "started\n",
      "started\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "Time estimated  5.6652586460113525\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "            \n",
    "# создаем, а потом запускаем потоки.\n",
    "pr1=threading.Thread(target=mult_matrix)\n",
    "pr2=threading.Thread(target=mult_matrix)\n",
    "pr3=threading.Thread(target=mult_matrix)\n",
    "pr1.start()\n",
    "pr2.start()\n",
    "pr3.start()\n",
    "\n",
    "pr1.join()\n",
    "pr2.join()\n",
    "pr3.join()\n",
    "\n",
    "t2 = time.time()\n",
    "print(\"Time estimated \", t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started\n",
      "started\n",
      "started\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "Time estimated 1.9312376976013184\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "\n",
    "# создаем, а потом запускаем потоки.\n",
    "pr1=multiprocessing.Process(target=mult_matrix)\n",
    "pr2=multiprocessing.Process(target=mult_matrix)\n",
    "pr3=multiprocessing.Process(target=mult_matrix)\n",
    "pr1.start()\n",
    "pr2.start()\n",
    "pr3.start()\n",
    "\n",
    "pr1.join()\n",
    "pr2.join()\n",
    "pr3.join()\n",
    "t2 = time.time()\n",
    "print(\"Time estimated\", t2-t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При помощи объекта типа `Lock` можно блокировать выполнение критических фрагментов кода. Например, если мы пишем в файл в нескольких потоках, мы должны гарантировать, что мы запишем свой фрагмент данных от начала и до конца. При этом другой поток не прервет наш вывод и не выведет свою информацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Func 1 says  1\n",
      "Func 2 says  3\n",
      "Func 2 says  298\n",
      "Func 1 says  311\n",
      "Func 2 says  589\n",
      "Func 1 says  621\n",
      "Func 2 says  886\n",
      "Func 1 says  937\n",
      "Func 2 says  1170\n",
      "Func 1 says  1257\n",
      "Func 2 says  1474\n",
      "Func 1 says  1559\n",
      "Func 2 says  1773\n",
      "Func 1 says  1861\n",
      "Func 2 says  2074\n",
      "Func 1 says  2151\n",
      "Func 2 says  2371\n",
      "Func 1 says  2461\n",
      "Func 2 says  2659\n",
      "Func 1 says  2807\n"
     ]
    }
   ],
   "source": [
    "lk = threading.Lock()\n",
    "\n",
    "Loki = 0\n",
    "\n",
    "def func1():\n",
    "    global Loki\n",
    "    for i in range(1000):\n",
    "        lk.acquire()\n",
    "        Loki += 1\n",
    "        lk.release()\n",
    "        if (i % 100) == 0:\n",
    "            print(\"Func 1 says \", Loki)\n",
    "        time.sleep(random.random()/100) # засыпаем на случайный промежуток времени.\n",
    "            \n",
    "def func2():\n",
    "    global Loki\n",
    "    for i in range(1000):\n",
    "        lk.acquire()\n",
    "        Loki += 2\n",
    "        lk.release()\n",
    "        if (i % 100) == 0:\n",
    "            print(\"Func 2 says \", Loki)\n",
    "        time.sleep(random.random()/100) # засыпаем на случайный промежуток времени.\n",
    "            \n",
    "# создаем, а потом запускаем потоки.\n",
    "pr1=threading.Thread(target=func1)\n",
    "pr2=threading.Thread(target=func2)\n",
    "pr1.start()\n",
    "pr2.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Внимание!!!</b> Вызов двух блокировок подряд вызовет полную блокировку процесса, а также всех процессов, зависящих от данной блокировки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также для синхронизации работы потоков могут использоваться события и семафоры.\n",
    "\n",
    "Событие может быть установлено или сброшено. Если поток пытается установить установленное или сбросить сброшенное событие, он блокируется (но может быть разблокирован по тайм-ауту).\n",
    "\n",
    "Семафор фактически хранит информацию о нескольких событиях, то есть у семафора есть некоторый объем. Процесс блокируется при запросе ресурса из семафрра, только если тот уже был запрошен n раз и ресурс исчерпан.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote 1\n",
      "read 1\n",
      "wrote 2\n",
      "read 2\n",
      "wrote 3\n",
      "read 3\n",
      "wrote 4\n",
      "read 4\n",
      "wrote 5\n",
      "read 5\n",
      "wrote 6\n",
      "read 6\n",
      "wrote 7\n",
      "read 7\n",
      "wrote 8\n",
      "read 8\n",
      "wrote 9\n",
      "read 9\n",
      "wrote 10\n",
      "read 10\n"
     ]
    }
   ],
   "source": [
    "# создадим очередь\n",
    "cntr = 0\n",
    "eve1 = threading.Event() # Разрешает читать читателю.\n",
    "eve2 = threading.Event() # Читатель прочитал, писатель может писать.\n",
    "\n",
    "# У нас будет два потока. \n",
    "# Writer будет писать даные в очередь через случайные промежутки времени. \n",
    "def writer():\n",
    "    global cntr\n",
    "    while cntr<10: #пишем 10 чисел\n",
    "        res = eve2.wait() # Всё прочитано, можно начинать писать.\n",
    "        eve2.clear() # Я понял, начинаю писать.\n",
    "        # Делаем какие-то долгие операции по генерации данных.\n",
    "        cntr+=1\n",
    "        print('wrote '+str(cntr)) # отчитываемся о записи.\n",
    "        eve1.set() # Данные готовы, можно читать.\n",
    "        time.sleep(random.random()) # засыпаем на случайный промежуток времени.\n",
    "\n",
    "# Reader в параллельном потоке читает из очереди через случайные промежутки времени.\n",
    "def reader():\n",
    "    while cntr<10: # пока прочитанное число меньше 10...\n",
    "        res = eve1.wait() # А не готовы ли данные для чтения?\n",
    "        if res:\n",
    "            print('read '+str(cntr)) # Отчитываемся.\n",
    "        else:\n",
    "            print('read failed')\n",
    "        eve1.clear() # Спасибо, я всё прочёл.\n",
    "        eve2.set() # Можно начинать писать.\n",
    "\n",
    "eve2.set() # Вначале писать может писать, а читателю нечего читать.\n",
    "eve1.clear()\n",
    "# создаем, а потом запускаем потоки.\n",
    "pr1=threading.Thread(target=writer)\n",
    "pr2=threading.Thread(target=reader)\n",
    "pr1.start()\n",
    "pr2.start()\n",
    "\n",
    "# Видно, как потоки работают параллельно, правда?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем организовать обмен данными при помощи `multiprocessing.queue`.\n",
    "Данный класс позволяет обмениваться информацией между потоками. При этом если поток-поставщик данных работает быстрее, то данные будут \"складироваться\" в очереди, пока потребитель их не заберет.\n",
    "Размер очереди может быть ограничен. В этом случае операция \"положить в очередь\" заблокирует поток, если очередь заполнена.\n",
    "Если очередь пуста, поток, запросивший данные также будет заблокирован при запросе данных. \n",
    "Для избежания блокировок можно использовать timeout (через какое время поток будет разблокирован и фцнкция сообщит о неуспехе).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote 0\n",
      "read 0\n",
      "wrote 1\n",
      "read 1\n",
      "wrote 2\n",
      "wrote 3\n",
      "read 2\n",
      "read 3\n",
      "wrote 4\n",
      "read 4\n",
      "wrote 5\n",
      "wrote 6\n",
      "read 5\n",
      "wrote 7\n",
      "read 6\n",
      "read 7\n",
      "wrote 8read 8\n",
      "\n",
      "wrote 9read 9\n",
      "\n",
      "read 11\n"
     ]
    }
   ],
   "source": [
    "# создадим очередь\n",
    "cntr=0\n",
    "exch=multiprocessing.Queue(5)\n",
    "random.seed()\n",
    "\n",
    "# У нас будет два потока. \n",
    "# Writer будет писать даные в очередь через случайные промежутки времени. \n",
    "def writer():\n",
    "    global cntr\n",
    "    while cntr<10: #пишем 10 чисел\n",
    "        exch.put(cntr) # собственно пишем в очередь\n",
    "        print('wrote '+str(cntr)) # отчитываемся о записи.\n",
    "        cntr+=1\n",
    "        time.sleep(random.random()) # засыпаем на случайный промежуток времени.\n",
    "    exch.put(11) # конец данных.\n",
    "\n",
    "# Reader в параллельном потоке читает из очереди через случайные промежутки времени.\n",
    "def reader():\n",
    "    i=-1\n",
    "    while i<10: # пока прочитанное число меньше 10...\n",
    "        i=exch.get() # Собственно читаем из очереди.\n",
    "        print('read '+str(i)) # Отчитываемся.\n",
    "        time.sleep(random.random()) # спим\n",
    "\n",
    "# создаем, а потом запускаем потоки.\n",
    "pr1=multiprocessing.Process(target=writer)\n",
    "pr2=multiprocessing.Process(target=reader)\n",
    "#pr1=threading.Thread(target=writer)\n",
    "#pr2=threading.Thread(target=reader)\n",
    "pr1.start()\n",
    "pr2.start()\n",
    "\n",
    "# Видно, как потоки работают параллельно, правда?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь попробуем решить следующую задачу.\n",
    "\n",
    "Необходимо получать новости из нескольких источников. Далее каждая новость токенизируется в отдельном потоке, лемматизируется в еще одном потоке. В конце идет поток, который обрабатывает полученные данные.\n",
    "Новости также получаются в отдельных потоках.\n",
    "\n",
    "Для передачи данных используем очередь. \n",
    "\n",
    "Для сигнализации завершения работы потоков используем события и семафоры.\n",
    "\n",
    "Использование очереди, событий и семафоров позволяет синхронизировать операции в потоках. Токенизатор начнет разбор только после того, как очередь получит данные от одного из загрузчиков новостей. Результат будет помещен в другую очередь. Токенизатор \"уснет\" до тех пор, пока не придет еще одна новость, зато \"проснется\" лемматизатор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!!===--- ВНИМАНИЕ!!! ---===!!!\n",
    "# Код в данной ячейке работает некорректно, так как завершение процессов вызывает взаимную  блокировку!\n",
    "# Корректный вариант синхронизации показан ниже.\n",
    "\n",
    "\n",
    "# Функция для загрузки одной новости из Ленты.ру\n",
    "def getLentaArticle(url):\n",
    "    \"\"\" getLentaArticle gets the body of the article from Lenta.ru\"\"\"\n",
    "    page = requests.get(url)\n",
    "    tree = html.fromstring(page.text)\n",
    "    text = '\\n'.join([p.text_content() for p in tree.xpath(\".//p[contains(@class,'topic-body__content-text')]\")])\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Функция загрузки одной новости из N+1.\n",
    "def getArticleTextNPlus1(adr):\n",
    "    r = requests.get(adr)\n",
    "    n_text = re.split(\"</div>\", re.split(\"</figure>\", re.split('</article>',re.split('<article', r.text)[1])[0])[1])[1]    \n",
    "    return BeautifulSoup(n_text, \"lxml\").get_text()\n",
    "\n",
    "# Загрузка новостей из Ленты.ру за некоторый период.\n",
    "def getLenta(qu, sem):\n",
    "    curdate = datetime.date(2017, 1, 16)\n",
    "    findate = datetime.date(2017, 1, 16)\n",
    "    res = \"\"\n",
    "\n",
    "# Загружаем новости до конечной даты.\n",
    "    while curdate <= findate:\n",
    "        print('lenta ' + curdate.strftime('%Y/%m/%d'))\n",
    "        day = requests.get('https://lenta.ru/news/' + curdate.strftime('%Y/%m/%d'))\n",
    "        body = re.findall('<h3>(.+?)</h3>', day.text)\n",
    "        links = ['https://lenta.ru' + re.findall('\"(.+?)\"', x)[0] for x in body]\n",
    "        for l in links: # идем по всем ссылкам на новости за день.\n",
    "            qu.put(getLentaArticle(l)) # Полученную новость кладем в очередь.\n",
    "            time.sleep(0.2)\n",
    "        curdate += datetime.timedelta(days=1)\n",
    "    sem.acquire() # Блокируем семафор один раз, по\n",
    "    print(\"lenta finished\")\n",
    "\n",
    "# Получаем новости с NPlus1 за заданный промежуток времени, кладем тексты новостей в очередь qu.\n",
    "# По завершении взводим семафор sem.\n",
    "def getNplus1(qu, sem):\n",
    "    curdate = datetime.date(2015, 12, 15)\n",
    "    findate = datetime.date(2015, 12, 19)\n",
    "\n",
    "    while curdate <= findate: # Перебираем все дни.\n",
    "        r = requests.get('https://nplus1.ru/news/'+curdate.strftime('%Y/%m/%d'))\n",
    "        print('nplus ' + curdate.strftime('%Y/%m/%d'))\n",
    "        # Берем заголовки и ссылки на новости за этот день.\n",
    "        refs = [re.split('\"', t)[6] for t in re.split('<article class=\"item item-news item-news', r.text)[1:]]\n",
    "        for t in refs:\n",
    "            qu.put(getArticleTextNPlus1(\"https://nplus1.ru\" + t)) # Получаем текст статьи и отправляем в очередь.\n",
    "            time.sleep(0.2) # Мы этичные хакеры и не стремимся к DDoS.\n",
    "        curdate += datetime.timedelta(days=1)\n",
    "    sem.acquire() # Взводим семафор.\n",
    "    print(\"nplus1 finished\")\n",
    "    \n",
    "# Функция токенизирует вход из очереди qu1 и кладет результаты токенизации в очередь qu2.\n",
    "# Токенизация ведется до тех пор, пока семафор semw не будет взведен максимальное количество раз.\n",
    "# По завершении токенизации устанавливаем событие evs.\n",
    "def tokenize(qu1, qu2, semw, evs):  \n",
    "    c = 0\n",
    "    # Пытаемся взвести семафор. Если не взведется, значит все потоки завершились (взведением семафора).\n",
    "    while semw.acquire(False): \n",
    "        txt = qu1.get() # Получаем данные из очереди.\n",
    "        semw.release() # Отпускаем семафор (мы же взвели его в while).\n",
    "        qu2.put(re.findall(\"[А-Яа-я]+(-[А-Яа-я]+)?\", txt)) # Очень простая токенизация кладет результаты в очередь.\n",
    "        c += 1\n",
    "        print('token '+str(c))\n",
    "    print(\"tokenization finished\")\n",
    "    evs.set() # Сообщаем о завершении работы установкой события.\n",
    "    print(\"tokenization finished\")\n",
    "\"\"\" Вот здесь-то и происходит блокировка.\n",
    "    while semw.acquire(False): блокирует семафор для потоков, поставляющих новости. В самом конце последний \n",
    "    поток с новостями заканчивает свою работу и пытается завершиться. Но семафор уже заполнен, и поток переводится\n",
    "    в состояние ожидания. При этом поток токенизации ждет получения данных txt=qu1.get(), но так как данные не \n",
    "    больше поступают, то он тоже блокируется. \n",
    "    Один поток ждет данных, чтобы продолжить работу и разблокировать семафор, другой заблокирован семафором и \n",
    "    больше не хочет отправлять данные. Клинч! Хорошо хоть, что в конце работы, но такое могло произойти и в середине.\n",
    "    \n",
    "    Через одну ячейку приведен код, который исправляет эту ситуацию.\n",
    "\"\"\"\n",
    "\n",
    "# Поток лемматизации текстов. Токены берутся из очереди qu1, результаты лемматизации кладутся в qu2.\n",
    "# Так как новости приходят по одной в токенизацию, скорее всего токены будут идти подряд. Но если вдруг у нас появится\n",
    "# еще один поток для токенизации, они начнут помещаться в очередь вперемешку. Так что такая технология подходит\n",
    "# только если нас не волнуется порядок слов.\n",
    "# Данный заканчиваются, когда будет установлено событие evw, сообщаем о своем завершении при помощи события evs.\n",
    "def lemmatize(qu1, qu2, evw, evs):\n",
    "    morpho = pymorphy2.MorphAnalyzer() # Создаем морфоанализатор.\n",
    "    l = []\n",
    "    c = 0\n",
    "    while not evw.is_set(): # Если событие установлено - пора завершать работу.\n",
    "        txt = qu1.get()\n",
    "        s = []\n",
    "        for w in txt:\n",
    "            s += morpho.parse(w)[0]\n",
    "        qu2.put(s) # Анализируем, кладем результат в очередь.\n",
    "        c += 1\n",
    "        print('lemma ' + str(c))\n",
    "    evs.set() # ЗАвершаем работу.\n",
    "    print(\"lemmatization finished\")\n",
    "\n",
    "# Функция имитирует, что она обрабатывает данные из очереди qu. Заершает работу по событию ev.    \n",
    "def utilize(qu, ev):\n",
    "    c = 0\n",
    "    while not ev.is_set(): # Если событие установлено - пора завершать работу.\n",
    "        t = qu.get()\n",
    "        #processing\n",
    "        c += 1\n",
    "        print('process ' + str(c))\n",
    "    print('processing finished')\n",
    "\n",
    "# не надо тормозить при получении данных из очереди,\n",
    "# надо поставить ожидание если очередь пуста.\n",
    "# то, что есть - хороший пример на сложности синхронизации. еще очередь поменьше сделай.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lenta 2017/01/16\n",
      "nplus 2015/12/15\n",
      "lenta finished\n",
      "token 1\n",
      "lemma 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-26:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_493103/1823877807.py\", line 108, in utilize\n",
      "    t = qu.get()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/home/edward/.local/lib/python3.9/site-packages/pymorphy2/tagset.py\", line 278, in __init__\n",
      "    self._assert_grammemes_are_known(set(grammemes_tuple))\n",
      "  File \"/home/edward/.local/lib/python3.9/site-packages/pymorphy2/tagset.py\", line 394, in _assert_grammemes_are_known\n",
      "    cls._assert_grammemes_initialized()\n",
      "  File \"/home/edward/.local/lib/python3.9/site-packages/pymorphy2/tagset.py\", line 403, in _assert_grammemes_initialized\n",
      "    raise RuntimeError(msg)\n",
      "RuntimeError: The class was not properly initialized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 2\n",
      "lemma 2\n",
      "token 3\n",
      "lemma 3\n",
      "token 4\n",
      "lemma 4\n",
      "token 5\n",
      "lemma 5\n",
      "token 6\n",
      "lemma 6\n",
      "token 7\n",
      "lemma 7\n",
      "token 8\n",
      "lemma 8\n",
      "token 9\n",
      "lemma 9\n",
      "token 10\n",
      "lemma 10\n",
      "token 11\n",
      "lemma 11\n",
      "token 12\n",
      "lemma 12\n",
      "token 13\n",
      "lemma 13\n",
      "token 14\n",
      "lemma 14\n",
      "token 15\n",
      "lemma 15\n",
      "token 16\n",
      "lemma 16\n",
      "token 17\n",
      "lemma 17\n",
      "token 18\n",
      "lemma 18\n",
      "token 19\n",
      "lemma 19\n",
      "token 20\n",
      "lemma 20\n",
      "token 21\n",
      "lemma 21\n",
      "token 22\n",
      "lemma 22\n",
      "token 23\n",
      "lemma 23\n",
      "nplus 2015/12/16\n",
      "token 24\n",
      "lemma 24\n",
      "token 25\n",
      "lemma 25\n",
      "token 26\n",
      "lemma 26\n",
      "token 27\n",
      "lemma 27\n",
      "token 28\n",
      "lemma 28\n",
      "token 29\n",
      "lemma 29\n",
      "token 30\n",
      "lemma 30\n",
      "token 31\n",
      "lemma 31\n",
      "token 32\n",
      "lemma 32\n",
      "token 33\n",
      "lemma 33\n",
      "token 34\n",
      "lemma 34\n",
      "token 35\n",
      "lemma 35\n",
      "token 36\n",
      "lemma 36\n",
      "token 37\n",
      "lemma 37\n",
      "nplus 2015/12/17\n",
      "token 38\n",
      "lemma 38\n",
      "token 39\n",
      "lemma 39\n",
      "token 40\n",
      "lemma 40\n",
      "token 41\n",
      "lemma 41\n",
      "token 42\n",
      "lemma 42\n",
      "token 43\n",
      "lemma 43\n",
      "token 44\n",
      "lemma 44\n",
      "token 45\n",
      "lemma 45\n",
      "token 46\n",
      "lemma 46\n",
      "token 47\n",
      "lemma 47\n",
      "token 48\n",
      "lemma 48\n",
      "token 49\n",
      "lemma 49\n",
      "token 50\n",
      "lemma 50\n",
      "token 51\n",
      "lemma 51\n",
      "token 52\n",
      "lemma 52\n",
      "token 53\n",
      "lemma 53\n",
      "token 54\n",
      "lemma 54\n",
      "token 55\n",
      "lemma 55\n",
      "token 56\n",
      "lemma 56\n",
      "token 57\n",
      "lemma 57\n",
      "nplus 2015/12/18\n",
      "token 58\n",
      "lemma 58\n",
      "token 59\n",
      "lemma 59\n",
      "token 60\n",
      "lemma 60\n",
      "token 61\n",
      "lemma 61\n",
      "token 62\n",
      "lemma 62\n",
      "token 63\n",
      "lemma 63\n",
      "token 64\n",
      "lemma 64\n",
      "token 65\n",
      "lemma 65\n",
      "token 66\n",
      "lemma 66\n",
      "token 67\n",
      "lemma 67\n",
      "token 68\n",
      "lemma 68\n",
      "token 69\n",
      "lemma 69\n",
      "token 70\n",
      "lemma 70\n",
      "token 71\n",
      "lemma 71\n",
      "token 72\n",
      "lemma 72\n",
      "token 73\n",
      "lemma 73\n",
      "token 74\n",
      "lemma 74\n",
      "token 75\n",
      "lemma 75\n",
      "nplus 2015/12/19\n",
      "token 76\n",
      "lemma 76\n",
      "token 77\n",
      "lemma 77\n",
      "token 78\n",
      "lemma 78\n",
      "token 79\n",
      "lemma 79\n",
      "token 80\n",
      "lemma 80\n",
      "token 81\n",
      "lemma 81\n",
      "token 82\n",
      "lemma 82\n"
     ]
    }
   ],
   "source": [
    "# Два потока новостей.\n",
    "newswirenumber = 2\n",
    "\n",
    "# Создаем очереди, семафор и события для синхронизации.\n",
    "textsq = multiprocessing.Queue(100)\n",
    "tokenq = multiprocessing.Queue(100)\n",
    "lemmaq = multiprocessing.Queue(100)\n",
    "newss = multiprocessing.Semaphore(newswirenumber)\n",
    "tokene = multiprocessing.Event()\n",
    "lemmae = multiprocessing.Event()\n",
    "\n",
    "# Запускаем процессы.\n",
    "lentap = multiprocessing.Process(target=getLenta, args=(textsq, newss,))\n",
    "nplusp = multiprocessing.Process(target=getNplus1, args=(textsq, newss,))  \n",
    "tokenp = multiprocessing.Process(target=tokenize, args=(textsq, tokenq, newss, tokene, ))   \n",
    "lemmap = multiprocessing.Process(target=lemmatize, args=(tokenq, lemmaq, tokene, lemmae, ))   \n",
    "processp = multiprocessing.Process(target=utilize, args=(lemmaq, lemmae, ))    \n",
    "    \n",
    "# Стартуем процессы    \n",
    "lentap.start()\n",
    "nplusp.start()\n",
    "tokenp.start()\n",
    "lemmap.start()\n",
    "processp.start()\n",
    "\n",
    "# Если надо - ждем пока процессы не завершатся.\n",
    "#lentap.join()\n",
    "#nplusp.join()\n",
    "#tokenp.join()\n",
    "#lemmap.join()\n",
    "#processp.join()\n",
    "#print(\"Everything is allright\")                               \n",
    "                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Это код работает более корректно, чем тот, что приведен выше.\n",
    "# Большая часть комментариев опущена, оставлены только те, что помогают понять изменения в логике.\n",
    "\n",
    "def getLentaArticle(url):\n",
    "    # Вместо того, что вызывать Ктулху тем, что мы разбираем XML при помощи регулярок,\n",
    "    # давайте будем использовать мощь BeautifulSoup.\n",
    "    page = requests.get(url)\n",
    "    tree = html.fromstring(page.text)\n",
    "    text = '\\n'.join([p.text_content() for p in tree.xpath(\".//p[contains(@class,'topic-body__content-text')]\")])\n",
    "    \n",
    "    return text\n",
    "\n",
    "def getArticleTextNPlus1(adr):\n",
    "    r = requests.get(adr)\n",
    "    n_text = re.split(\"</div>\", re.split(\"</figure>\", re.split('</article>',re.split('<article', r.text)[1])[0])[1])[1]    \n",
    "    return BeautifulSoup(n_text, \"lxml\").get_text()\n",
    "\n",
    "def getLenta(qu, sem):\n",
    "    curdate = datetime.date(2017, 1, 16)\n",
    "    findate = datetime.date(2017, 1, 16)\n",
    "    res=\"\"\n",
    "\n",
    "    while curdate <= findate:\n",
    "        print('lenta ' + curdate.strftime('%Y/%m/%d'))\n",
    "        day = requests.get('https://lenta.ru/news/'+curdate.strftime('%Y/%m/%d'))\n",
    "        body = re.findall('<h3>(.+?)</h3>', day.text)\n",
    "        links = ['https://lenta.ru'+re.findall('\"(.+?)\"', x)[0] for x in body]\n",
    "        for l in links[:50]:\n",
    "            qu.put(getLentaArticle(l))\n",
    "            time.sleep(0.2)\n",
    "        curdate += datetime.timedelta(days=1)\n",
    "    sem.acquire()\n",
    "    print(\"lenta finished\")\n",
    "\n",
    "def getNplus1(qu, sem):\n",
    "    curdate = datetime.date(2015, 12, 15)\n",
    "    findate = datetime.date(2015, 12, 18)\n",
    "\n",
    "    while curdate <= findate:\n",
    "        r = requests.get('https://nplus1.ru/news/'+curdate.strftime('%Y/%m/%d'))\n",
    "        print('nplus ' + curdate.strftime('%Y/%m/%d'))\n",
    "        refs=[re.split('\"', t)[6] for t in re.split('<article class=\"item item-news item-news', r.text)[1:]]\n",
    "        for t in refs:\n",
    "            qu.put(getArticleTextNPlus1(\"https://nplus1.ru\"+t))\n",
    "            time.sleep(0.2)\n",
    "        curdate += datetime.timedelta(days=1)\n",
    "    sem.acquire()\n",
    "    print(\"nplus1 finished\")\n",
    "    \n",
    "# На входе - те же самые очереди, семафор и событие, но используем мы их по-другому.\n",
    "def tokenize(qu1, qu2, semw, evs):  \n",
    "    c = 0\n",
    "    while semw.acquire(False): # Так же пытаемся получить семафор.\n",
    "        try:\n",
    "            semw.release() # ! Первым делом отпускаем его, чтобы никого не держать больше.\n",
    "            txt = qu1.get(timeout=0.1) # Если что-то пойдет не так, нас отпустят через 0,1 секунды.\n",
    "        except queue.Empty: # Если произошел выход по таймауту, генерируется исключение.\n",
    "            #print('tokenization waits')\n",
    "            pass # Данных нет, пойдем посмотрим, может вообще завершаться пора?\n",
    "        else:\n",
    "            qu2.put(re.findall(\"[А-Яа-я]+(-[А-Яа-я]+)?\", txt)) # Данные есть - токенизируем и кладем в очередь.\n",
    "            c += 1\n",
    "            print('token '+str(c))\n",
    "\n",
    "    print(\"tokenization \")\n",
    "    evs.set()\n",
    "    print(\"finished\")\n",
    "\n",
    "def lemmatize(qu1, qu2, evw, evs):\n",
    "    morpho = pymorphy2.MorphAnalyzer()\n",
    "    l = []\n",
    "    c = 0\n",
    "    while not evw.is_set():\n",
    "        try:\n",
    "            txt = qu1.get(timeout=0.1) # Поддерживаем логику таймаута везде на всякий случай.\n",
    "        except queue.Empty:\n",
    "            pass\n",
    "        else:\n",
    "            s = []\n",
    "            for w in s:\n",
    "                s += morpho.parse(w)[0]\n",
    "            qu2.put(s)\n",
    "            c += 1\n",
    "            print('lemma '+str(c))\n",
    "    evs.set()\n",
    "    print(\"lemmatization finished\")\n",
    "\n",
    "def utilize(qu, ev):\n",
    "    c = 0\n",
    "    while not ev.is_set(): # Поддерживаем логику таймаута везде на всякий случай.\n",
    "        try:\n",
    "            t = qu.get(timeout=0.1)\n",
    "        except queue.Empty:\n",
    "            pass\n",
    "        else:\n",
    "        #processing\n",
    "            c += 1\n",
    "            print('process '+str(c))\n",
    "    print('processing finished')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lenta 2017/01/16\n",
      "nplus 2015/12/15\n",
      "lenta finished\n",
      "token 1\n",
      "lemma 1\n",
      "process 1\n",
      "token 2lemma 2\n",
      "process 2\n",
      "\n",
      "token 3lemma 3process 3\n",
      "\n",
      "\n",
      "token 4lemma 4\n",
      "process 4\n",
      "\n",
      "token 5lemma 5\n",
      "process 5\n",
      "\n",
      "token 6lemma 6\n",
      "process 6\n",
      "\n",
      "token 7lemma 7\n",
      "process 7\n",
      "\n",
      "token 8lemma 8\n",
      "process 8\n",
      "\n",
      "token 9lemma 9\n",
      "process 9\n",
      "\n",
      "token 10lemma 10\n",
      "process 10\n",
      "\n",
      "token 11lemma 11\n",
      "process 11\n",
      "\n",
      "token 12lemma 12\n",
      "process 12\n",
      "\n",
      "token 13lemma 13\n",
      "process 13\n",
      "\n",
      "token 14lemma 14\n",
      "\n",
      "process 14\n",
      "token 15lemma 15\n",
      "process 15\n",
      "\n",
      "token 16lemma 16\n",
      "process 16\n",
      "\n",
      "token 17lemma 17\n",
      "process 17\n",
      "\n",
      "token 18lemma 18\n",
      "\n",
      "process 18\n",
      "token 19lemma 19\n",
      "\n",
      "process 19\n",
      "token 20lemma 20\n",
      "process 20\n",
      "\n",
      "token 21lemma 21\n",
      "process 21\n",
      "\n",
      "token 22lemma 22\n",
      "process 22\n",
      "\n",
      "token 23lemma 23\n",
      "process 23\n",
      "\n",
      "nplus 2015/12/16\n",
      "token 24lemma 24\n",
      "process 24\n",
      "\n",
      "token 25lemma 25\n",
      "process 25\n",
      "\n",
      "token 26lemma 26\n",
      "process 26\n",
      "\n",
      "token 27lemma 27\n",
      "process 27\n",
      "\n",
      "token 28lemma 28\n",
      "process 28\n",
      "\n",
      "token 29lemma 29\n",
      "process 29\n",
      "\n",
      "token 30lemma 30\n",
      "process 30\n",
      "\n",
      "token 31lemma 31\n",
      "process 31\n",
      "\n",
      "token 32lemma 32\n",
      "process 32\n",
      "\n",
      "token 33lemma 33\n",
      "process 33\n",
      "\n",
      "token 34lemma 34\n",
      "\n",
      "process 34\n",
      "token 35lemma 35\n",
      "process 35\n",
      "\n",
      "token 36lemma 36\n",
      "process 36\n",
      "\n",
      "token 37\n",
      "lemma 37process 37\n",
      "\n",
      "nplus 2015/12/17\n",
      "token 38lemma 38\n",
      "\n",
      "process 38\n",
      "token 39lemma 39\n",
      "process 39\n",
      "\n",
      "token 40lemma 40\n",
      "process 40\n",
      "\n",
      "token 41lemma 41\n",
      "process 41\n",
      "\n",
      "token 42lemma 42\n",
      "process 42\n",
      "\n",
      "token 43lemma 43\n",
      "process 43\n",
      "\n",
      "token 44lemma 44\n",
      "process 44\n",
      "\n",
      "token 45lemma 45\n",
      "process 45\n",
      "\n",
      "token 46lemma 46\n",
      "process 46\n",
      "\n",
      "token 47lemma 47\n",
      "process 47\n",
      "\n",
      "token 48lemma 48\n",
      "process 48\n",
      "\n",
      "token 49lemma 49\n",
      "process 49\n",
      "\n",
      "token 50lemma 50\n",
      "process 50\n",
      "\n",
      "token 51lemma 51\n",
      "process 51\n",
      "\n",
      "token 52lemma 52\n",
      "process 52\n",
      "\n",
      "token 53lemma 53\n",
      "process 53\n",
      "\n",
      "token 54lemma 54\n",
      "process 54\n",
      "\n",
      "token 55lemma 55\n",
      "process 55\n",
      "\n",
      "token 56lemma 56process 56\n",
      "\n",
      "\n",
      "token 57lemma 57\n",
      "process 57\n",
      "\n",
      "nplus 2015/12/18\n",
      "token 58lemma 58\n",
      "process 58\n",
      "\n",
      "token 59lemma 59\n",
      "process 59\n",
      "\n",
      "token 60lemma 60\n",
      "process 60\n",
      "\n",
      "token 61lemma 61\n",
      "process 61\n",
      "\n",
      "token 62lemma 62\n",
      "process 62\n",
      "\n",
      "token 63lemma 63\n",
      "\n",
      "process 63\n",
      "token 64lemma 64\n",
      "process 64\n",
      "\n",
      "token 65lemma 65\n",
      "process 65\n",
      "\n",
      "token 66lemma 66\n",
      "process 66\n",
      "\n",
      "token 67lemma 67\n",
      "process 67\n",
      "\n",
      "token 68lemma 68\n",
      "process 68\n",
      "\n",
      "token 69lemma 69\n",
      "process 69\n",
      "\n",
      "token 70lemma 70\n",
      "process 70\n",
      "\n",
      "token 71lemma 71\n",
      "process 71\n",
      "\n",
      "token 72lemma 72\n",
      "process 72\n",
      "\n",
      "token 73lemma 73\n",
      "process 73\n",
      "\n",
      "token 74lemma 74\n",
      "process 74\n",
      "\n",
      "token 75lemma 75\n",
      "process 75\n",
      "\n",
      "nplus1 finished\n",
      "tokenization \n",
      "finished\n",
      "lemmatization finishedprocessing finished\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Два потока новостей.\n",
    "newswirenumber = 2\n",
    "\n",
    "# Создаем очереди, семафор и события для синхронизации.\n",
    "textsq = multiprocessing.Queue(100)\n",
    "tokenq = multiprocessing.Queue(100)\n",
    "lemmaq = multiprocessing.Queue(100)\n",
    "newss = multiprocessing.Semaphore(newswirenumber)\n",
    "tokene = multiprocessing.Event()\n",
    "lemmae = multiprocessing.Event()\n",
    "\n",
    "# Запускаем процессы.\n",
    "lentap = multiprocessing.Process(target=getLenta, args=(textsq, newss,))\n",
    "nplusp = multiprocessing.Process(target=getNplus1, args=(textsq, newss,))  \n",
    "tokenp = multiprocessing.Process(target=tokenize, args=(textsq, tokenq, newss, tokene, ))   \n",
    "lemmap = multiprocessing.Process(target=lemmatize, args=(tokenq, lemmaq, tokene, lemmae, ))   \n",
    "processp = multiprocessing.Process(target=utilize, args=(lemmaq, lemmae, ))    \n",
    "    \n",
    "# Стартуем процессы    \n",
    "lentap.start()\n",
    "nplusp.start()\n",
    "tokenp.start()\n",
    "lemmap.start()\n",
    "processp.start()\n",
    "\n",
    "# Если надо - ждем пока процессы не завершатся.\n",
    "#lentap.join()\n",
    "#nplusp.join()\n",
    "#tokenp.join()\n",
    "#lemmap.join()\n",
    "#processp.join()\n",
    "#print(\"Everything is allright\")                               \n",
    "                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymorphy2 import MorphAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1920753\n",
      "CPU times: user 5.51 s, sys: 17.6 ms, total: 5.53 s\n",
      "Wall time: 5.53 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "morpho = MorphAnalyzer()\n",
    "total_len = 0\n",
    "\n",
    "with open(\"data/war_and_peace.txt\") as infile:\n",
    "    for line in infile:\n",
    "        words = [w[0] for w in re.findall(\"([А-Яа-я]+(-[А-Яа-я]+)*)\", line)]\n",
    "        for word in words:\n",
    "            res = morpho.parse(word)\n",
    "            total_len += len(res)\n",
    "print(total_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 62.4 ms, sys: 8.03 ms, total: 70.5 ms\n",
      "Wall time: 69.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "morpho = MorphAnalyzer()\n",
    "\n",
    "with open(\"data/war_and_peace.txt\") as infile:\n",
    "    for line in infile:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lines = []\n",
    "with open(\"data/war_and_peace.txt\") as infile:\n",
    "    for line in infile:\n",
    "        all_lines.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1920753\n",
      "CPU times: user 7.13 s, sys: 0 ns, total: 7.13 s\n",
      "Wall time: 7.13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "total_len = 0\n",
    "\n",
    "for line in all_lines:\n",
    "    words = [w[0] for w in re.findall(\"([А-Яа-я]+(-[А-Яа-я]+)*)\", line)]\n",
    "    for word in words:\n",
    "        res = morpho.parse(word)\n",
    "        total_len += len(res)\n",
    "        \n",
    "print(total_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1920753\n",
      "CPU times: user 0 ns, sys: 7.78 ms, total: 7.78 ms\n",
      "Wall time: 5.66 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def read_lines(qu, event):\n",
    "    cntr = 0\n",
    "    buffer = []\n",
    "    with open(\"data/war_and_peace.txt\") as infile:\n",
    "        for line in infile:\n",
    "            buffer.append(line)\n",
    "            if len(buffer) == 100:\n",
    "                qu.put(buffer)\n",
    "                buffer = []\n",
    "    qu.put(buffer)\n",
    "    event.set()\n",
    "    \n",
    "def tag_words(qu, event):\n",
    "    total_len = 0\n",
    "    morpho = MorphAnalyzer()\n",
    "\n",
    "    while not event.is_set() or not qu.empty():\n",
    "        try:\n",
    "            lines = qu.get(timeout=0.1) # Поддерживаем логику таймаута везде на всякий случай.\n",
    "        except queue.Empty:\n",
    "            pass\n",
    "        else:\n",
    "            for line in lines:\n",
    "                words = [w[0] for w in re.findall(\"([А-Яа-я]+(-[А-Яа-я]+)*)\", line)]\n",
    "                for word in words:\n",
    "                    res = morpho.parse(word)        \n",
    "                    total_len += len(res)\n",
    "    print(total_len)\n",
    "\n",
    "wordsq = multiprocessing.Queue(100)\n",
    "wordse = multiprocessing.Event()\n",
    "readp = multiprocessing.Process(target=read_lines, args=(wordsq, wordse,))\n",
    "tagp = multiprocessing.Process(target=tag_words, args=(wordsq, wordse,))  \n",
    "\n",
    "readp.start()\n",
    "tagp.start()\n",
    "\n",
    "readp.join()\n",
    "tagp.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Хорошее описание объектов Питона для параллельного программирования - [здесь](https://devpractice.ru/python-lesson-23-concurrency-part-2/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
