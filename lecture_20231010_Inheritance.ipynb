{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –ù–∞—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –≤ Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î–∞–≤–∞–π—Ç–µ —Ä–µ—à–∏–º —Å–ª–µ–¥—É—é—â—É—é –∑–∞–¥–∞—á—É.\n",
    "\n",
    "–ù–µ–æ–±—Ö–æ–¥–∏–º–æ –Ω–∞–ø–∏—Å–∞—Ç—å —Ä–æ–±–æ—Ç–∞, –∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ—Ç —Å–∫–∞—á–∏–≤–∞—Ç—å –Ω–æ–≤–æ—Å—Ç–∏ —Å —Å–∞–π—Ç–∞ –õ–µ–Ω—Ç–∞.–†—É –∏ —Ñ–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å –∏—Ö –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∏–Ω—Ç–µ—Ä–µ—Å–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è. –û—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Ç—Ä–µ–±—É–µ—Ç—Å—è –æ—Ç–º–µ—á–∞—Ç—å –∏–Ω—Ç–µ—Ä–µ—Å—É—é—â–∏–µ –µ–≥–æ –Ω–æ–≤–æ—Å—Ç–∏, –ø–æ –∫–æ—Ç–æ—Ä—ã–º —Å–∏—Å—Ç–µ–º–∞ –±—É–¥–µ—Ç –≤—ã–¥–µ–ª—è—Ç—å –æ–±–ª–∞—Å—Ç–∏ –µ–≥–æ –∏–Ω—Ç–µ—Ä–µ—Å–æ–≤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "from lxml import html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ù–æ —Å–ø–µ—Ä–≤–∞ –ø–æ–≥–æ–≤–æ—Ä–∏–º –≤–æ—Ç –æ —á–µ–º"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exceptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í –ü–∏—Ç–æ–Ω–µ –µ—Å—Ç—å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –æ—Ç–ª–∞–≤–ª–∏–≤–∞—Ç—å –ø—Ä–æ–∏—Å—Ö–æ–¥—è—â–∏–µ –æ—à–∏–±–∫–∏ –ø—Ä–∏ –ø–æ–º–æ—â–∏ try ... except. –ï—Å–ª–∏ –≤ –±–ª–æ–∫–µ try –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –æ—à–∏–±–∫–∞, —Ç–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–æ–≥—Ä–∞–º–º—ã –Ω–µ –ø—Ä–µ–∫—Ä–∞—â–∞–µ—Ç—Å—è, –∞ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è —Å–ø–µ—Ä–≤–∞ –±–ª–æ–∫ except, –∞ –ø–æ—Ç–æ–º –∫–æ–¥ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –¥–∞–ª—å—à–µ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–≤–≤–µ–¥–∏—Ç–µ —á–∏—Å–ª–æ0\n",
      "–í–≤–µ–¥–∏—Ç–µ –¥—Ä—É–≥–æ–µ —á–∏—Å–ª–æ!\n",
      "–≤–≤–µ–¥–∏—Ç–µ —á–∏—Å–ª–æ0\n",
      "–í–≤–µ–¥–∏—Ç–µ –¥—Ä—É–≥–æ–µ —á–∏—Å–ª–æ!\n",
      "–≤–≤–µ–¥–∏—Ç–µ —á–∏—Å–ª–æ1\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    try:\n",
    "        d1 = input(\"–≤–≤–µ–¥–∏—Ç–µ —á–∏—Å–ª–æ\")\n",
    "        d2 = 10 / int(d1)\n",
    "        print(d2)\n",
    "        break\n",
    "    except:\n",
    "        print(\"–í–≤–µ–¥–∏—Ç–µ –¥—Ä—É–≥–æ–µ —á–∏—Å–ª–æ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception comes!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    a = b / 0\n",
    "except:\n",
    "    print(\"Exception comes!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'b' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_75241/759579516.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# –ë–µ–∑ –∏—Å–∫–ª—é—á–∏—Ç–µ–ª—å–Ω–æ–π —Å–∏—Ç—É–∞—Ü–∏–∏.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'b' is not defined"
     ]
    }
   ],
   "source": [
    "# –ë–µ–∑ –∏—Å–∫–ª—é—á–∏—Ç–µ–ª—å–Ω–æ–π —Å–∏—Ç—É–∞—Ü–∏–∏.\n",
    "a = b / 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ó–∞–º–µ—á—É, —á—Ç–æ –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ –≤—ã–∑—ã–≤–∞—é—Ç –∏—Å–∫–ª—é—á–∏—Ç–µ–ª—å–Ω—ã–µ —Å–∏—Ç—É–∞—Ü–∏–∏, –µ—Å–ª–∏ –≤ –Ω–∏—Ö —á—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é. –≠—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å —à—Ç–∞—Ç–Ω—ã–º –ø–æ–≤–µ–¥–µ–Ω–∏–µ–º —Ñ—É–Ω–∫—Ü–∏–∏. \n",
    "\n",
    "–ï—Å–ª–∏ —Ö–æ—á–µ—Ç—Å—è –ø–æ–π–º–∞—Ç—å —Å–∏—Ç—É–∞—Ü–∏—é, –∫–æ–≥–¥–∞ –∫–æ–¥ –≤—ã–ø–æ–ª–Ω–∏–ª—Å—è –±–µ–∑ –∏—Å–∫–ª—é—á–∏—Ç–µ–ª—å–Ω–æ–π —Å–∏—Ç—É–∞—Ü–∏–∏, –Ω—É–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏—é `try ... except ... else ...`. –ë–ª–æ–∫ `else` –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –≤ —Ç–æ–º —Å–ª—É—á–∞–µ, –∫–æ–≥–¥–∞ –∫–æ–¥ –≤—ã–ø–æ–ª–Ω–∏–ª—Å—è —à—Ç–∞—Ç–Ω–æ, —Ç–æ –µ—Å—Ç—å –ø–æ–ª–Ω–æ—Å—Ç—å—é –∏ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ. –í —Ç–∞–∫–æ–π —Å–∏—Ç—É–∞—Ü–∏–∏ –º–æ–∂–Ω–æ –æ–∂–∏–¥–∞—Ç—å –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è –ø—Ä–æ–≥—Ä–∞–º–º—ã –ø–æ –≤—Å–µ–º –ø—É–Ω–∫—Ç–∞–º."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_75332/1269304327.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    f = open(\"no_file_at_disk.none\")\n",
    "except:\n",
    "    data = None\n",
    "else:\n",
    "    f.seek(0, 2) # move the cursor to the end of the file\n",
    "    size = f.tell()\n",
    "    data = f.read(size)\n",
    "    \n",
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ò–Ω–æ–≥–¥–∞ –±—ã–≤–∞–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –≤—ã–ø–æ–ª–Ω–∏—Ç—å –∫–æ–¥ –ø–æ—Å–ª–µ –≤ –ª—é–±–æ–º —Å–ª—É—á–∞–µ - –ø—Ä–æ–∏–∑–æ—à–ª–æ –∏—Å–∫–ª—é—á–µ–Ω–∏–µ –∏–ª–∏ –Ω–µ—Ç. –ù–∞–ø—Ä–∏–º–µ—Ä, –Ω–∞–º –Ω–∞–¥–æ –æ—Å–≤–æ–±–æ–¥–∏—Ç—å –∫–∞–∫–∏–µ-—Ç–æ —Ä–µ—Å—É—Ä—Å—ã. –î–ª—è —ç—Ç–æ–≥–æ –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–ª–æ–∫ `finally`. –ï—Å–ª–∏ –∏—Å–∫–ª—é—á–µ–Ω–∏—è –Ω–µ –±—É–¥–µ—Ç, –æ–Ω –≤—ã–ø–æ–ª–Ω–∏—Ç—Å—è –∏ –∫–æ–¥ –ø—Ä–æ–¥–æ–ª–∂–∏—Ç —Å–≤–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ. –ï—Å–ª–∏ –∏—Å–∫–ª—é—á–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–æ–π–¥–µ—Ç –¥–ª—è `try ... finally ... `, –≤—ã–ø–æ–ª–Ω–∏—Ç—Å—è –±–ª–æ–∫ `finally`, –∞ —Ç–æ–ª—å–∫–æ –ø–æ—Ç–æ–º –ø—Ä–æ–∏–∑–æ–π–¥–µ—Ç –∏—Å–∫–ª—é—á–µ–Ω–∏–µ. –ï—Å–ª–∏ –æ–Ω–æ –ø—Ä–æ–∏–∑–æ–π–¥–µ—Ç –≤ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ `try ... except ... finally ...`, —Å–ø–µ—Ä–≤–∞ –æ—Ç—Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ–¥ –∏—Å–∫–ª—é—á–µ–Ω–∏—è, –∞ –ø–æ—Ç–æ–º `finally`.\n",
    "\n",
    "`finally` –∏–¥–µ—Ç –ø–æ—Å–ª–µ `else`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'll be back. üëç\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_75332/3827096827.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# c = 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m# except:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#     print(\"Exception comes!\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "# b = None\n",
    "b = 1\n",
    "c = 0\n",
    "# c = 1\n",
    "try:\n",
    "    a = b / c\n",
    "# except:\n",
    "#     print(\"Exception comes!\")\n",
    "# else:\n",
    "#     print(\"Try not to get worried, try not to turn on to Problems that upset you, oh.\")\n",
    "finally:\n",
    "    print(\"I'll be back. üëç\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ú—ã –º–æ–∂–µ–º –ø–æ–π–º–∞—Ç—å **–ø–µ—Ä–µ–º–µ–Ω–Ω—É—é** –∏—Å–∫–ª—é—á–µ–Ω–∏—è –∏ –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å –Ω–∞ –Ω–µ–µ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'ZeroDivisionError'> ['__cause__', '__class__', '__context__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__suppress_context__', '__traceback__', 'args', 'with_traceback'] ['tb_frame', 'tb_lasti', 'tb_lineno', 'tb_next']\n"
     ]
    }
   ],
   "source": [
    "# b = None\n",
    "b = 1\n",
    "c = 0\n",
    "# c = 1\n",
    "\n",
    "try:\n",
    "    a = b / c\n",
    "except Exception as err:\n",
    "    print(type(err), dir(err), dir(err.__traceback__))#, err.with_traceback())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ö–∞–∫ –º–æ–∂–Ω–æ —É–≤–∏–¥–µ—Ç—å –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –ø—Ä–∏–º–µ—Ä–∞, –∏—Å–∫–ª—é—á–µ–Ω–∏—è –±—ã–≤–∞—é—Ç —Ä–∞–∑–Ω—ã–µ, –º—ã –º–æ–∂–µ–º —Å–∫–∞–∑–∞—Ç—å –∫–∞–∫–∏–µ –∏–º–µ–Ω–Ω–æ –ª–æ–≤–∏—Ç—å."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Never divide by zero ('division by zero',)\n"
     ]
    }
   ],
   "source": [
    "# b = None\n",
    "b = 1\n",
    "c = 0\n",
    "# c = 1\n",
    "\n",
    "try:\n",
    "    a = b / c\n",
    "except TypeError as err:\n",
    "    print('Take care on your variables', err.args)\n",
    "except ZeroDivisionError as err:\n",
    "    print('Never divide by zero', err.args)\n",
    "except Exception as err:\n",
    "    print(type(err), dir(err))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ú–æ–∂–Ω–æ –ø–æ—Ä–æ–∂–¥–∞—Ç—å —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–µ –∏—Å–∫–ª—é—á–µ–Ω–∏—è. –î–ª—è —ç—Ç–æ–≥–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º `raise`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xfe in position 0: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_75332/2355057964.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34mb'\\xfe\\xff'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xfe in position 0: invalid start byte"
     ]
    }
   ],
   "source": [
    "b'\\xfe\\xff'.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def never_work() -> None:\n",
    "    raise\n",
    "    \n",
    "def never_work2() -> None:\n",
    "    raise Exception(\"I'm booooreeeed!\")\n",
    "    \n",
    "def never_work3() -> None:\n",
    "    err = ZeroDivisionError(\"I'm looking like zero division!\", {'a':1, 'b':2})\n",
    "    err.it_wents_wrong = ['asd', 12]\n",
    "    raise err    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_55237/1941191728.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnever_work\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_55237/3483338864.py\u001b[0m in \u001b[0;36mnever_work\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnever_work\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnever_work2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"I'm booooreeeed!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "never_work()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "I'm looking like zero division!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_55237/2336824269.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnever_work2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_55237/3483338864.py\u001b[0m in \u001b[0;36mnever_work2\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnever_work2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mZeroDivisionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"I'm looking like zero division!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: I'm looking like zero division!"
     ]
    }
   ],
   "source": [
    "never_work2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what? (\"I'm looking like zero division!\", {'a': 1, 'b': 2}) ['asd', 12]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    never_work3()\n",
    "except ZeroDivisionError as err:\n",
    "    print('what?', err.args, err.it_wents_wrong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### namedtuple\n",
    "\n",
    "–ï—Å—Ç—å —Å—Ç–∞—Ä–∞—è –ø—Ä–æ–±–ª–µ–º–∞: –º–Ω–µ –Ω–µ –æ—á–µ–Ω—å –ø–æ–Ω—è—Ç–Ω–æ, –ø–æ—á–µ–º—É —è —Ö—Ä–∞–Ω—é –æ–±—ä–µ–∫—Ç—ã –≤ —Å–ª–æ–≤–∞—Ä—è—Ö, —Å–ø–∏—Å–∫–∞—Ö –∏–ª–∏ –∫–æ—Ä—Ç–µ–∂–∞—Ö. –° –¥—Ä—É–≥–æ–π —Å—Ç–æ—Ä–æ–Ω—ã, —è —Ö–æ—á—É, —á—Ç–æ–±—ã –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ–ª–µ–π –æ–±—ä–µ–∫—Ç–∞ –Ω–∏–∫—Ç–æ –Ω–µ –º–µ–Ω—è–ª. –ò–ª–∏ —á—Ç–æ–±—ã –æ–Ω–æ –∏–º–µ–ª–æ —Ç–æ–ª—å–∫–æ –ø—Ä–æ—Å—Ç—ã–µ —Å–≤–æ–π—Å—Ç–≤–∞ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ –±–µ–∑ –º–µ—Ç–æ–¥–æ–≤. –ò–ª–∏ —Å–æ–∑–¥–∞–≤–∞—Ç—å –∫–ª–∞—Å—Å—ã –∏ –æ–±—ä–µ–∫—Ç—ã –Ω–∞–ª–µ—Ç—É. \n",
    "\n",
    "–î–ª—è —ç—Ç–æ–≥–æ –µ—Å—Ç—å —Å—Ç–∞—Ä–æ–µ —Ä–µ—à–µ–Ω–∏–µ - `namedtuple`. –ï–π –º–æ–∂–Ω–æ –ø–µ—Ä–µ–¥–∞—Ç—å —Å–ø–∏—Å–æ–∫ –Ω–∞–∑–≤–∞–Ω–∏–π, –ø–æ –∫–æ—Ç–æ—Ä—ã–º –º—ã –±—É–¥–µ–º –æ–±—Ä–∞—â–∞—Ç—å—Å—è –∫ —ç–ª–µ–º–µ–Ω—Ç–∞–º –∫–æ—Ä—Ç–µ–∂–∞. –ü—Ä–∏ —ç—Ç–æ–º –Ω–∞–∑–≤–∞–Ω–∏—è –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–∞–∫ —Å–≤–æ–π—Å—Ç–≤–∞, —Ç–æ –µ—Å—Ç—å –ø–∏—Å–∞—Ç—å –ø–æ—Å–ª–µ –∏–º–µ–Ω–∏ –æ–±—ä–µ–∫—Ç–∞ —á–µ—Ä–µ–∑ —Ç–æ—á–∫—É. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π —Ç–∏–ø, –ø–µ—Ä–µ–¥–∞–µ–º –≤ –Ω–µ–≥–æ –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–∏–ø–∞ –∏ —Å–ø–∏—Å–æ–∫ –ø–æ–ª–µ–π.\n",
    "LentaArticleTupled = namedtuple('LentaArticleTupled', \n",
    "                                ['title', 'text', 'description', 'time', 'author'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç —ç—Ç–æ–≥–æ –Ω–æ–≤–æ–≥–æ —Ç–∏–ø–∞, –ø–µ—Ä–µ–¥–∞–µ–º –≤ –Ω–µ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ–ª–µ–π.\n",
    "la = LentaArticleTupled('123', '234', 'asdf', '10:01', 'Nope')\n",
    "la2 = LentaArticleTupled('321', text='098', description='asdf', time='10:01', author='Nope')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'123'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "la.title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ö—Å—Ç–∞—Ç–∏, —ç—Ç–æ –≤—Å—ë –µ—â—ë –∫–æ—Ä—Ç–µ–∂, —Ç–æ –µ—Å—Ç—å –º–æ–∂–Ω–æ –æ–±—Ä–∞—â–∞—Ç—å—Å—è –∫ –ø–æ–ª—è–º –ø–æ –Ω–æ–º–µ—Ä—É."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'234'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "la[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ú–µ–Ω—è—Ç—å –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ–ª–µ–π –Ω–µ –ø–æ–ª—É—á–∏—Ç—Å—è - —ç—Ç–æ –∂–µ –∫–æ—Ä—Ç–µ–∂!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "can't set attribute",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_75332/2788621633.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mla\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'123'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: can't set attribute"
     ]
    }
   ],
   "source": [
    "la.title = '123'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ê —á—Ç–æ –≤–Ω—É—Ç—Ä–∏?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(LentaArticleTupled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__add__',\n",
       " '__class__',\n",
       " '__class_getitem__',\n",
       " '__contains__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getnewargs__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__match_args__',\n",
       " '__module__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__rmul__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '_asdict',\n",
       " '_field_defaults',\n",
       " '_fields',\n",
       " '_make',\n",
       " '_replace',\n",
       " 'author',\n",
       " 'count',\n",
       " 'description',\n",
       " 'index',\n",
       " 'text',\n",
       " 'time',\n",
       " 'title']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(LentaArticleTupled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LentaArticleTupled.title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–°–æ–∑–¥–∞–¥–∏–º —Ç–µ–ø–µ—Ä—å —Ñ—É–Ω–∫—Ü–∏—é, –∫–æ—Ç–æ—Ä–∞—è –∑–∞–≥—Ä—É–∂–∞–µ—Ç –Ω–æ–≤–æ—Å—Ç—å —Å –õ–µ–Ω—Ç—ã.—Ä—É –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–º–µ–Ω–æ–≤–∞–Ω–Ω—ã–π –∫–æ—Ä—Ç–µ–∂."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_75332/1625100845.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marticle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mget_lenta_article_tupled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://lenta.ru/news/2021/02/27/apple_effect/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_75332/1625100845.py\u001b[0m in \u001b[0;36mget_lenta_article_tupled\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".//div[contains(@class, 'topic-authors')]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".//meta[@property='og:description']\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"content\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".//time[contains(@class, 'topic-header__time')]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m             '\\n'.join([p.text_content() for p in \n\u001b[1;32m     10\u001b[0m                 tree.xpath(\".//div[contains(@class, '_news')]//p[contains(@class, 'topic-body__content-text')]\")]\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "def get_lenta_article_tupled(url: str) -> LentaArticleTupled:\n",
    "    page = requests.get(url)\n",
    "    tree = html.fromstring(page.text)\n",
    "    article = LentaArticleTupled(\n",
    "            tree.xpath(\".//h1\")[0].text_content(),\n",
    "            tree.xpath(\".//div[contains(@class, 'topic-authors')]\")[0].text_content().strip(),\n",
    "            tree.xpath(\".//meta[@property='og:description']\")[0].get(\"content\"),\n",
    "            tree.xpath(\".//time[contains(@class, 'topic-header__time')]\")[0].text_content().strip(), \n",
    "            '\\n'.join([p.text_content() for p in \n",
    "                tree.xpath(\".//div[contains(@class, '_news')]//p[contains(@class, 'topic-body__content-text')]\")]\n",
    "                    )\n",
    "           )\n",
    "    \n",
    "    return article\n",
    "\n",
    "get_lenta_article_tupled('https://lenta.ru/news/2021/02/27/apple_effect/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### @dataclass\n",
    "\n",
    "–ò–Ω–æ–≥–¥–∞ –Ω–∞–º –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —Å–æ–∑–¥–∞—Ç—å –∫–ª–∞—Å—Å, –∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å –≤ —Å–µ–±–µ —Ç–æ–ª—å–∫–æ –¥–∞–Ω–Ω—ã–µ, –Ω–æ –Ω–µ –±—É–¥–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å –≤ —Å–µ–±–µ –º–µ—Ç–æ–¥–æ–≤ —Ä–∞–±–æ—Ç—ã —Å —ç—Ç–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏. –î–ª—è —ç—Ç–æ–≥–æ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –¥–µ–∫–æ—Ä–∞—Ç–æ—Ä `dataclass` –∏–∑ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ `dataclasses`.\n",
    "\n",
    "–ò—Ö —É–¥–æ–±—Å—Ç–≤–æ –∑–∞–∫–ª—é—á–∞–µ—Ç—Å—è –≤ —Ç–æ–º, —á—Ç–æ –º–æ–∂–Ω–æ –ø—Ä–æ—Å—Ç–æ –æ–ø–∏—Å–∞—Ç—å –ø–æ–ª—è, –≤—Ö–æ–¥—è—â–∏–µ –≤ —ç—Ç–æ—Ç –∫–ª–∞—Å—Å–∞, –∏ –≤—Å–µ –æ–±—ä–µ–∫—Ç—ã –±—É–¥—É—Ç —Å–æ–∑–¥–∞–≤–∞—Ç—å—Å—è —Å —ç—Ç–∏–º–∏ –ø–æ–ª—è–º–∏. –ü—Ä–∏ —ç—Ç–æ–º –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –Ω–∞–¥–æ —É–∫–∞–∑—ã–≤–∞—Ç—å —Ç–∏–ø –∞—Ç—Ä–∏–±—É—Ç–∞. (–ù–æ –º–æ–∂–Ω–æ —É–∫–∞–∑–∞—Ç—å `Any` –∏–∑ –º–æ–¥—É–ª—è `typing`.)\n",
    "\n",
    "–ü—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –º–æ–∂–Ω–æ –ø—Ä–∏—Å–≤–æ–∏—Ç—å –∞—Ç—Ä–∏–±—É—Ç–∞–º –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é. –ù–æ —Å–ª–µ–¥—É–µ—Ç –∏–º–µ—Ç—å –≤ –≤–∏–¥—É, —á—Ç–æ —Å–ø–µ—Ä–≤–∞ –∏–¥—É—Ç –≤—Å–µ –ø–æ–ª—è –±–µ–∑ –∑–Ω–∞—á–µ–Ω–∏–π –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é, –∞ –ø–æ—Ç–æ–º –≤—Å–µ —Å –ø—Ä–∏—Å–≤–∞–∏–≤–∞–µ–º—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏.\n",
    "\n",
    "–ó–∞–º–µ—Ç–∏–º, —á—Ç–æ –≤ —Ç–∞–∫–∏—Ö –∫–ª–∞—Å—Å–∞—Ö –º–æ–≥—É—Ç –±—ã—Ç—å –∏ –º–µ—Ç–æ–¥—ã. –ü—Ä–æ—Å—Ç–æ –∏–Ω–æ–≥–¥–∞ –ø—Ä–æ—â–µ –æ–ø–∏—Å–∞—Ç—å —Ç–∞–∫–æ–π –∫–ª–∞—Å—Å –∏ –Ω–∏—á–µ–≥–æ –≤ –Ω–µ–≥–æ –Ω–µ –¥–æ–±–∞–≤–ª—è—Ç—å, –∞ –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –ø—É—Å—Ç—å –±–µ—Ä—É—Ç—Å—è –∏–∑ –æ–ø–∏—Å–∞–Ω–∏—è.\n",
    "\n",
    "–ë–æ–ª–µ–µ –ø–æ–¥—Ä–æ–±–Ω–æ –ø—Ä–æ –Ω–∏—Ö –º–æ–∂–Ω–æ –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å [–∑–¥–µ—Å—å](https://habr.com/ru/post/415829/) –∏ [–∑–¥–µ—Å—å](https://docs.python.org/3/library/dataclasses.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class LentaArticle:\n",
    "    title: str\n",
    "    text: str\n",
    "    description: str\n",
    "    time: str = \"00:00\"\n",
    "    author: str = \"No author\"\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–¢–µ–ø–µ—Ä—å –Ω–∞–ø–∏—à–µ–º —Ñ—É–Ω–∫—Ü–∏—é, –∫–æ—Ç–æ—Ä–∞—è –±—É–¥–µ—Ç –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –æ–±—ä–µ–∫—Ç –Ω–æ–≤–æ—Å—Ç–∏, –∞ –Ω–µ –±—É–¥–µ—Ç —Ö—Ä–∞–Ω–∏—Ç—å –∞—Ç—Ä–∏–±—É—Ç—ã –æ–¥–Ω–æ–π —Å—É—â–Ω–æ—Å—Ç–∏ –≤ —Ä–∞–∑–Ω—ã—Ö –º–µ—Å—Ç–∞—Ö."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_75332/1610471783.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marticle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mget_lenta_article\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://lenta.ru/news/2021/02/27/apple_effect/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_75332/1610471783.py\u001b[0m in \u001b[0;36mget_lenta_article\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0marticle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLentaArticle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mttl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdscrptn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0marticle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".//time[contains(@class, 'topic-header__time')]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0marticle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".//div[contains(@class, 'topic-authors')]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marticle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "def get_lenta_article(url: str) -> LentaArticle:\n",
    "    page = requests.get(url)\n",
    "    tree = html.fromstring(page.text)\n",
    "    ttl = tree.xpath(\".//h1\")[0].text_content()\n",
    "    dscrptn = tree.xpath(\".//meta[@property='og:description']\")[0].get(\"content\")\n",
    "\n",
    "    txt = '\\n'.join([p.text_content() for p in \n",
    "             tree.xpath(\".//div[contains(@class, '_news')]//p[contains(@class, 'topic-body__content-text')]\")]\n",
    "                    )\n",
    "    \n",
    "    article = LentaArticle(ttl, txt, dscrptn)\n",
    "    article.time = tree.xpath(\".//time[contains(@class, 'topic-header__time')]\")[0].text_content().strip()\n",
    "    article.author = tree.xpath(\".//div[contains(@class, 'topic-authors')]\")[0].text_content().strip()\n",
    "    return article\n",
    "\n",
    "get_lenta_article('https://lenta.ru/news/2021/02/27/apple_effect/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í–æ–æ–±—â–µ-—Ç–æ, –∫–∞–∫-—Ç–æ –Ω–µ –æ—á–µ–Ω—å –∫—Ä–∞—Å–∏–≤–æ. –ê –¥–∞–≤–∞–π—Ç–µ, —Ä–∞–∑ —É–∂ –º–æ–∂–Ω–æ –∑–∞–≤–æ–¥–∏—Ç—å —Ñ—É–Ω–∫—Ü–∏–∏, —Å–æ–∑–¥–∞–¥–∏–º –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä, –≤ –∫–æ—Ç–æ—Ä—ã–π –±—É–¥—É—Ç –ø–µ—Ä–µ–¥–∞–≤–∞—Ç—å—Å—è –∑–Ω–∞—á–µ–Ω–∏—è –≤ —É–¥–æ–±–Ω–æ–º –¥–ª—è –Ω–∞—Å –ø–æ—Ä—è–¥–∫–µ. –ê –∑–∞–æ–¥–Ω–æ –∑–∞–≤–µ–¥–µ–º –º–µ—Ç–æ–¥ `__repr__`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass()\n",
    "class LentaArticle:\n",
    "    title: str\n",
    "    text: str\n",
    "    description: str\n",
    "    time: str = \"00:00\"\n",
    "    author: str = \"No author\"\n",
    "        \n",
    "    def __init__(self: 'LentaArticle', _title: str, _author: str, _description: str,\n",
    "                 _time: str, _text: str):\n",
    "        self.title = _title\n",
    "        self.author = _author\n",
    "        self.description = _description\n",
    "        self.time = _time\n",
    "        self.text = _text\n",
    "        \n",
    "    def __repr__(self: 'LentaArticle') -> str:\n",
    "        return f\"\"\"LentaArticle(\\n  title={self.title[:60]}\\n  author={self.author}\\n  \"\"\"\\\n",
    "               f\"\"\"time={self.time}\\n  {self.text[:100]}...\"\"\"\n",
    "        \n",
    "        \n",
    "def get_lenta_article(url: str) -> LentaArticle:\n",
    "    page = requests.get(url)\n",
    "    tree = html.fromstring(page.text)\n",
    "    article = LentaArticle(\n",
    "            tree.xpath(\".//h1\")[0].text_content(),\n",
    "            tree.xpath(\".//div[contains(@class, 'topic-authors')]\")[0].text_content().strip(),\n",
    "            tree.xpath(\".//meta[@property='og:description']\")[0].get(\"content\"),\n",
    "            tree.xpath(\".//time[contains(@class, 'topic-header__time')]\")[0].text_content().strip(), \n",
    "            '\\n'.join([p.text_content() for p in \n",
    "                tree.xpath(\".//div[contains(@class, '_news')]//p[contains(@class, 'topic-body__content-text')]\")]\n",
    "                    )\n",
    "           )\n",
    "    \n",
    "    return article\n",
    "\n",
    "get_lenta_article('https://lenta.ru/news/2021/02/27/apple_effect/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î–µ–∫–æ—Ä–∞—Ç–æ—Ä `@dataclass` –æ–±–ª–∞–¥–∞–µ—Ç —Ü–µ–ª—ã–º —Ä—è–¥–æ–º –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, –ø–æ–º–æ–≥–∞—é—â–∏—Ö –ø—Ä–æ—â–µ —Ä–µ—à–∞—Ç—å –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –∑–∞–¥–∞—á–∏. \n",
    "\n",
    "`frozen=True` - –≤ –æ–±—ä–µ–∫—Ç—ã –Ω–µ–ª—å–∑—è –±—É–¥–µ—Ç –¥–æ–±–∞–≤–ª—è—Ç—å –Ω–æ–≤—ã–µ –∞—Ç—Ä–∏–±—É—Ç—ã.  \n",
    "`init, repr, eq, order =True` - –∑–∞–≤–æ–¥—è—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä, –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è, —ç–∫–≤–∏–≤–∞–ª–µ–Ω—Ç–Ω–æ—Å—Ç–∏, —Å—Ä–∞–≤–Ω–µ–Ω–∏—è."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "FrozenInstanceError",
     "evalue": "cannot assign to field 'newOne'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFrozenInstanceError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_75332/4180302307.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0maaa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLentaArticleFrozen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0maaa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewOne\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n",
      "\u001b[0;31mFrozenInstanceError\u001b[0m: cannot assign to field 'newOne'"
     ]
    }
   ],
   "source": [
    "@dataclass(frozen=True)\n",
    "class LentaArticleFrozen:\n",
    "    title: str = \"\"\n",
    "    text: str = \"\"\n",
    "    description: str = \"\"\n",
    "    time: str = \"00:00\"\n",
    "    author: str = \"No author\"\n",
    "        \n",
    "aaa = LentaArticleFrozen()\n",
    "aaa.newOne = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ó–∞–ø—É—Å—Ç–∏–º –≤–æ—Ç —Ç–∞–∫–æ–π –∫–æ–¥. –ò —á—Ç–æ –º—ã —É–≤–∏–¥–∏–º?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "mutable default <class 'list'> for field author is not allowed: use default_factory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_75332/662127301.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mdataclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mLentaArticleMAuthors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtitle\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdescription\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/dataclasses.py\u001b[0m in \u001b[0;36mwrap\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m   1173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1175\u001b[0;31m         return _process_class(cls, init, repr, eq, order, unsafe_hash,\n\u001b[0m\u001b[1;32m   1176\u001b[0m                               frozen, match_args, kw_only, slots)\n\u001b[1;32m   1177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/dataclasses.py\u001b[0m in \u001b[0;36m_process_class\u001b[0;34m(cls, init, repr, eq, order, unsafe_hash, frozen, match_args, kw_only, slots)\u001b[0m\n\u001b[1;32m    953\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m             \u001b[0;31m# Otherwise it's a field of some type.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 955\u001b[0;31m             \u001b[0mcls_fields\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_field\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    956\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls_fields\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/dataclasses.py\u001b[0m in \u001b[0;36m_get_field\u001b[0;34m(cls, a_name, a_type, default_kw_only)\u001b[0m\n\u001b[1;32m    810\u001b[0m     \u001b[0;31m# For real fields, disallow mutable defaults for known types.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_field_type\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0m_FIELD\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 812\u001b[0;31m         raise ValueError(f'mutable default {type(f.default)} for field '\n\u001b[0m\u001b[1;32m    813\u001b[0m                          f'{f.name} is not allowed: use default_factory')\n\u001b[1;32m    814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: mutable default <class 'list'> for field author is not allowed: use default_factory"
     ]
    }
   ],
   "source": [
    "@dataclass()\n",
    "class LentaArticleMAuthors:\n",
    "    title: str\n",
    "    text: str\n",
    "    description: str\n",
    "    time: str = \"00:00\"\n",
    "    author: str = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. –ù–∏–∫—Ç–æ –Ω–µ —Å–ª–µ–¥–∏—Ç –∑–∞ —Ç–∏–ø–∞–º–∏ –∑–Ω–∞—á–µ–Ω–∏–π.\n",
    "2. –ü—Ä–∏—Å–≤–∞–∏–≤–∞—Ç—å –º—É—Ç–∞–±–µ–ª—å–Ω—ã–µ —Ç–∏–ø—ã –Ω–µ–ª—å–∑—è. –ü—Ä–µ–¥–ª–∞–≥–∞—é—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å `default_factory`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import field\n",
    "\n",
    "@dataclass()\n",
    "class LentaArticleMAuthors:\n",
    "    title: str\n",
    "    text: str\n",
    "    description: str\n",
    "    time: str = \"00:00\"\n",
    "    author: list[str] = field(default_factory=list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__annotations__',\n",
       " '__class__',\n",
       " '__dataclass_fields__',\n",
       " '__dataclass_params__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__match_args__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'tttt']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class My2:\n",
    "    ttt = []\n",
    "    \n",
    "@dataclass\n",
    "class My3:\n",
    "    tttt: My2 = My2\n",
    "        \n",
    "aaa = My3()\n",
    "dir(aaa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ê —Ç–µ–ø–µ—Ä—å –Ω–∞—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ö–ª–∞—Å—Å –º–æ–∂–µ—Ç –Ω–∞—Å–ª–µ–¥–æ–≤–∞—Ç—å—Å—è (–±—ã—Ç—å *–Ω–∞—Å–ª–µ–¥–Ω–∏–∫–æ–º* –∏–ª–∏ *–¥–æ—á–µ—Ä–Ω–∏–º –∫–ª–∞—Å—Å–æ–º*) –æ—Ç –¥—Ä—É–≥–æ–≥–æ –∫–ª–∞—Å—Å–∞ (*–±–∞–∑–æ–≤–æ–≥–æ* –∏–ª–∏ *—Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–æ–≥–æ*). –í —ç—Ç–æ–º —Å–ª—É—á–∞–µ –æ–Ω –ø–æ–ª—É—á–∞–µ—Ç –≤—Å–µ –º–µ—Ç–æ–¥—ã –∏ —Å–≤–æ–π—Å—Ç–≤–∞, –∫–æ—Ç–æ—Ä—ã–µ –±—ã–ª–∏ —É –±–∞–∑–æ–≤–æ–≥–æ –∫–ª–∞—Å—Å–∞. –û–Ω –º–æ–∂–µ—Ç –¥–æ–±–∞–≤–ª—è—Ç—å –Ω–æ–≤—ã–µ –º–µ—Ç–æ–¥—ã –∏ —Å–≤–æ–π—Å—Ç–≤–∞, –∞ —Ç–∞–∫–∂–µ –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è—Ç—å —Å—Ç–∞—Ä—ã–µ.\n",
    "\n",
    "–î–ª—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –±–∞–∑–æ–≤–æ–≥–æ –∫–ª–∞—Å—Å–∞ –≤ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä–µ —Å–ª–µ–¥—É–µ—Ç –≤—ã–∑—ã–≤–∞—Ç—å `–ò–º—è–ë–∞–∑–æ–≤–æ–≥–æ–ö–ª–∞—Å—Å–∞.__init__(self)` –∏–ª–∏ (—á—Ç–æ –≥–æ—Ä–∞–∑–¥–æ –ª—É—á—à–µ) `super().__init__()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A: # –ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å.\n",
    "    def __init__(self):\n",
    "        self.asd = \"\"\n",
    "        self.zxc = 0.0\n",
    "        \n",
    "    def ret_asd(self):\n",
    "        return self.asd\n",
    "    \n",
    "    def ret_zxc(self):\n",
    "        return self.zxc\n",
    "    \n",
    "class B(A): # –ù–æ–≤—ã–π –∫–ª–∞—Å—Å –í, –∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ—Ç –Ω–∞—Å–ª–µ–¥–Ω–∏–∫–æ–º –ê.\n",
    "    def __init__(self):\n",
    "#         self.zxc = 0.0\n",
    "        A.__init__(self)\n",
    "        self.asd = \"1\"\n",
    "        self.qwe = 0\n",
    "        \n",
    "    def ret_qwe(self): # –ù–æ–≤–∞—è —Ñ—É–Ω–∫—Ü–∏—è.\n",
    "        return self.qwe\n",
    "    \n",
    "    def ret_asd(self): # –ü–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ–≤–µ–¥–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ –≤ –¥–∞–Ω–Ω–æ–º –∫–ª–∞—Å—Å–µ.\n",
    "        return self.asd + '1'\n",
    "    \n",
    "class C(B):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.zxc = 0.0\n",
    "        self.asd = \"2\"\n",
    "        self.qwe = 0\n",
    "        self.poi = 100\n",
    "        \n",
    "    def ret_poi(self):\n",
    "        return self.poi\n",
    "\n",
    "#     def ret_asd(self):\n",
    "#         return self.asd + '2'\n",
    "    \n",
    "    \n",
    "class D(C, B): # –ù–∞—Å–ª–µ–¥–æ–≤–∞—Ç—å—Å—è –º–æ–∂–Ω–æ –æ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∫–ª–∞—Å—Å–æ–≤.\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa = A()\n",
    "bbb = B()\n",
    "ccc = C()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('11', '', 0.0, 0.0, '21')"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbb.ret_asd(), aaa.ret_asd(), aaa.ret_zxc(), bbb.ret_zxc(), ccc.ret_asd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(__main__.C, __main__.A, __main__.B, object)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class A:\n",
    "    def first(self):\n",
    "        print('A')\n",
    "        \n",
    "class B:\n",
    "    def first(self):\n",
    "        print('B')\n",
    "        \n",
    "class C(A, B):\n",
    "    pass\n",
    "\n",
    "c = C()\n",
    "c.first()\n",
    "C.__mro__ # –í –∫–∞–∫–æ–º –ø–æ—Ä—è–¥–∫–µ –æ–Ω –±—É–¥–µ—Ç –∏—Å–∫–∞—Ç—å —Ñ—É–Ω–∫—Ü–∏–∏."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü—É—Å—Ç—å —É –Ω–∞—Å –µ—Å—Ç—å –¥–≤–∞ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞ –∫–æ–¥–∞, –∫–æ—Ç–æ—Ä—ã–µ –≤—ã–∫–∞—á–∏–≤–∞—é—Ç –õ–µ–Ω—Ç—É.—Ä—É –∏ N+1. –ö–∞–∫ —ç—Ç–æ –≤—ã–≥–ª—è–¥–∏—Ç –ø–æ–∫–∞–∑–∞–Ω–æ –Ω–∏–∂–µ. –î–∞–≤–∞–π—Ç–µ –ø–æ–ø—ã—Ç–∞–µ–º—Å—è —Å–¥–µ–ª–∞—Ç—å —á—Ç–æ-—Ç–æ –ø–æ–ª—É—á—à–µ —Å —É—á–µ—Ç–æ–º —Ç–æ–≥–æ, —á—Ç–æ –Ω–∞ —Å–≤–µ—Ç–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –Ω–∞—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re # –†–µ–≥—É–ª—è—Ä–Ω—ã–µ –≤—ã—Ä–∞–∂–µ–Ω–∏—è.\n",
    "import requests # –ó–∞–≥—Ä—É–∑–∫–∞ –Ω–æ–≤–æ—Å—Ç–µ–π —Å —Å–∞–π—Ç–∞.\n",
    "from bs4 import BeautifulSoup # –ü—Ä–µ–≤—Ä–∞—â–∞–ª–∫–∞ html –≤ —Ç–µ–∫—Å—Ç.\n",
    "import pymorphy2 # –ú–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä.\n",
    "import datetime # –ù–æ–≤–æ—Å—Ç–∏ –±—É–¥–µ–º –ø–µ—Ä–µ–±–∏—Ä–∞—Ç—å –ø–æ –¥–∞—Ç–µ.\n",
    "from collections import Counter # –ù–µ —Å—á–∏—Ç–∞—Ç—å –∂–µ —á–∞—Å—Ç–æ—Ç—ã —Å–∞–º–∏–º.\n",
    "import math # –ö–æ—Ä–µ–Ω—å –∫–≤–∞–¥—Ä–∞—Ç–Ω—ã–π."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–≠—Ç–æ –∫–ª–∞—Å—Å –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –õ–µ–Ω—Ç—ã.—Ä—É. –û–Ω –ø–æ–∑–≤–æ–ª—è–µ—Ç –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å—Ç–∞—Ç—å–∏ —Å —Å–∞–π—Ç–∞, —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –∏—Ö –≤ —Ñ–∞–π–ª —Å—á–∏—Ç–∞—Ç—å —ç—Ç–æ—Ç —Ñ–∞–π–ª, —Å–æ–∑–¥–∞—Ç—å —á–∞—Å—Ç–æ—Ç–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å –Ω–æ–≤–æ—Å—Ç–µ–π.\n",
    "\n",
    "–ö–ª–∞—Å—Å —Ö—Ä–∞–Ω–∏—Ç –≤—Å–µ –Ω–æ–≤–æ—Å—Ç–∏, –∑–∞–≥–æ–ª–æ–≤–∫–∏ –∏ —Å–ª–æ–≤–∞—Ä–∏ –≤ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö —Å–ø–∏—Å–∫–∞—Ö."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class getNewsPaper:\n",
    "        \n",
    "    # –ö–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä - –≤—ã–∑—ã–≤–∞–µ—Ç—Å—è –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –æ–±—ä–µ–∫—Ç–∞ –∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –µ–≥–æ.\n",
    "    def __init__(self, filename=None):\n",
    "        self.articles = []     # –ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ —Å—Ç–∞—Ç—å–∏.\n",
    "        self.titles = []       # –ó–∞–≥–æ–ª–æ–≤–∫–∏ —Å—Ç–∞—Ç–µ–π.\n",
    "        self.dictionaries = [] # –°–ª–æ–≤–∞—Ä–∏ –¥–ª—è –∫–∞–∂–¥–æ–π –∏–∑ —Å—Ç–∞—Ç–µ–π.\n",
    "        # –°–æ–∑–¥–∞–µ–º –∏ –∑–∞–≥—Ä—É–∂–∞–µ–º –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —Å–ª–æ–≤–∞—Ä—å.\n",
    "        self.morph = pymorphy2.MorphAnalyzer()\n",
    "        if filename != None:\n",
    "            self.loadArticles(filename)\n",
    "\n",
    "    # –ó–∞–≥—Ä—É–∑–∫–∞ —Å—Ç–∞—Ç—å–∏ –ø–æ URL.\n",
    "    def getLentaArticle(self, url):\n",
    "        \"\"\" getLentaArticle gets the body of an article from Lenta.ru\"\"\"\n",
    "        # –ü–æ–ª—É—á–∞–µ—Ç —Ç–µ–∫—Å—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—ã.\n",
    "        resp = requests.get(url)\n",
    "        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–µ–∫—Å—Ç –≤ –æ–±—ä–µ–∫—Ç —Ç–∏–ø–∞ BeautifulSoup.\n",
    "        bs = BeautifulSoup(resp.text, \"html5lib\") \n",
    "        # –ü–æ–ª—É—á–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Å—Ç–∞—Ç—å–∏.\n",
    "        self.titles.append(bs.h1.text.replace(\"\\xa0\", \" \"))\n",
    "        # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç —Å—Ç–∞—Ç—å–∏.\n",
    "        self.articles.append(BeautifulSoup(\" \".join(\n",
    "                    [p.text for p in bs.find_all(\"p\")]), \"html5lib\").get_text().replace(\"\\xa0\", \" \"))\n",
    "\n",
    "    # –ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö —Å—Ç–∞—Ç–µ–π –∑–∞ –æ–¥–∏–Ω –¥–µ–Ω—å.\n",
    "    def getLentaDay(self, url):\n",
    "        \"\"\" Gets all URLs for a given day and gets all texts. \"\"\"\n",
    "        try:\n",
    "            # –ì—Ä—É–∑–∏–º —Å—Ç—Ä–∞–Ω–∏—Ü—É —Å–æ —Å–ø–∏—Å–∫–æ–º –≤—Å–µ—Ö —Å—Ç–∞—Ç–µ–π.\n",
    "            day = requests.get(url) \n",
    "            # –ü–æ–ª—É—á–∞–µ–º —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã —Å –Ω—É–∂–Ω—ã–º–∏ –Ω–∞–º –∞–¥—Ä–µ—Å–∞–º–∏ —Å—Ç–∞—Ç–µ–π.\n",
    "            h3s = BeautifulSoup(day.text, \"html5lib\").find_all(\"h3\")\n",
    "            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∞–¥—Ä–µ—Å–∞ –Ω–∞ —Å—Ç–∞—Ç—å–∏ –∑–∞ –¥–µ–Ω—å.\n",
    "            links = [\"http://lenta.ru\"+l.find_all(\"a\")[0][\"href\"] for l in h3s]\n",
    "            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—Ç–∞—Ç—å–∏.\n",
    "            for l in links:\n",
    "                self.getLentaArticle(l)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # –ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö —Å—Ç–∞—Ç–µ–π –∑–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ –¥–Ω–µ–π.\n",
    "    def getLentaPeriod(self, start, finish):\n",
    "        curdate = start\n",
    "        while curdate <= finish:\n",
    "            print(curdate.strftime('%Y/%m/%d')) # Just in case.\n",
    "            # –°–ø–∏—Å–æ–∫ —Å—Ç–∞—Ç–µ–π –≥—Ä—É–∑–∏—Ç—Å—è —Å –≤–æ—Ç —Ç–∞–∫–æ–≥–æ –∞–¥—Ä–µ—Å–∞.\n",
    "            self.getLentaDay(f\"https://lenta.ru/news/{curdate.strftime('%Y/%m/%d')}\")\n",
    "            curdate += datetime.timedelta(days=1)\n",
    "\n",
    "    # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–∞ –¥–ª—è —Å—Ç–∞—Ç—å–∏.\n",
    "    posConv = {'ADJF': '_ADJ', 'NOUN': '_NOUN', 'VERB': '_VERB'}\n",
    "    def getArticleDictionary(self, text, needPos=None):\n",
    "        words = [a[0] for a in re.findall(\"([–ê-–Ø–Å–∞-—è—ë]+(-[–ê-–Ø–Å–∞-—è—ë]+)*)\", text)]\n",
    "        reswords = []\n",
    "    \n",
    "        for w in words:\n",
    "            wordform = self.morph.parse(w)[0]\n",
    "            try:\n",
    "                if wordform.tag.POS in ['ADJF', 'NOUN', 'VERB']:\n",
    "                    if needPos != None:\n",
    "                        reswords.append(wordform.normal_form+self.posConv[wordform.tag.POS])\n",
    "                    else:\n",
    "                        reswords.append(wordform.normal_form)\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "        stat = Counter(reswords)\n",
    "        # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ —Å–ª–æ–≤–∞ —Å —á–∞—Å—Ç–æ—Ç–æ–π –±–æ–ª—å—à–µ 1.\n",
    "        stat = {a: stat[a] for a in stat.keys() if stat[a]>1}\n",
    "        return stat\n",
    "\n",
    "    # –ü–æ—Å—á–∏—Ç–∞–µ–º –≤–µ–∫—Ç–æ—Ä–∞ –¥–ª—è –≤—Å–µ—Ö —Å—Ç–∞—Ç–µ–π.\n",
    "    def calcArticleDictionaries(self, needPos=None):\n",
    "        self.dictionaries = []\n",
    "        for a in self.articles:\n",
    "            self.dictionaries.append(self.getArticleDictionary(a, needPos))\n",
    "            \n",
    "    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç–∞—Ç—å–∏ –≤ —Ñ–∞–π–ª.\n",
    "    def saveArticles(self, filename):\n",
    "        \"\"\" Saves all articles to a file with a filename. \"\"\"\n",
    "        newsfile = open(filename, \"w\")\n",
    "        for art, titl in zip(self.articles, self.titles):\n",
    "            newsfile.write('\\n=====\\n'+titl)\n",
    "            newsfile.write('\\n-----\\n'+art)\n",
    "        newsfile.close()\n",
    "\n",
    "    # –ß–∏—Ç–∞–µ–º —Å—Ç–∞—Ç—å–∏ –∏–∑ —Ñ–∞–π–ª–∞.\n",
    "    def loadArticles(self, filename):\n",
    "        \"\"\" Loads and replaces all articles from a file with a filename. \"\"\"\n",
    "        newsfile = open(filename, encoding=\"utf-8\")\n",
    "        text = newsfile.read()\n",
    "        self.articles = text.split('\\n=====\\n')[1:]\n",
    "        for i, a in enumerate(self.articles):\n",
    "            b, self.articles[i] = a.split('\\n-----\\n')\n",
    "            self.titles.append(b)\n",
    "        newsfile.close()\n",
    "\n",
    "    # –î–ª—è —É–¥–æ–±—Å—Ç–≤–∞ - –ø–æ–∏—Å–∫ —Å—Ç–∞—Ç—å–∏ –ø–æ –µ–µ –∑–∞–≥–æ–ª–æ–≤–∫—É.\n",
    "    def findNewsByTitle(self, title):\n",
    "        if title in self.titles:\n",
    "            return self.titles.index(title)\n",
    "        else:\n",
    "            return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–≠—Ç–æ –∫–ª–∞—Å—Å –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ —Å–∞–π—Ç–∞ N+1.ru. –ï–≥–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –æ—á–µ–Ω—å —Å–∏–ª—å–Ω–æ —Å—Ö–æ–∂–∞ —Å–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π –õ–µ–Ω—Ç—ã.—Ä—É, –∏–º–µ–Ω–Ω–æ –ø–æ—ç—Ç–æ–º—É –º—ã –µ–≥–æ –∏ –±–µ—Ä–µ–º. \n",
    "\n",
    "–ó–¥–µ—Å—å –∑–∞–≤–µ–¥–µ–Ω —Ç–∏–ø –ø–æ–¥ –Ω–æ–≤–æ—Å—Ç–Ω—É—é –∑–∞–º–µ—Ç–∫—É, —Ç–∞–∫ –∫–∞–∫ –¥–ª—è –Ω–µ–µ —Ö—Ä–∞–Ω–∏—Ç—Å—è –≥–æ—Ä–∞–∑–¥–æ –±–æ–ª—å—à–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏: –≤—Ä–µ–º—è, –¥–∞—Ç–∞, —Ä—É–±—Ä–∏–∫–∞, —Å–ª–æ–∂–Ω–æ—Å—Ç—å, –∞–≤—Ç–æ—Ä, –∑–∞–≥–æ–ª–æ–≤–æ–∫, —Ç–µ–∫—Å—Ç. –ü–æ–º–∏–º–æ —ç—Ç–æ–≥–æ, —Å—Ç–∞—Ç—å—è —É–º–µ–µ—Ç —Å–æ—Ö—Ä–∞–Ω—è—Ç—å —Å–µ–±—è –≤ [JSON](https://ruseller.com/lessons.php?id=1212) (–±–µ–∑ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–π [–±–∏–±–ª–∏–æ—Ç–µ–∫–∏](https://pythonworld.ru/moduli/modul-json.html)) –∏ —Å–ª–æ–≤–∞—Ä—å –ü–∏—Ç–æ–Ω–∞.\n",
    "\n",
    "–î–∞–ª—å—à–µ –∏–¥—É—Ç –¥–≤–µ —Ñ—É–Ω–∫—Ü–∏–∏, –∫–æ—Ç–æ—Ä—ã–µ –≤—ã–≥—Ä—É–∂–∞—é—Ç –æ—Ç–¥–µ–ª—å–Ω—É—é —Å—Ç–∞—Ç—å—é –∏ –≤—Å–µ —Å—Ç–∞—Ç—å–∏ –∑–∞ –¥–µ–Ω—å."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "delcom=re.compile(\"<!--.+-->\", re.S)\n",
    "\n",
    "# –ö–ª–∞—Å—Å, —Ö—Ä–∞–Ω—è—â–∏–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å—Ç–∞—Ç—å–µ.\n",
    "class NPlus1Article:\n",
    "    def __init__(self):\n",
    "        self.time = \"\"\n",
    "        self.date = \"\"\n",
    "        self.rubr = \"\"\n",
    "        self.diff = \"\"\n",
    "        self.author = \"\"\n",
    "        self.title = \"\"\n",
    "        self.text = \"\"\n",
    "        \n",
    "    # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ JSON.\n",
    "    def toJSON(self):\n",
    "        res = f'{{\"date\":\"{self.date}\", \"time\":\"{self.time}\", \"rubrics\":\"{self.rubr}\", \"difficulty\":\"'\\\n",
    "              f'{self.diff}\", \"title\":\"{self.head}\", \"author\":\"{self.author}\",\"text\":\"'\n",
    "        res += self.text.replace('\"', '\\\\\"') + '\"}'\n",
    "        return res\n",
    "\n",
    "    # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ —Å–ª–æ–≤–∞—Ä—å.\n",
    "    def toDict(self):\n",
    "        res={\"date\": self.date, \"time\": self.time, \"rubrics\": self.rubr, \"difficulty\": self.diff, \\\n",
    "             \"title\" :self.head, \"author\": self.author,\"text\": self.text.replace('\"', '\\\\\"')}\n",
    "        return res\n",
    "    \n",
    "def getArticleTextNPlus1(adr):\n",
    "    r = requests.get(adr)\n",
    "    #print(r.text)\n",
    "    art = NPlus1Article()\n",
    "    tables = re.split(\"</div>\",re.split('=\"tables\"', r.text)[1])[0]\n",
    "    t1 = re.split(\"</time>\", re.split(\"<time\", tables)[1])[0]\n",
    "    art.time = re.split(\"</span>\", re.split(\"<span>\", t1)[1])[0]\n",
    "    art.date = re.split(\"</span>\", re.split(\"<span>\", t1)[2])[0]\n",
    "    art.rubr = re.findall(\"<a data-rubric.+?>(.+?)</a>\", r.text)[0]\n",
    "    art.diff = re.split(\"</span>\", re.split('\"difficult-value\">', tables)[1])[0]\n",
    "    art.head = re.split(\"</h1>\",re.split('<h1>', r.text)[1])[0]\n",
    "    art.author = re.split('\" />',re.split('<meta name=\"author\" content=\"', r.text)[1])[0]\n",
    "    art.text = re.split(\"</div>\", re.split(\"</figure>\", re.split('</article>',re.split('<article', r.text)[1])[0])[1])[1]    \n",
    "\n",
    "    beaux_text = BeautifulSoup(art.text, \"html5lib\")\n",
    "    art.text = delcom.sub(\"\", beaux_text.get_text() )\n",
    "    art.text = art.text.replace('\\xa0', ' ')\n",
    "\n",
    "    return art\n",
    "\n",
    "def getDayArticles(adr):\n",
    "    r = requests.get(adr)\n",
    "    titles = BeautifulSoup(r.text, \"html5lib\")(\"article\")\n",
    "    addrs = [\"https://nplus1.ru/\"+a(\"a\")[0][\"href\"] for a in titles]\n",
    "    articles = []\n",
    "    for adr in addrs:\n",
    "        articles.append(getArticleTextNPlus1(adr))\n",
    "    return articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î–∞–≤–∞–π—Ç–µ –¥–ª—è –Ω–∞—á–∞–ª–∞ –æ—Ç–∫–∞–∂–µ–º—Å—è –æ—Ç –∫–ª–∞—Å—Å–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –≤—ã–∫–∞—á–∏–≤–∞—é—Ç –¥–∞–Ω–Ω—ã–µ, –∏ —Å–æ—Å—Ä–µ–¥–æ—Ç–æ—á–∏–º—Å—è –Ω–∞ —Å–∞–º–∏—Ö –¥–∞–Ω–Ω—ã—Ö, –∫–æ—Ç–æ—Ä—ã–µ –æ–Ω–∏ –≤–æ–∑–≤—Ä–∞—â–∞—é—Ç. –î–∞–≤–∞–π—Ç–µ —Å—á–∏—Ç–∞—Ç—å, —á—Ç–æ –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∏ —Ç–µ–∫—Å—Ç –µ—Å—Ç—å —É –ª—é–±–æ–π —Å—Ç–∞—Ç—å–∏, –∞ –≤—Å—ë –æ—Å—Ç–∞–ª—å–Ω–æ–µ - —ç—Ç–æ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –¥–µ—Ç–∞–ª–∏, –∑–∞–≤–∏—Å—è—â–∏–µ –æ—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Å–∞–π—Ç–∞.\n",
    "\n",
    "–°–æ–∑–¥–∞–¥–∏–º –∫–ª–∞—Å—Å –±–∞–∑–æ–≤–æ–π —Å—Ç–∞—Ç—å–∏, –∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å –≤ —Å–µ–±–µ —Ç–æ–ª—å–∫–æ –¥–≤–∞ –ø–æ–ª—è. [–£–Ω–∞—Å–ª–µ–¥—É–µ–º](https://o7planning.org/ru/11417/inheritance-and-polymorphism-in-python) –æ—Ç –Ω–µ–≥–æ –∫–ª–∞—Å—Å —Å—Ç–∞—Ç—å–∏ –¥–ª—è N+1 - NPlus1Article. –¢–µ–ø–µ—Ä—å –º–æ–∂–Ω–æ —Å—á–∏—Ç–∞—Ç—å, —á—Ç–æ –ª—é–±–∞—è —Ñ—É–Ω–∫—Ü–∏—è –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–±—ä–µ–∫—Ç, –∫–æ—Ç–æ—Ä—ã–π –≤–µ–¥–µ—Ç —Å–µ–±—è –∫–∞–∫ –æ–±—ä–µ–∫—Ç BaseArticle - —É –Ω–µ–≥–æ –µ—Å—Ç—å –ø–æ–ª—è title –∏ text.\n",
    "\n",
    "–í –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä–µ NPlus1Article –≤—ã–∑—ã–≤–∞–µ—Ç—Å—è –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä –±–∞–∑–æ–≤–æ–≥–æ –∫–ª–∞—Å—Å–∞. –ü—Ä–∏ –ø–æ–º–æ—â–∏ —Ñ—É–Ω–∫—Ü–∏–∏ `super()` –º—ã –æ–±—Ä–∞—â–∞–µ–º—Å—è –∫ –æ–±—ä–µ–∫—Ç—ã –∫–∞–∫ –∫ –æ–±—ä–µ–∫—Ç—É —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–æ–≥–æ –∫–ª–∞—Å—Å–∞ (–Ω–∞–º –¥–∞–∂–µ –Ω–µ –≤–∞–∂–Ω–æ –∑–Ω–∞—Ç—å –∫–∞–∫–æ–≥–æ).\n",
    "\n",
    "----\n",
    "\n",
    "–í–æ–æ–±—â–µ, –Ω–∞—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –¥–ª—è —Ç—Ä–µ—Ö –≤–µ—â–µ–π:\n",
    "- —Ä–∞—Å—à–∏—Ä–∏—Ç—å —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª –∏–ª–∏ –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –∏–º–µ—é—â–µ–≥–æ—Å—è –∫–ª–∞—Å—Å–∞;\n",
    "- –≤–∑—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –∫–ª–∞—Å—Å–æ–≤ —Å –æ–±—â–µ–π —á–∞—Å—Ç—å—é –∏ –≤—ã–¥–µ–ª–∏—Ç—å –µ–µ –≤ –µ–¥–∏–Ω—ã–π –±–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å **—Å –≤—ã–¥–µ–ª–µ–Ω–∏–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–π —Å—É—â–Ω–æ—Å—Ç–∏**.\n",
    "- –æ–±–µ—Å–ø–µ—á–∏—Ç—å –µ–¥–∏–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –∫–ª–∞—Å—Å–æ–≤-–Ω–∞—Å–ª–µ–¥–Ω–∏–∫–æ–≤ (—ç—Ç–æ —Å–∫–æ—Ä–µ–µ –ø–æ–¥—Ö–æ–¥ –¥–ª—è [—è–∑—ã–∫–æ–≤ –≥—Ä—É–ø–ø—ã –í–∏—Ä—Ç–∞](https://habr.com/ru/post/303380/), –≤ –ü–∏—Ç–æ–Ω–µ —á–∞—Å—Ç–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –ø–æ –¥–æ–≥–æ–≤–æ—Ä–µ–Ω–Ω–æ—Å—Ç–∏, –Ω–æ –Ω–∞—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ–º–æ–≥–∞–µ—Ç —É–ø—Ä–æ—Å–∏—Ç—å –ø–æ–Ω–∏–º–∞–Ω–∏–µ)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ß—Ç–æ —Ç–∞–∫–æ–µ [super](https://habr.com/ru/company/skillfactory/blog/683744/)? –ò–ª–∏ [–≤–æ—Ç](https://habr.com/ru/company/piter/blog/592127/). –ò–ª–∏ –∏–∑ —á–µ–≥–æ –ø–æ—Å—Ç–∞—Ä—à–µ, –Ω–æ [–ø–æ–ø—Ä–æ—â–µ](https://habr.com/ru/post/62203/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü–æ—á–µ–º—É –±—ã –Ω–µ –ø–æ–ª–æ–∂–∏—Ç—å —Å—é–¥–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ —Å–ª–æ–≤–∞—Ä—å –∏ \n",
    "class BaseArticle:\n",
    "    def __init__(self):\n",
    "        print(type(super()))\n",
    "        self.title=\"\"\n",
    "        self.text=\"\"\n",
    "        \n",
    "    def getSuper3(self):\n",
    "        return super()\n",
    "        \n",
    "class NPlus1Article(BaseArticle):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.title += \"---\"\n",
    "        self.time=\"\"\n",
    "        self.date=\"\"\n",
    "        self.rubr=\"\"\n",
    "        self.diff=\"\"\n",
    "        self.author=\"\"\n",
    "        \n",
    "    def getSuper(self):\n",
    "        return super(NPlus1Article, self)\n",
    "        \n",
    "    def getSuper2(self):\n",
    "        return super(BaseArticle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'super'>\n"
     ]
    }
   ],
   "source": [
    "rrr = BaseArticle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<super: __main__.NPlus1Article, <__main__.NPlus1Article at 0x7f265daf9100>>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rr = NPlus1Article()\n",
    "rr.getSuper()\n",
    "#dir(rr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.NPlus1Article at 0x7fad00adc6a0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'super'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rr2=NPlus1Article()\n",
    "rr2.getSuper3().__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(rr2.__class__)#.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.NPlus1Article at 0x7fad00af0b70>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rr3 = rr2.__class__()\n",
    "rr3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<super: __main__.NPlus1Article, <__main__.NPlus1Article at 0x7fad00af0a90>>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rr4 = rr2.getSuper()\n",
    "rr4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'author',\n",
       " 'date',\n",
       " 'diff',\n",
       " 'getSuper',\n",
       " 'rubr',\n",
       " 'time']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(NPlus1Article())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û—Ñ–æ—Ä–º–∏–º –∑–∞–≥—Ä—É–∑–∫—É —Å—Ç–∞—Ç–µ–π –∫–∞–∫ —Ñ—É–Ω–∫—Ü–∏–∏ –∏ –Ω–∞–ø–∏—à–µ–º –µ—â–µ –æ–¥–Ω—É, –∫–æ—Ç–æ—Ä–∞—è –≤—ã–≥—Ä—É–∂–∞–µ—Ç —Å—Ç–∞—Ç—å—é –≤ JSON, —Å–ø–∏—Å–æ–∫ –≤—ã–≥—Ä—É–∂–∞–µ–º—ã—Ö –ø–æ–ª–µ–π –∑–∞–≤–∏—Å–∏—Ç –æ—Ç —Ç–∏–ø–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–∏–ø–∞ –ø—Ä–æ–≤–æ–¥–∏—Ç—Å—è –ø—Ä–∏ –ø–æ–º–æ—â–∏ —Ñ—É–Ω–∫—Ü–∏–∏ `isinstance`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getArticleTextNPlus1(adr):\n",
    "    r = requests.get(adr)\n",
    "    #print(r.text)\n",
    "    art = NPlus1Article()\n",
    "#     tables = re.split(\"</div>\",re.split('=\"tables\"', r.text)[1])[0]\n",
    "#     t1 = re.split(\"</time>\", re.split(\"<time\", tables)[1])[0]\n",
    "#     art.time = re.split(\"</span>\", re.split(\"<span>\", t1)[1])[0]\n",
    "    art.time = \"12.34.5678\"\n",
    "#     art.date = re.split(\"</span>\", re.split(\"<span>\", t1)[2])[0]\n",
    "    art.date = \"1234\"\n",
    "#     art.rubr = re.findall(\"<a data-rubric.+?>(.+?)</a>\", r.text)[0]\n",
    "    art.rubr = \"7hfgedgtr\"\n",
    "#     art.diff = re.split(\"</span>\", re.split('\"difficult-value\">', tables)[1])[0]\n",
    "    art.diff = \"5\"\n",
    "#     art.head = re.split(\"</h1>\",re.split('<h1>', r.text)[1])[0]\n",
    "    art.head = \"header\"\n",
    "#     art.author = re.split('\" />',re.split('<meta name=\"author\" content=\"', r.text)[1])[0]\n",
    "    art.author = \"ivanoff\"\n",
    "#     art.text = re.split(\"</div>\", re.split(\"</figure>\", re.split('</article>',re.split('<article', r.text)[1])[0])[1])[1]    \n",
    "    art.text = \"Some text\"\n",
    "\n",
    "#     beaux_text = BeautifulSoup(art.text, \"html5lib\")\n",
    "#     art.text = delcom.sub(\"\", beaux_text.get_text() )\n",
    "#     art.text = art.text.replace('\\xa0', ' ')\n",
    "\n",
    "    # print(art.n_time, art.n_date, art.n_rubr, art.n_diff)\n",
    "    # print(art.n_head)\n",
    "    # print(art.n_author)\n",
    "    # print(art.n_text)\n",
    "    #return [n_time, n_date, n_rubr, n_diff, n_author, n_head, n_text]\n",
    "    return art\n",
    "\n",
    "def getLentaArticle(url):\n",
    "    \"\"\" getLentaArticle gets the body of an article from Lenta.ru\"\"\"\n",
    "    # –ü–æ–ª—É—á–∞–µ—Ç —Ç–µ–∫—Å—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—ã.\n",
    "    resp=requests.get(url)\n",
    "    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–µ–∫—Å—Ç –≤ –æ–±—ä–µ–∫—Ç —Ç–∏–ø–∞ BeautifulSoup.\n",
    "    bs=BeautifulSoup(resp.text, \"html5lib\")\n",
    "    art=BaseArticle()\n",
    "    art.title=bs.h1.text.replace(\"\\xa0\", \" \")\n",
    "    art.text=BeautifulSoup(\" \".join([p.text for p in bs.find_all(\"p\")]), \"html5lib\").get_text().replace(\"\\xa0\", \" \")\n",
    "    return art\n",
    "\n",
    "def articleToJSON(art):\n",
    "    # –ó–¥–µ—Å—å —Å–¥–µ–ª–∞–µ–º –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ - –ø–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ isinstance(BaseArticle), –∞ –ø–æ—Ç–æ–º elif(NPlus1Article), —Ç–æ–≥–¥–∞ –≤ else –Ω–µ –ø–æ–π–¥–µ—Ç.\n",
    "    if isinstance(art , BaseArticle):\n",
    "        return '{\"title\":\"'+art.title+'\",'+\n",
    "               ' \"text\":\"'+art.text.replace('\"', '\\\\\"')+'\"}'\n",
    "    elif isinstance(art , NPlus1Article):\n",
    "        res =  f'{{\"date\":\"{art.date}\", \"time\":\"{art.time}\", \"rubrics\":\"{art.rubr}\", '\n",
    "        res += f'\"difficulty\":\"{art.diff}\", \"title\":\"{art.title}\", \"author\":\"'\n",
    "        res += art.author+'\",\"text\":\"'+art.text.replace('\"', '\\\\\"')+'\"}'\n",
    "        return res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ó–∞–≥—Ä—É–∂–∞–µ–º —Å—Ç–∞—Ç—å–∏ –∏ –≤—ã–≤–æ–¥–∏–º JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'super'>\n",
      "<class 'super'>\n",
      "{\"title\":\"–ì–µ—Ä–º–∞–Ω–∏—è –Ω–∞—É—á–∏—Ç –†–æ—Å—Å–∏—é —Å–æ–±–∏—Ä–∞—Ç—å –º—É—Å–æ—Ä–§–æ—Ç–æ: –ú–∞–∫—Å–∏–º –ë–æ–≥–æ–¥–≤–∏–¥ / –†–ò–ê –ù–æ–≤–æ—Å—Ç–∏ –ë—ã–≤—à–∏–π –º–∏–Ω–∏—Å—Ç—Ä –ì–µ—Ä–º–∞–Ω–∏–∏ –ø–æ –≤–æ–ø—Ä–æ—Å–∞–º –æ–∫—Ä—É–∂–∞—é—â–µ–π —Å—Ä–µ–¥—ã, –æ—Ö—Ä–∞–Ω—ã –ø—Ä–∏—Ä–æ–¥—ã –∏ –∑–∞—â–∏—Ç—ã –∞—Ç–æ–º–Ω—ã—Ö —Ä–µ–∞–∫—Ç–æ—Ä–æ–≤ –ö–ª–∞—É—Å –¢–µ–ø—Ñ–µ—Ä –ø—Ä–æ–∫–æ–Ω—Å—É–ª—å—Ç–∏—Ä—É–µ—Ç —Ä–æ—Å—Å–∏–π—Å–∫–æ–µ –ú–∏–Ω–ø—Ä–∏—Ä–æ–¥—ã –ø–æ –ø–æ–≤–æ–¥—É —É—Ç–∏–ª–∏–∑–∞—Ü–∏–∏ –º—É—Å–æ—Ä–∞, –ø–∏—à–µ—Ç –†–ë–ö —Å–æ —Å—Å—ã–ª–∫–æ–π –Ω–∞ –ø—Ä–µ—Å—Å-—Å–ª—É–∂–±—É –≤–∏—Ü–µ-–ø—Ä–µ–º—å–µ—Ä–∞ –ê–ª–µ–∫—Å–µ—è –ì–æ—Ä–¥–µ–µ–≤–∞. ¬´–ì–ª–∞–≤–Ω—ã–π –∏–¥–µ–æ–ª–æ–≥ –Ω–µ–º–µ—Ü–∫–æ–π –º–æ–¥–µ–ª–∏ –ø–µ—Ä–µ—Ä–∞–±–æ—Ç–∫–∏ –∏ —É—Ç–∏–ª–∏–∑–∞—Ü–∏–∏ –º—É—Å–æ—Ä–∞ –≤—ã—Å—Ç—É–ø–∏—Ç –Ω–µ–∑–∞–≤–∏—Å–∏–º—ã–º –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç–æ–º –∑–∞–ø—É—Å–∫–∞ —Ä–æ—Å—Å–∏–π—Å–∫–æ–π —Å–∏—Å—Ç–µ–º—ã –æ–±—Ä–∞—â–µ–Ω–∏—è —Å —Ç–≤–µ—Ä–¥—ã–º–∏ –∫–æ–º–º—É–Ω–∞–ª—å–Ω—ã–º–∏ –æ—Ç—Ö–æ–¥–∞–º–∏ –∏ –±—É–¥–µ—Ç —ç–∫—Å–ø–µ—Ä—Ç–Ω–æ —Å–æ–ø—Ä–æ–≤–æ–∂–¥–∞—Ç—å —Ö–æ–¥ –µ–µ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏¬ª, ‚Äî –≥–æ–≤–æ—Ä–∏—Ç—Å—è –≤ —Å–æ–æ–±—â–µ–Ω–∏–∏ –ø–æ –∏—Ç–æ–≥–∞–º –≤–∏–∑–∏—Ç–∞ –ì–æ—Ä–¥–µ–µ–≤–∞ –≤ –ì–µ—Ä–º–∞–Ω–∏—é. –û—Ç–º–µ—á–∞–µ—Ç—Å—è, —á—Ç–æ –≤–æ –≤—Ä–µ–º—è –ø–æ–µ–∑–¥–∫–∏ –≤–∏—Ü–µ-–ø—Ä–µ–º—å–µ—Ä –æ–∑–Ω–∞–∫–æ–º–∏–ª—Å—è —Å –Ω–µ–º–µ—Ü–∫–æ–π —Å–∏—Å—Ç–µ–º–æ–π —Å–±–æ—Ä–∞ –∏ –ø–µ—Ä–µ—Ä–∞–±–æ—Ç–∫–∏ –º—É—Å–æ—Ä–∞. –ë–ª–∞–≥–æ–¥–∞—Ä—è –µ–π –≤—Å–µ –æ—Ç—Ö–æ–¥—ã —É–¥–∞–µ—Ç—Å—è –ø–µ—Ä–µ—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –≤–æ –≤—Ç–æ—Ä—Å—ã—Ä—å–µ, ¬´–∑–µ–ª–µ–Ω—ã–π —É–≥–æ–ª—å¬ª –∏ —Ü–≤–µ—Ç–æ—á–Ω—ã–π –≥—Ä—É–Ω—Ç. –í –†–æ—Å—Å–∏–∏ —ç—Ç–æ—Ç –ø—É—Ç—å –ø—Ä–æ–¥–µ–ª—ã–≤–∞—é—Ç —Ç–æ–ª—å–∫–æ 10 –ø—Ä–æ—Ü–µ–Ω—Ç–æ–≤ –æ—Ç—Ö–æ–¥–æ–≤. –ü–æ —Å–ª–æ–≤–∞–º –ì–æ—Ä–¥–µ–µ–≤–∞, —Ä–æ—Å—Å–∏–π—Å–∫–∏–µ –≤–ª–∞—Å—Ç–∏ —Å—Ç–∞–≤—è—Ç –ø–µ—Ä–µ–¥ —Å–æ–±–æ–π –∑–∞–¥–∞—á—É –≤ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–∞–∑ –ø–æ–≤—ã—Å–∏—Ç—å —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –ø–µ—Ä–µ—Ä–∞–±–æ—Ç–∫–∏ –æ—Ç—Ö–æ–¥–æ–≤ –∑–∞ –±–ª–∏–∂–∞–π—à–∏–µ —à–µ—Å—Ç—å –ª–µ—Ç, –∞ —Ç–∞–∫–∂–µ –ø–æ–ª–Ω–æ—Å—Ç—å—é —Ä–µ–∫—É–ª—å—Ç–∏–≤–∏—Ä–æ–≤–∞—Ç—å 200 —Å–≤–∞–ª–æ–∫, —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–Ω—ã—Ö –≤ —á–µ—Ä—Ç–µ —Ä–æ—Å—Å–∏–π—Å–∫–∏—Ö –≥–æ—Ä–æ–¥–æ–≤. –†–∞–Ω–µ–µ –≤ —Ö–æ–¥–µ –ø–æ—Å–ª–∞–Ω–∏—è –∫ –§–µ–¥–µ—Ä–∞–ª—å–Ω–æ–º—É —Å–æ–±—Ä–∞–Ω–∏—é –ø—Ä–µ–∑–∏–¥–µ–Ω—Ç –í–ª–∞–¥–∏–º–∏—Ä –ü—É—Ç–∏–Ω –ø–æ—Ç—Ä–µ–±–æ–≤–∞–ª –Ω–∞–≤–µ—Å—Ç–∏ –ø–æ—Ä—è–¥–æ–∫ –≤ —Å—Ñ–µ—Ä–µ —Å–±–æ—Ä–∞ –∏ –ø–µ—Ä–µ—Ä–∞–±–æ—Ç–∫–∏ –º—É—Å–æ—Ä–∞. –° 2019 –≥–æ–¥–∞ –≤ –†–æ—Å—Å–∏–∏ –ø—Ä–æ—Ö–æ–¥–∏—Ç —Ä–µ—Ñ–æ—Ä–º–∞, –≤ —Ä–∞–º–∫–∞—Ö –∫–æ—Ç–æ—Ä–æ–π –±—ã–ª —Å–æ–∑–¥–∞–Ω ¬´–†–æ—Å—Å–∏–π—Å–∫–∏–π —ç–∫–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –æ–ø–µ—Ä–∞—Ç–æ—Ä¬ª. –í –µ–≥–æ –∑–∞–¥–∞—á–∏ –±—É–¥–µ—Ç –≤—Ö–æ–¥–∏—Ç—å: –∫–æ–æ—Ä–¥–∏–Ω–∞—Ü–∏—è —Ä–∞–±–æ—Ç—ã —Ä–µ–≥–∏–æ–Ω–∞–ª—å–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ç–æ—Ä–æ–≤, —Ñ–∏–Ω–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–æ–≤ –ø–æ –æ–±—Ä–∞–±–æ—Ç–∫–µ –æ—Ç—Ö–æ–¥–æ–≤, –∞ —Ç–∞–∫–∂–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –≥–∞—Ä–∞–Ω—Ç–∏–π –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–æ–Ω–Ω—ã–º –ø—Ä–æ–µ–∫—Ç–∞–º.\"}\n",
      "{\"title\":\"---Some text\"}\n"
     ]
    }
   ],
   "source": [
    "a1 = getLentaArticle(\"https://lenta.ru/news/2019/02/20/trash/\")\n",
    "a2 = getArticleTextNPlus1(\"https://nplus1.ru/news/2019/02/20/deep-sqeak\")\n",
    "\n",
    "print(articleToJSON(a1))\n",
    "print(articleToJSON(a2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û–∫–∞–∑—ã–≤–∞–µ—Ç—Å—è, —Ñ—É–Ω–∫—Ü–∏—è `isinstance` –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–µ –ø—Ä–∏–≤–æ–¥–∏—Ç—Å—è –ª–∏ –æ–±—ä–µ–∫—Ç –∫ –ø—Ä–æ–≤–µ—Ä—è–µ–º–æ–º—É —Ç–∏–ø—É –∏ –µ—Å–ª–∏ –ø—Ä–∏–≤–æ–¥–∏—Ç—Å—è, —Ç–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç True. –ù–∞–º –∂–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Å —Ç–∏–ø–æ–º. –î–ª—è —ç—Ç–æ–≥–æ –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏—é `type(a) is`. \n",
    "\n",
    "–ú–æ–∂–Ω–æ, –∫–æ–Ω–µ—á–Ω–æ, –ø—Ä–æ—Å—Ç–æ —Ä–∞—Å—Å—Ç–∞–≤–∏—Ç—å –ø—Ä–æ–≤–µ—Ä–∫–∏ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ, –æ—Å—Ç–∞–≤–∏–≤ –±–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –Ω–∞–ø–æ—Å–ª–µ–¥–æ–∫, –Ω–æ —Ç–∞–∫ –±–æ–ª—å—à–µ —à–∞–Ω—Å –Ω–∞–¥–µ–ª–∞—Ç—å –æ—à–∏–±–æ–∫."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(a1, BaseArticle), isinstance(a2, NPlus1Article)\n",
    "isinstance(a2, BaseArticle), isinstance(a1, NPlus1Article)\n",
    "type(a1) is BaseArticle, type(a2) is NPlus1Article\n",
    "type(a2) is BaseArticle, type(a1) is NPlus1Article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type BaseArticle is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_864515/41643079.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python3.9/json/__init__.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mindent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mseparators\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         default is None and not sort_keys and not kw):\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/json/encoder.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;31m# exceptions aren't as detailed.  The list call should be roughly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;31m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_one_shot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/json/encoder.py\u001b[0m in \u001b[0;36miterencode\u001b[0;34m(self, o, _one_shot)\u001b[0m\n\u001b[1;32m    255\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m                 self.skipkeys, _one_shot)\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m def _make_iterencode(markers, _default, _encoder, _indent, _floatstr,\n",
      "\u001b[0;32m/usr/lib/python3.9/json/encoder.py\u001b[0m in \u001b[0;36mdefault\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \"\"\"\n\u001b[0;32m--> 179\u001b[0;31m         raise TypeError(f'Object of type {o.__class__.__name__} '\n\u001b[0m\u001b[1;32m    180\u001b[0m                         f'is not JSON serializable')\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type BaseArticle is not JSON serializable"
     ]
    }
   ],
   "source": [
    "json.dumps(a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"title\":\"–ì–µ—Ä–º–∞–Ω–∏—è –Ω–∞—É—á–∏—Ç –†–æ—Å—Å–∏—é —Å–æ–±–∏—Ä–∞—Ç—å –º—É—Å–æ—Ä–ë—ã–≤—à–∏–π –º–∏–Ω–∏—Å—Ç—Ä –ì–µ—Ä–º–∞–Ω–∏–∏ –ø–æ –≤–æ–ø—Ä–æ—Å–∞–º –æ–∫—Ä—É–∂–∞—é—â–µ–π —Å—Ä–µ–¥—ã, –æ—Ö—Ä–∞–Ω—ã –ø—Ä–∏—Ä–æ–¥—ã –∏ –∑–∞—â–∏—Ç—ã –∞—Ç–æ–º–Ω—ã—Ö —Ä–µ–∞–∫—Ç–æ—Ä–æ–≤ –ö–ª–∞—É—Å –¢–µ–ø—Ñ–µ—Ä –ø—Ä–æ–∫–æ–Ω—Å—É–ª—å—Ç–∏—Ä—É–µ—Ç —Ä–æ—Å—Å–∏–π—Å–∫–æ–µ –ú–∏–Ω–ø—Ä–∏—Ä–æ–¥—ã –ø–æ –ø–æ–≤–æ–¥—É —É—Ç–∏–ª–∏–∑–∞—Ü–∏–∏ –º—É—Å–æ—Ä–∞, –ø–∏—à–µ—Ç –†–ë–ö —Å–æ —Å—Å—ã–ª–∫–æ–π –Ω–∞ –ø—Ä–µ—Å—Å-—Å–ª—É–∂–±—É –≤–∏—Ü–µ-–ø—Ä–µ–º—å–µ—Ä–∞ –ê–ª–µ–∫—Å–µ—è –ì–æ—Ä–¥–µ–µ–≤–∞. ¬´–ì–ª–∞–≤–Ω—ã–π –∏–¥–µ–æ–ª–æ–≥ –Ω–µ–º–µ—Ü–∫–æ–π –º–æ–¥–µ–ª–∏ –ø–µ—Ä–µ—Ä–∞–±–æ—Ç–∫–∏ –∏ —É—Ç–∏–ª–∏–∑–∞—Ü–∏–∏ –º—É—Å–æ—Ä–∞ –≤—ã—Å—Ç—É–ø–∏—Ç –Ω–µ–∑–∞–≤–∏—Å–∏–º—ã–º –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç–æ–º –∑–∞–ø—É—Å–∫–∞ —Ä–æ—Å—Å–∏–π—Å–∫–æ–π —Å–∏—Å—Ç–µ–º—ã –æ–±—Ä–∞—â–µ–Ω–∏—è —Å —Ç–≤–µ—Ä–¥—ã–º–∏ –∫–æ–º–º—É–Ω–∞–ª—å–Ω—ã–º–∏ –æ—Ç—Ö–æ–¥–∞–º–∏ –∏ –±—É–¥–µ—Ç —ç–∫—Å–ø–µ—Ä—Ç–Ω–æ —Å–æ–ø—Ä–æ–≤–æ–∂–¥–∞—Ç—å —Ö–æ–¥ –µ–µ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏¬ª, ‚Äî –≥–æ–≤–æ—Ä–∏—Ç—Å—è –≤ —Å–æ–æ–±—â–µ–Ω–∏–∏ –ø–æ –∏—Ç–æ–≥–∞–º –≤–∏–∑–∏—Ç–∞ –ì–æ—Ä–¥–µ–µ–≤–∞ –≤ –ì–µ—Ä–º–∞–Ω–∏—é. –û—Ç–º–µ—á–∞–µ—Ç—Å—è, —á—Ç–æ –≤–æ –≤—Ä–µ–º—è –ø–æ–µ–∑–¥–∫–∏ –≤–∏—Ü–µ-–ø—Ä–µ–º—å–µ—Ä –æ–∑–Ω–∞–∫–æ–º–∏–ª—Å—è —Å –Ω–µ–º–µ—Ü–∫–æ–π —Å–∏—Å—Ç–µ–º–æ–π —Å–±–æ—Ä–∞ –∏ –ø–µ—Ä–µ—Ä–∞–±–æ—Ç–∫–∏ –º—É—Å–æ—Ä–∞. –ë–ª–∞–≥–æ–¥–∞—Ä—è –µ–π –≤—Å–µ –æ—Ç—Ö–æ–¥—ã —É–¥–∞–µ—Ç—Å—è –ø–µ—Ä–µ—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –≤–æ –≤—Ç–æ—Ä—Å—ã—Ä—å–µ, ¬´–∑–µ–ª–µ–Ω—ã–π —É–≥–æ–ª—å¬ª –∏ —Ü–≤–µ—Ç–æ—á–Ω—ã–π –≥—Ä—É–Ω—Ç. –í –†–æ—Å—Å–∏–∏ —ç—Ç–æ—Ç –ø—É—Ç—å –ø—Ä–æ–¥–µ–ª—ã–≤–∞—é—Ç —Ç–æ–ª—å–∫–æ 10 –ø—Ä–æ—Ü–µ–Ω—Ç–æ–≤ –æ—Ç—Ö–æ–¥–æ–≤. –ü–æ —Å–ª–æ–≤–∞–º –ì–æ—Ä–¥–µ–µ–≤–∞, —Ä–æ—Å—Å–∏–π—Å–∫–∏–µ –≤–ª–∞—Å—Ç–∏ —Å—Ç–∞–≤—è—Ç –ø–µ—Ä–µ–¥ —Å–æ–±–æ–π –∑–∞–¥–∞—á—É –≤ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–∞–∑ –ø–æ–≤—ã—Å–∏—Ç—å —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –ø–µ—Ä–µ—Ä–∞–±–æ—Ç–∫–∏ –æ—Ç—Ö–æ–¥–æ–≤ –∑–∞ –±–ª–∏–∂–∞–π—à–∏–µ —à–µ—Å—Ç—å –ª–µ—Ç, –∞ —Ç–∞–∫–∂–µ –ø–æ–ª–Ω–æ—Å—Ç—å—é —Ä–µ–∫—É–ª—å—Ç–∏–≤–∏—Ä–æ–≤–∞—Ç—å 200 —Å–≤–∞–ª–æ–∫, —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–Ω—ã—Ö –≤ —á–µ—Ä—Ç–µ —Ä–æ—Å—Å–∏–π—Å–∫–∏—Ö –≥–æ—Ä–æ–¥–æ–≤. –†–∞–Ω–µ–µ –≤ —Ö–æ–¥–µ –ø–æ—Å–ª–∞–Ω–∏—è –∫ –§–µ–¥–µ—Ä–∞–ª—å–Ω–æ–º—É —Å–æ–±—Ä–∞–Ω–∏—é –ø—Ä–µ–∑–∏–¥–µ–Ω—Ç –í–ª–∞–¥–∏–º–∏—Ä –ü—É—Ç–∏–Ω –ø–æ—Ç—Ä–µ–±–æ–≤–∞–ª –Ω–∞–≤–µ—Å—Ç–∏ –ø–æ—Ä—è–¥–æ–∫ –≤ —Å—Ñ–µ—Ä–µ —Å–±–æ—Ä–∞ –∏ –ø–µ—Ä–µ—Ä–∞–±–æ—Ç–∫–∏ –º—É—Å–æ—Ä–∞. –° 2019 –≥–æ–¥–∞ –≤ –†–æ—Å—Å–∏–∏ –ø—Ä–æ—Ö–æ–¥–∏—Ç —Ä–µ—Ñ–æ—Ä–º–∞, –≤ —Ä–∞–º–∫–∞—Ö –∫–æ—Ç–æ—Ä–æ–π –±—ã–ª —Å–æ–∑–¥–∞–Ω ¬´–†–æ—Å—Å–∏–π—Å–∫–∏–π —ç–∫–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –æ–ø–µ—Ä–∞—Ç–æ—Ä¬ª. –í –µ–≥–æ –∑–∞–¥–∞—á–∏ –±—É–¥–µ—Ç –≤—Ö–æ–¥–∏—Ç—å: –∫–æ–æ—Ä–¥–∏–Ω–∞—Ü–∏—è —Ä–∞–±–æ—Ç—ã —Ä–µ–≥–∏–æ–Ω–∞–ª—å–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ç–æ—Ä–æ–≤, —Ñ–∏–Ω–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–æ–≤ –ø–æ –æ–±—Ä–∞–±–æ—Ç–∫–µ –æ—Ç—Ö–æ–¥–æ–≤, –∞ —Ç–∞–∫–∂–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –≥–∞—Ä–∞–Ω—Ç–∏–π –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–æ–Ω–Ω—ã–º –ø—Ä–æ–µ–∫—Ç–∞–º.\"}\n",
      "{\"date\":\"20 –§–µ–≤. 2019\", \"time\":\"18:55\", \"rubrics\":\"–ë–∏–æ–ª–æ–≥–∏—è\", \"difficulty\":\"3.1\", \"title\":\"\", \"author\":\"–ï–ª–∏–∑–∞–≤–µ—Ç–∞ –ò–≤—Ç—É—à–æ–∫\",\"text\":\"–ê–º–µ—Ä–∏–∫–∞–Ω—Å–∫–∏–µ —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏–ª–∏ DeepSqeak ‚Äî –ø—Ä–æ–≥—Ä–∞–º–º—É –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–æ–∫–∞–ª–∏–∑–∞—Ü–∏–∏ –≥—Ä—ã–∑—É–Ω–æ–≤. –û–Ω–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–≤–µ—Ä—Ç–æ—á–Ω—ã—Ö –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π –∏ –ø–æ–∑–≤–æ–ª—è–µ—Ç –≤—ã–¥–µ–ª—è—Ç—å –∏–∑ –∞—É–¥–∏–æ—Ñ–∞–π–ª–æ–≤ –æ—Ç–¥–µ–ª—å–Ω—ã–µ –∑–≤—É–∫–∏ –ø–æ –∏—Ö —Å–æ–Ω–æ–≥—Ä–∞–º–º–µ, –ø–æ—Å–ª–µ —á–µ–≥–æ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç –∏—Ö, —Å–æ–∑–¥–∞–≤–∞—è ¬´—Å–ª–æ–≤–∞—Ä—å¬ª. –°—Ç–∞—Ç—å—è –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–∞ –≤ –∂—É—Ä–Ω–∞–ª–µ Neuropsychopharmacology, —Å–∞–º –∞–ª–≥–æ—Ä–∏—Ç–º –¥–æ—Å—Ç—É–ø–µ–Ω –≤ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤ –Ω–∞ GitHub.–î–ª—è –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏ –¥—Ä—É–≥ —Å –¥—Ä—É–≥–æ–º –≥—Ä—ã–∑—É–Ω—ã –∏—Å–ø–æ–ª—å–∑—É—é—Ç —É–ª—å—Ç—Ä–∞–∑–≤—É–∫–æ–≤—É—é –≤–æ–∫–∞–ª–∏–∑–∞—Ü–∏—é ‚Äî –∏–∑–¥–∞—é—Ç –∑–≤—É–∫–∏ —Å —á–∞—Å—Ç–æ—Ç–æ–π –æ—Ç 20 –∫–∏–ª–æ–≥–µ—Ä—Ü. ¬´–°–ª–æ–≤–∞—Ä—å¬ª —Ç–∞–∫–∏—Ö –∑–≤—É–∫–æ–≤ —É –Ω–∏—Ö –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –±–æ–ª—å—à–æ–π: –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –ø–æ–¥—Ä–∞–∑–¥–µ–ª—è—é—Ç –∏—Ö –Ω–∞ —Å–ª–æ–≥–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –¥–ª–∏–Ω—ã –∏ —á–∞—Å—Ç–æ—Ç—ã, –∞ –∫–∞–∂–¥—ã–π –∏–∑ –Ω–∏—Ö —Å–≤—è–∑—ã–≤–∞—é—Ç —Å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–π —Ä–µ–∞–∫—Ü–∏–µ–π –∂–∏–≤–æ—Ç–Ω–æ–≥–æ. –ö –ø—Ä–∏–º–µ—Ä—É, –∑–≤—É–∫–∏ —Å —á–∞—Å—Ç–æ—Ç–æ–π 50 –∫–∏–ª–æ–≥–µ—Ä—Ü –∞—Å—Å–æ—Ü–∏–∏—Ä—É—é—Ç—Å—è —Å –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–π —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π —Ä–µ–∞–∫—Ü–∏–µ–π –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω—ã—Ö –∫—Ä—ã—Å, –∞ –±–æ–ª–µ–µ –Ω–∏–∑–∫–∏–µ –∑–≤—É–∫–∏ ‚Äî —Å —á–∞—Å—Ç–æ—Ç–æ–π –æ–∫–æ–ª–æ 20 ‚Äî —Å –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–æ–π. –ü—Ä–∏ —ç—Ç–æ–º —É –º—ã—à–µ–π –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–æ–Ω–Ω—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è.–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –∏–∑ –í–∞—à–∏–Ω–≥—Ç–æ–Ω—Å–∫–æ–≥–æ —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç–∞ –ø–æ–¥ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ–º –ö–µ–≤–∏–Ω–∞ –ö–æ—Ñ—Ñ–∏ (Kevin Coffey) —Ä–µ—à–∏–ª–∏ —Å–æ–∑–¥–∞—Ç—å –∞–ª–≥–æ—Ä–∏—Ç–º, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–º–æ–∂–µ—Ç —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞—Ç—å –∑–≤—É–∫–∏, –∏–∑–¥–∞–≤–∞–µ–º—ã–µ –≥—Ä—ã–∑—É–Ω–∞–º–∏, —Ä–∞–∑–¥–µ–ª—è—Ç—å –∏—Ö –Ω–∞ —Å–ª–æ–≥–∏ –∏ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å. –ê–Ω–∞–ª–∏–∑ —Å –ø–æ–º–æ—â—å—é DeepSqeak —Å–æ—Å—Ç–æ–∏—Ç –∏–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —ç—Ç–∞–ø–æ–≤: —Å–Ω–∞—á–∞–ª–∞ –∏–∑ –∑–≤—É–∫–æ–≤–æ–≥–æ —Ñ–∞–π–ª–∞ —Å–æ–∑–¥–∞–µ—Ç—Å—è —Å–æ–Ω–æ–≥—Ä–∞–º–º–∞, –∏–∑ –∫–æ—Ç–æ—Ä–æ–π –≤—ã–¥–µ–ª—è—é—Ç—Å—è –∑–≤—É–∫–æ–≤—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã. –¢–∞–∫ –∫–∞–∫ –Ω–∞ —Å–æ–Ω–æ–≥—Ä–∞–º–º—É –º–æ–∂–µ—Ç –ø–æ–ø–∞—Å—Ç—å –∏ —à—É–º, –¥–∞–ª–µ–µ –≤ –∞–ª–≥–æ—Ä–∏—Ç–º–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å–≤–µ—Ä—Ç–æ—á–Ω–∞—è –Ω–µ–π—Ä–æ—Å–µ—Ç—å, –∫–æ—Ç–æ—Ä–∞—è —Ä–∞–∑–¥–µ–ª—è–µ—Ç –∑–≤—É–∫–æ–≤—ã–µ –∫–æ–ª–µ–±–∞–Ω–∏—è –Ω–∞ –∑–≤—É–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –∏–∑–¥–∞—é—Ç —Å–∞–º–∏ –≥—Ä—ã–∑—É–Ω—ã, –∏ —Å—Ç–æ—Ä–æ–Ω–Ω–∏–π —à—É–º. \n",
      "    \n",
      "        \n",
      "                        \n",
      "                \n",
      "                    \n",
      "                        \n",
      "                    \"}\n"
     ]
    }
   ],
   "source": [
    "def articleToJSON(art):\n",
    "    # –ó–¥–µ—Å—å —Å–¥–µ–ª–∞–µ–º –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ - –ø–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ isinstance(BaseArticle), –∞ –ø–æ—Ç–æ–º elif(NPlus1Article), —Ç–æ–≥–¥–∞ –≤ else –Ω–µ –ø–æ–π–¥–µ—Ç.\n",
    "    if type(art) is BaseArticle:\n",
    "        return '{\"title\":\"'+art.title+art.text.replace('\"', '\\\\\"')+'\"}'\n",
    "    elif type(art) is NPlus1Article:\n",
    "        res = '{\"date\":\"'+art.date+'\", \"time\":\"'+art.time+'\", \"rubrics\":\"'+art.rubr+'\", \"difficulty\":\"'\n",
    "        res += art.diff+'\", \"title\":\"'+art.title+'\", \"author\":\"'+art.author+'\",\"text\":\"'\n",
    "        res += art.text.replace('\"', '\\\\\"')+'\"}'\n",
    "        return res\n",
    "\n",
    "a1 = getLentaArticle(\"https://lenta.ru/news/2019/02/20/trash/\")\n",
    "a2 = getArticleTextNPlus1(\"https://nplus1.ru/news/2019/02/20/deep-sqeak\")\n",
    "\n",
    "print(articleToJSON(a1))\n",
    "print(articleToJSON(a2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–¢–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–µ–π.\n",
    "\n",
    "–ú—ã —É–≤–∏–¥–µ–ª–∏, —á—Ç–æ –Ω–∞—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –º–æ–∂–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –¥–ª—è —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–∞. –ü–æ–ø—Ä–æ–±—É–µ–º –ø—Ä–∏–º–µ–Ω–∏—Ç—å —ç—Ç–æ –∑–Ω–∞–Ω–∏–µ –∫ –ø—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—é –∫–ª–∞—Å—Å–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –∑–∞–≥—Ä—É–∂–∞—é—Ç —Å—Ç–∞—Ç—å–∏. –°–æ–∑–¥–∞–¥–∏–º –±–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å, –∫–æ—Ç–æ—Ä—ã–π —É–º–µ–µ—Ç —Å–æ—Ö—Ä–∞–Ω—è—Ç—å —Å—Ç–∞—Ç—å–∏ –≤ —Ñ–∞–π–ª –∏ —Å—á–∏—Ç—ã–≤–∞—Ç—å –∏—Ö –æ—Ç—Ç—É–¥–∞. –ü—Ä–∏ —ç—Ç–æ–º —Å–æ—Ö—Ä–∞–Ω—è—Ç—å—Å—è –±—É–¥—É—Ç —Ç–æ–ª—å–∫–æ –∑–∞–≥–æ–ª–æ–≤–∫–∏ –∏ —Ç–µ–∫—Å—Ç, –∞ –æ—Å—Ç–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è, –µ—Å–ª–∏ –æ–Ω–∞ –±—ã–ª–∞, –±—É–¥–µ—Ç —Ç–µ—Ä—è—Ç—å—Å—è. –¢–∞–∫–∂–µ –∫–ª–∞—Å—Å –±—É–¥–µ—Ç —É–º–µ—Ç—å —Å—Ç—Ä–æ–∏—Ç—å —á–∞—Å—Ç–æ—Ç–Ω—ã–µ —Å–ª–æ–≤–∞—Ä–∏ –¥–ª—è —Å—Ç–∞—Ç–µ–π. –î–∞–ª—å—à–µ —É–Ω–∞—Å–ª–µ–¥—É–µ–º—Å—è –æ—Ç —ç—Ç–æ–≥–æ –∫–ª–∞—Å—Å–∞ –∏ –¥–æ–±–∞–≤–∏–º —Ñ—É–Ω–∫—Ü–∏–∏ —Ä–∞–±–æ—Ç—ã —Å –∑–∞–¥–∞–Ω–Ω—ã–º —Å–∞–π—Ç–æ–º."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseGetNewsPaper:\n",
    "    ''' –ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç–∞—Ç–µ–π. –û–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –æ—Å–Ω–æ–≤–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª, –Ω–æ –Ω–µ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å.\n",
    "    '''        \n",
    "    # –ö–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä - –≤—ã–∑—ã–≤–∞–µ—Ç—Å—è –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –æ–±—ä–µ–∫—Ç–∞ –∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –µ–≥–æ.\n",
    "    def __init__(self):\n",
    "        self.articles = []     # –ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ —Å—Ç–∞—Ç—å–∏.\n",
    "        self.dictionaries = [] # –°–ª–æ–≤–∞—Ä–∏ –¥–ª—è –∫–∞–∂–¥–æ–π –∏–∑ —Å—Ç–∞—Ç–µ–π.\n",
    "        # –°–æ–∑–¥–∞–µ–º –∏ –∑–∞–≥—Ä—É–∂–∞–µ–º –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —Å–ª–æ–≤–∞—Ä—å.\n",
    "        self.morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "    # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–∞ –¥–ª—è —Å—Ç–∞—Ç—å–∏.\n",
    "    def getArticleDictionary(self, text, needPos=None):\n",
    "        words = [a[0] for a in re.findall(\"([–ê-–Ø–Å–∞-—è—ë]+(-[–ê-–Ø–Å–∞-—è—ë]+)*)\", text)]\n",
    "        reswords = []\n",
    "    \n",
    "        for w in words:\n",
    "            wordform = self.morph.parse(w)[0]\n",
    "            try:\n",
    "                if wordform.tag.POS in ['ADJF', 'NOUN', 'VERB', 'PRTF', 'GRND']:\n",
    "                    if needPos != None:\n",
    "                        reswords.append(wordform.normal_form+'_'+wordform.tag.POS)\n",
    "                    else:\n",
    "                        reswords.append(wordform.normal_form)\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "        stat = Counter(reswords)\n",
    "        # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ —Å–ª–æ–≤–∞ —Å —á–∞—Å—Ç–æ—Ç–æ–π –±–æ–ª—å—à–µ 1.\n",
    "        stat = {a: stat[a] for a in stat.keys() if stat[a]>1}\n",
    "        return stat\n",
    "\n",
    "    # –ü–æ—Å—á–∏—Ç–∞–µ–º –≤–µ–∫—Ç–æ—Ä–∞ –¥–ª—è –≤—Å–µ—Ö —Å—Ç–∞—Ç–µ–π.\n",
    "    def calcArticleDictionaries(self, needPos=None):\n",
    "        self.dictionaries = []\n",
    "        for a in self.articles:\n",
    "            self.dictionaries.append(self.getArticleDictionary(a.text, needPos))\n",
    "            \n",
    "    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç–∞—Ç—å–∏ –≤ —Ñ–∞–π–ª.\n",
    "    def saveArticles(self, filename):\n",
    "        \"\"\" Saves all articles to a file with a filename. \"\"\"\n",
    "        newsfile = open(filename, \"w\")\n",
    "        for art in self.articles:\n",
    "            newsfile.write('\\n=====\\n'+art.title)\n",
    "            newsfile.write('\\n-----\\n'+art.text)\n",
    "        newsfile.close()\n",
    "\n",
    "    # –ß–∏—Ç–∞–µ–º —Å—Ç–∞—Ç—å–∏ –∏–∑ —Ñ–∞–π–ª–∞.\n",
    "    def loadArticles(self, filename):\n",
    "        \"\"\" Loads and replaces all articles from a file with a filename. \"\"\"\n",
    "        newsfile = open(filename, encoding=\"utf-8\")\n",
    "        text = newsfile.read()\n",
    "        loaded = text.split('\\n=====\\n')[1:]\n",
    "        self.articles=[]\n",
    "        for i, a in enumerate(loaded):\n",
    "            self.articles.append(BaseArticle())\n",
    "            b, self.articles[i].text = a.split('\\n-----\\n')\n",
    "            self.articles[i].title = b\n",
    "        newsfile.close()\n",
    "\n",
    "class GetLenta(BaseGetNewsPaper):\n",
    "    ''' –ö–ª–∞—Å—Å –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –õ–µ–Ω—Ç—ã.—Ä—É.  –ù–∞—Å–ª–µ–¥—É–µ—Ç—Å—è –æ—Ç BaseGetNewsPaper.\n",
    "    '''\n",
    "    # –ó–∞–≥—Ä—É–∑–∫–∞ —Å—Ç–∞—Ç—å–∏ –ø–æ URL.\n",
    "    def getLentaArticle(self, url):\n",
    "        \"\"\" getLentaArticle gets the body of an article from Lenta.ru\"\"\"\n",
    "        # –ü–æ–ª—É—á–∞–µ—Ç —Ç–µ–∫—Å—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—ã.\n",
    "        resp = requests.get(url)\n",
    "        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–µ–∫—Å—Ç –≤ –æ–±—ä–µ–∫—Ç —Ç–∏–ø–∞ BeautifulSoup.\n",
    "        bs = BeautifulSoup(resp.text, \"html5lib\") \n",
    "        \n",
    "        art = BaseArticle()\n",
    "        # –ü–æ–ª—É—á–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Å—Ç–∞—Ç—å–∏.\n",
    "        art.title = bs.h1.text.replace(\"\\xa0\", \" \")\n",
    "        # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç —Å—Ç–∞—Ç—å–∏.\n",
    "        art.text = BeautifulSoup(\" \".join([p.text for p in \\\n",
    "                                           bs.find_all(\"p\")]), \"html5lib\").get_text().replace(\"\\xa0\", \" \")\n",
    "        return art\n",
    "\n",
    "    # –ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö —Å—Ç–∞—Ç–µ–π –∑–∞ –æ–¥–∏–Ω –¥–µ–Ω—å.\n",
    "    def getLentaDay(self, url):\n",
    "        \"\"\" Gets all URLs for a given day and gets all texts. \"\"\"\n",
    "        try:\n",
    "            # –ì—Ä—É–∑–∏–º —Å—Ç—Ä–∞–Ω–∏—Ü—É —Å–æ —Å–ø–∏—Å–∫–æ–º –≤—Å–µ—Ö —Å—Ç–∞—Ç–µ–π.\n",
    "            day = requests.get(url) \n",
    "            # –ü–æ–ª—É—á–∞–µ–º —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã —Å –Ω—É–∂–Ω—ã–º–∏ –Ω–∞–º –∞–¥—Ä–µ—Å–∞–º–∏ —Å—Ç–∞—Ç–µ–π.\n",
    "            h3s = BeautifulSoup(day.text, \"html5lib\").find_all(\"h3\")\n",
    "            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∞–¥—Ä–µ—Å–∞ –Ω–∞ —Å—Ç–∞—Ç—å–∏ –∑–∞ –¥–µ–Ω—å.\n",
    "            links = [\"http://lenta.ru\"+l.find_all(\"a\")[0][\"href\"] for l in h3s]\n",
    "            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—Ç–∞—Ç—å–∏.\n",
    "            for l in links:\n",
    "                art = self.getLentaArticle(l)\n",
    "                self.articles.append(art)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # –ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö —Å—Ç–∞—Ç–µ–π –∑–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ –¥–Ω–µ–π.\n",
    "    def getLentaPeriod(self, start, finish):\n",
    "        \"\"\"Gets articles for a period fom start to finish. \"\"\"\n",
    "        curdate = start\n",
    "        while curdate <= finish:\n",
    "            print(curdate.strftime('%Y/%m/%d')) # Just in case.\n",
    "            # –°–ø–∏—Å–æ–∫ —Å—Ç–∞—Ç–µ–π –≥—Ä—É–∑–∏—Ç—Å—è —Å –≤–æ—Ç —Ç–∞–∫–æ–≥–æ –∞–¥—Ä–µ—Å–∞.\n",
    "            self.getLentaDay('https://lenta.ru/news/'+curdate.strftime('%Y/%m/%d'))\n",
    "            curdate += datetime.timedelta(days=1)\n",
    "\n",
    "class GetNPlus1(BaseGetNewsPaper):\n",
    "    ''' –ö–ª–∞—Å—Å –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ NPlus1.ru. –ù–∞—Å–ª–µ–¥—É–µ—Ç—Å—è –æ—Ç BaseGetNewsPaper.\n",
    "    '''\n",
    "    def getArticleTextNPlus1(self, adr):\n",
    "        \"\"\"Get an article from nplus1.ru\"\"\"\n",
    "        r = requests.get(adr)\n",
    "        #print(r.text)\n",
    "        art = NPlus1Article()\n",
    "        tables = re.split(\"</div>\",re.split('=\"tables\"', r.text)[1])[0]\n",
    "        t1 = re.split(\"</time>\", re.split(\"<time\", tables)[1])[0]\n",
    "        art.time = re.split(\"</span>\", re.split(\"<span>\", t1)[1])[0]\n",
    "        art.date = re.split(\"</span>\", re.split(\"<span>\", t1)[2])[0]\n",
    "        art.rubr = re.findall(\"<a data-rubric.+?>(.+?)</a>\", r.text)[0]\n",
    "        art.diff = re.split(\"</span>\", re.split('\"difficult-value\">', tables)[1])[0]\n",
    "        art.title = re.findall(\"<h1>(.+?)</h1>\", r.text)[0]\n",
    "        art.author = re.split('\" />',re.split('<meta name=\"author\" content=\"', r.text)[1])[0]\n",
    "        art.text = re.split(\"</div>\", re.split(\"</figure>\", re.split('</article>',re.split('<article', r.text)[1])[0])[1])[1]    \n",
    "\n",
    "        beaux_text = BeautifulSoup(art.text, \"html5lib\")\n",
    "        art.text = delcom.sub(\"\", beaux_text.get_text() )\n",
    "        art.text = art.text.replace('\\xa0', ' ')\n",
    "        return art\n",
    "\n",
    "    def getNPlus1Day(self, adr):\n",
    "        \"\"\" Gwt all article for a day by its URL given in adr parameter.\"\"\"\n",
    "        r = requests.get(adr)\n",
    "        titles = BeautifulSoup(r.text, \"html5lib\")(\"article\")\n",
    "        addrs = [\"https://nplus1.ru/\"+a(\"a\")[0][\"href\"] for a in titles]\n",
    "        for adr in addrs:\n",
    "            aa = self.getArticleTextNPlus1(adr)\n",
    "            self.articles.append(aa)\n",
    "        \n",
    "    # –ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö —Å—Ç–∞—Ç–µ–π –∑–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ –¥–Ω–µ–π.\n",
    "    def getNPlus1Period(self, start, finish):\n",
    "        \"\"\" Gets all articles from nplus1.ru for a period from start to finish. \"\"\"\n",
    "        curdate = start\n",
    "        while curdate <= finish:\n",
    "            print(curdate.strftime('%Y/%m/%d')) # Just in case.\n",
    "            # –°–ø–∏—Å–æ–∫ —Å—Ç–∞—Ç–µ–π –≥—Ä—É–∑–∏—Ç—Å—è —Å –≤–æ—Ç —Ç–∞–∫–æ–≥–æ –∞–¥—Ä–µ—Å–∞.\n",
    "            self.getNPlus1Day('https://nplus1.ru/news/'+curdate.strftime('%Y/%m/%d'))\n",
    "            curdate += datetime.timedelta(days=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä—É–µ–º –∫–∞–∫ —Ä–∞–±–æ—Ç–∞—é—Ç –Ω–∞—à–∏ –∫–ª–∞—Å—Å—ã - –∑–∞–≥—Ä—É–∑–∏–º —Ç—Ä–∏ –¥–Ω—è —Å –æ–±–æ–∏—Ö —Å–∞–π—Ç–æ–≤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/02/01\n",
      "2018/02/02\n",
      "2018/02/03\n"
     ]
    }
   ],
   "source": [
    "lenta=GetLenta()\n",
    "lenta.getLentaPeriod(datetime.date(2018, 2, 1), datetime.date(2018, 2, 3))\n",
    "lenta.saveArticles(\"data/lenta_test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/02/01\n",
      "2018/02/02\n",
      "2018/02/03\n"
     ]
    }
   ],
   "source": [
    "n1=GetNPlus1()\n",
    "n1.getNPlus1Period(datetime.date(2018, 2, 1), datetime.date(2018, 2, 3))\n",
    "\n",
    "n1.saveArticles(\"data/nplus1_test.txt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü—Ä–æ—á–∏—Ç–∞–µ–º —Å—Ç–∞—Ç—å–∏ –∏–∑ —Ñ–∞–π–ª–∞."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'–î–ù–ö –ø–æ–º–æ–≥–ª–∞ —É–ø—Ä–∞–≤–ª—è—Ç—å —Ä–æ–µ–º –º–æ–ª–µ–∫—É–ª—è—Ä–Ω—ã—Ö –º–æ—Ç–æ—Ä–æ–≤ –∏–∑ –º–∏–∫—Ä–æ—Ç—Ä—É–±–æ—á–µ–∫'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n2=GetNPlus1()\n",
    "n2.loadArticles(\"data/nplus1_test.txt\")\n",
    "\n",
    "n2.articles[1].title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û–¥–Ω–∞–∫–æ –¥–∞–≤–∞—Ç—å —Ä–∞–∑–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è –¥–ª—è —Ñ—É–Ω–∫—Ü–∏–π, –∫–æ—Ç–æ—Ä—ã–µ –¥–µ–ª–∞—é—Ç –æ–¥–Ω–æ –∏ —Ç–æ –∂–µ - –Ω–µ –æ—á–µ–Ω—å —Ö–æ—Ä–æ—à–æ, –æ—Å–æ–±–µ–Ω–Ω–æ –µ—Å–ª–∏ —ç—Ç–∏ —Ñ—É–Ω–∫—Ü–∏–∏ –≤—Ö–æ–¥—è—Ç –≤ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –∫–ª–∞—Å—Å–∞.\n",
    "\n",
    "–ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å (–≤ —Å–ª—É—á–∞–µ Python) - —ç—Ç–æ –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –æ–±—è–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞, —á—Ç–æ –∫–ª–∞—Å—Å —É–º–µ–µ—Ç –≤—ã–ø–æ–ª–Ω—è—Ç—å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏. –í —ç—Ç–æ–º —Å–ª—É—á–∞–µ –Ω–µ –≤–∞–∂–Ω–æ, –∫–∞–∫–æ–π –∏–º–µ–Ω–Ω–æ –∫–ª–∞—Å—Å –Ω–∞—Å–ª–µ–¥—É–µ—Ç. –î–ª—è —ç—Ç–æ–≥–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —É –±–∞–∑–æ–≤–æ–≥–æ –∫–ª–∞—Å—Å–∞ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏, –∞ –≤ –¥–æ—á–µ—Ä–Ω–∏—Ö –∫–ª–∞—Å—Å–∞—Ö –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —ç—Ç–∏ —Ñ—É–Ω–∫—Ü–∏–∏."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseGetNewsPaper:\n",
    "    ''' –ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç–∞—Ç–µ–π. –û–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –æ—Å–Ω–æ–≤–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª –∏ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å.\n",
    "        –ö–ª–∞—Å—Å—ã-–Ω–∞—Å–ª–µ–¥–Ω–∏–∫–∏ –±—É–¥—É—Ç —É–º–µ—Ç—å –∑–∞–≥—Ä—É–∂–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –ø—Ä–∏ –ø–æ–º–æ—â–∏ –æ–¥–Ω–æ–≥–æ –ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ–≥–æ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞.\n",
    "    '''        \n",
    "        \n",
    "    # –ö–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä - –≤—ã–∑—ã–≤–∞–µ—Ç—Å—è –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –æ–±—ä–µ–∫—Ç–∞ –∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –µ–≥–æ.\n",
    "    def __init__(self):\n",
    "        self.articles=[]     # –ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ —Å—Ç–∞—Ç—å–∏.\n",
    "        self.dictionaries=[] # –°–ª–æ–≤–∞—Ä–∏ –¥–ª—è –∫–∞–∂–¥–æ–π –∏–∑ —Å—Ç–∞—Ç–µ–π.\n",
    "        # –°–æ–∑–¥–∞–µ–º –∏ –∑–∞–≥—Ä—É–∂–∞–µ–º –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —Å–ª–æ–≤–∞—Ä—å.\n",
    "        self.morph=pymorphy2.MorphAnalyzer()\n",
    "\n",
    "    # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–∞ –¥–ª—è —Å—Ç–∞—Ç—å–∏.\n",
    "    def getArticleDictionary(self, text, needPos=None):\n",
    "        words=[a[0] for a in re.findall(\"([–ê-–Ø–Å–∞-—è—ë]+(-[–ê-–Ø–Å–∞-—è—ë]+)*)\", text)]\n",
    "        reswords=[]\n",
    "    \n",
    "        for w in words:\n",
    "            wordform=self.morph.parse(w)[0]\n",
    "            try:\n",
    "                if wordform.tag.POS in ['ADJF', 'NOUN', 'VERB', 'PRTF', 'GRND']:\n",
    "                    if needPos!=None:\n",
    "                        reswords.append(wordform.normal_form+'_'+wordform.tag.POS)\n",
    "                    else:\n",
    "                        reswords.append(wordform.normal_form)\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "        stat=Counter(reswords)\n",
    "        # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ —Å–ª–æ–≤–∞ —Å —á–∞—Å—Ç–æ—Ç–æ–π –±–æ–ª—å—à–µ 1.\n",
    "        stat={a: stat[a] for a in stat.keys() if stat[a]>1}\n",
    "        return stat\n",
    "\n",
    "    # –ü–æ—Å—á–∏—Ç–∞–µ–º –≤–µ–∫—Ç–æ—Ä–∞ –¥–ª—è –≤—Å–µ—Ö —Å—Ç–∞—Ç–µ–π.\n",
    "    def calcArticleDictionaries(self, needPos=None):\n",
    "        self.dictionaries=[]\n",
    "        for a in self.articles:\n",
    "            self.dictionaries.append(self.getArticleDictionary(a.text, needPos))\n",
    "            \n",
    "\n",
    "    # –ó–∞–≥—Ä—É–∑–∏—Ç—å –Ω–æ–≤–æ—Å—Ç–∏ –∑–∞ –ø–µ—Ä–∏–æ–¥.\n",
    "    # –≠—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è –æ–±—ä—è–≤–ª–µ–Ω–∞ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ –∏ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞.\n",
    "    def getPeriod(self, start, finish):\n",
    "        print(\"Nothing to do.\")\n",
    "    \n",
    "    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç–∞—Ç—å–∏ –≤ —Ñ–∞–π–ª.\n",
    "    def saveArticles(self, filename):\n",
    "        \"\"\" Saves all articles to a file with a filename. \"\"\"\n",
    "        newsfile = open(filename, \"w\")\n",
    "        for art in self.articles:\n",
    "            newsfile.write('\\n=====\\n'+art.title)\n",
    "            newsfile.write('\\n-----\\n'+art.text)\n",
    "        newsfile.close()\n",
    "\n",
    "    # –ß–∏—Ç–∞–µ–º —Å—Ç–∞—Ç—å–∏ –∏–∑ —Ñ–∞–π–ª–∞.\n",
    "    def loadArticles(self, filename):\n",
    "        \"\"\" Loads and replaces all articles from a file with a filename. \"\"\"\n",
    "        newsfile = open(filename, encoding=\"utf-8\")\n",
    "        text = newsfile.read()\n",
    "        loaded = text.split('\\n=====\\n')[1:]\n",
    "        self.articles=[]\n",
    "        for i, a in enumerate(loaded):\n",
    "            self.articles.append(BaseArticle())\n",
    "            b, self.articles[i].text = a.split('\\n-----\\n')\n",
    "            self.articles[i].title = b\n",
    "        newsfile.close()\n",
    "        \n",
    "class GetLenta(BaseGetNewsPaper):\n",
    "    ''' –ö–ª–∞—Å—Å –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –õ–µ–Ω—Ç—ã.—Ä—É.  –ù–∞—Å–ª–µ–¥—É–µ—Ç—Å—è –æ—Ç BaseGetNewsPaper.\n",
    "    '''\n",
    "\n",
    "    # –ó–∞–≥—Ä—É–∑–∫–∞ —Å—Ç–∞—Ç—å–∏ –ø–æ URL.\n",
    "    def getLentaArticle(self, url):\n",
    "        \"\"\" getLentaArticle gets the body of an article from Lenta.ru\"\"\"\n",
    "        # –ü–æ–ª—É—á–∞–µ—Ç —Ç–µ–∫—Å—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—ã.\n",
    "        resp=requests.get(url)\n",
    "        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–µ–∫—Å—Ç –≤ –æ–±—ä–µ–∫—Ç —Ç–∏–ø–∞ BeautifulSoup.\n",
    "        bs=BeautifulSoup(resp.text, \"html5lib\") \n",
    "        \n",
    "        art=BaseArticle()\n",
    "        # –ü–æ–ª—É—á–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Å—Ç–∞—Ç—å–∏.\n",
    "        art.title=bs.h1.text.replace(\"\\xa0\", \" \")\n",
    "        # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç —Å—Ç–∞—Ç—å–∏.\n",
    "        art.text=BeautifulSoup(\" \".join([p.text for p in bs.find_all(\"p\")]), \"html5lib\").get_text().replace(\"\\xa0\", \" \")\n",
    "        return art\n",
    "\n",
    "    # –ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö —Å—Ç–∞—Ç–µ–π –∑–∞ –æ–¥–∏–Ω –¥–µ–Ω—å.\n",
    "    def getLentaDay(self, url):\n",
    "        \"\"\" Gets all URLs for a given day and gets all texts. \"\"\"\n",
    "        try:\n",
    "            # –ì—Ä—É–∑–∏–º —Å—Ç—Ä–∞–Ω–∏—Ü—É —Å–æ —Å–ø–∏—Å–∫–æ–º –≤—Å–µ—Ö —Å—Ç–∞—Ç–µ–π.\n",
    "            day = requests.get(url) \n",
    "            # –ü–æ–ª—É—á–∞–µ–º —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã —Å –Ω—É–∂–Ω—ã–º–∏ –Ω–∞–º –∞–¥—Ä–µ—Å–∞–º–∏ —Å—Ç–∞—Ç–µ–π.\n",
    "            h3s=BeautifulSoup(day.text, \"html5lib\").find_all(\"h3\")\n",
    "            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∞–¥—Ä–µ—Å–∞ –Ω–∞ —Å—Ç–∞—Ç—å–∏ –∑–∞ –¥–µ–Ω—å.\n",
    "            links=[\"http://lenta.ru\"+l.find_all(\"a\")[0][\"href\"] for l in h3s]\n",
    "            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—Ç–∞—Ç—å–∏.\n",
    "            for l in links:\n",
    "                art=self.getLentaArticle(l)\n",
    "                self.articles.append(art)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # –ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö —Å—Ç–∞—Ç–µ–π –∑–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ –¥–Ω–µ–π.\n",
    "    def getLentaPeriod(self, start, finish):\n",
    "        curdate=start\n",
    "        while curdate<=finish:\n",
    "            print(curdate.strftime('%Y/%m/%d')) # Just in case.\n",
    "            # –°–ø–∏—Å–æ–∫ —Å—Ç–∞—Ç–µ–π –≥—Ä—É–∑–∏—Ç—Å—è —Å –≤–æ—Ç —Ç–∞–∫–æ–≥–æ –∞–¥—Ä–µ—Å–∞.\n",
    "            self.getLentaDay('https://lenta.ru/news/'+curdate.strftime('%Y/%m/%d'))\n",
    "            curdate+=datetime.timedelta(days=1)\n",
    "\n",
    "    def getPeriod(self, start, finish):\n",
    "        self.getLentaPeriod(start, finish)\n",
    "    \n",
    "\n",
    "class GetNPlus1(BaseGetNewsPaper):\n",
    "    ''' –ö–ª–∞—Å—Å –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ NPlus1.ru.  –ù–∞—Å–ª–µ–¥—É–µ—Ç—Å—è –æ—Ç BaseGetNewsPaper.\n",
    "    '''\n",
    "\n",
    "    def getArticleTextNPlus1(self, adr):\n",
    "        r = requests.get(adr)\n",
    "        #print(r.text)\n",
    "        art = NPlus1Article()\n",
    "        tables = re.split(\"</div>\",re.split('=\"tables\"', r.text)[1])[0]\n",
    "        t1 = re.split(\"</time>\", re.split(\"<time\", tables)[1])[0]\n",
    "        art.time = re.split(\"</span>\", re.split(\"<span>\", t1)[1])[0]\n",
    "        art.date = re.split(\"</span>\", re.split(\"<span>\", t1)[2])[0]\n",
    "        art.rubr = re.findall(\"<a data-rubric.+?>(.+?)</a>\", r.text)[0]\n",
    "        art.diff = re.split(\"</span>\", re.split('\"difficult-value\">', tables)[1])[0]\n",
    "        art.title = re.findall(\"<h1>(.+?)</h1>\", r.text)[0]\n",
    "        art.author = re.split('\" />',re.split('<meta name=\"author\" content=\"', r.text)[1])[0]\n",
    "        art.text = re.split(\"</div>\", re.split(\"</figure>\", re.split('</article>',re.split('<article', r.text)[1])[0])[1])[1]    \n",
    "\n",
    "        beaux_text = BeautifulSoup(art.text, \"html5lib\")\n",
    "        art.text = delcom.sub(\"\", beaux_text.get_text() )\n",
    "        art.text = art.text.replace('\\xa0', ' ')\n",
    "        return art\n",
    "\n",
    "    def getNPlus1Day(self, adr):\n",
    "        r = requests.get(adr)\n",
    "        titles = BeautifulSoup(r.text, \"html5lib\")(\"article\")\n",
    "        addrs = [\"https://nplus1.ru/\"+a(\"a\")[0][\"href\"] for a in titles]\n",
    "        for adr in addrs:\n",
    "            aa=self.getArticleTextNPlus1(adr)\n",
    "            self.articles.append(aa)\n",
    "        \n",
    "    # –ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö —Å—Ç–∞—Ç–µ–π –∑–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ –¥–Ω–µ–π.\n",
    "    def getNPlus1Period(self, start, finish):\n",
    "        curdate=start\n",
    "        while curdate<=finish:\n",
    "            print(curdate.strftime('%Y/%m/%d')) # Just in case.\n",
    "            # –°–ø–∏—Å–æ–∫ —Å—Ç–∞—Ç–µ–π –≥—Ä—É–∑–∏—Ç—Å—è —Å –≤–æ—Ç —Ç–∞–∫–æ–≥–æ –∞–¥—Ä–µ—Å–∞.\n",
    "            self.getNPlus1Day('https://nplus1.ru/news/'+curdate.strftime('%Y/%m/%d'))\n",
    "            curdate+=datetime.timedelta(days=1)\n",
    "\n",
    "    def getPeriod(self, start, finish):\n",
    "        self.getNPlus1Period(start, finish)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n1=GetNPlus1()\n",
    "#filename=\"nplus1_test.txt\"\n",
    "n1 = GetLenta()\n",
    "filename = \"lenta_test.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ê —Ç–µ–ø–µ—Ä—å –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —É–≥–∞–¥–∞—Ç—å –¥–ª—è –∫–∞–∫–æ–≥–æ –∫–ª–∞—Å—Å–∞ –±—ã–ª –≤—ã–ø–æ–ª–Ω–µ–Ω —ç—Ç–æ—Ç –∫–æ–¥?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/02/01\n",
      "2018/02/02\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n1.getPeriod(datetime.date(2018, 2, 1), datetime.date(2018, 2, 2))\n",
    "n1.saveArticles(filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ê–±—Å—Ç—Ä–∞–∫—Ç–Ω—ã–µ –º–µ—Ç–æ–¥—ã –∏ –∫–ª–∞—Å—Å—ã"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–¢–µ–ø–µ—Ä—å —Å–¥–µ–ª–∞–µ–º —Ç–∞–∫, —á—Ç–æ–±—ã –æ–±—ä–µ–∫—Ç—ã –±–∞–∑–æ–≤–æ–≥–æ –∫–ª–∞—Å—Å–∞ –Ω–µ–ª—å–∑—è –±—ã–ª–æ —Å–æ–∑–¥–∞–≤–∞—Ç—å. –≠—Ç–æ –Ω–µ —Å–æ–≤—Å–µ–º —Ö–æ—Ä–æ—à–æ –∏–º–µ–Ω–Ω–æ –¥–ª—è –Ω–∞—à–µ–≥–æ —Å–ª—É—á–∞—è, –Ω–æ –¥–ª—è —É—á–µ–±–Ω—ã—Ö —Ü–µ–ª–µ–π –Ω–æ—Ä–º–∞–ª—å–Ω–æ.\n",
    "\n",
    "–ü–æ–¥–∫–ª—é—á–∏–º –∞–±—Å—Ç—Ä–∞–∫—Ç–Ω—ã–µ –∫–ª–∞—Å—Å—ã –∏–∑ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ ABC (Abstract Base Classes) –∏ –¥–µ–∫–æ—Ä–∞—Ç–æ—Ä abstractmethod. –¢–µ–ø–µ—Ä—å –º–µ—Ç–æ–¥ `getPeriod` –±—É–¥–µ—Ç –∞–±—Å—Ç—Ä–∞–∫—Ç–Ω—ã–º, —Ç–æ –µ—Å—Ç—å –æ–Ω –Ω–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω. –ò–∑-–∑–∞ —ç—Ç–æ–≥–æ (–∏ –Ω–∞—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –æ—Ç ABC) –∫–ª–∞—Å—Å BaseGetNewsPaper –±—É–¥–µ—Ç –∞–±—Å—Ç—Ä–∞–∫—Ç–Ω—ã–º, —Ç–æ –µ—Å—Ç—å –µ–≥–æ –æ–±—ä–µ–∫—Ç—ã –Ω–µ–ª—å–∑—è —Å–æ–∑–¥–∞–≤–∞—Ç—å."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseGetNewsPaper(ABC):\n",
    "        \n",
    "    # –ö–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä - –≤—ã–∑—ã–≤–∞–µ—Ç—Å—è –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –æ–±—ä–µ–∫—Ç–∞ –∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –µ–≥–æ.\n",
    "    def __init__(self):\n",
    "        self.articles = []     # –ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ —Å—Ç–∞—Ç—å–∏.\n",
    "        self.dictionaries = [] # –°–ª–æ–≤–∞—Ä–∏ –¥–ª—è –∫–∞–∂–¥–æ–π –∏–∑ —Å—Ç–∞—Ç–µ–π.\n",
    "        # –°–æ–∑–¥–∞–µ–º –∏ –∑–∞–≥—Ä—É–∂–∞–µ–º –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —Å–ª–æ–≤–∞—Ä—å.\n",
    "        self.morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "    # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–∞ –¥–ª—è —Å—Ç–∞—Ç—å–∏.\n",
    "    def getArticleDictionary(self, text, needPos=None):\n",
    "        words = [a[0] for a in re.findall(\"([–ê-–Ø–Å–∞-—è—ë]+(-[–ê-–Ø–Å–∞-—è—ë]+)*)\", text)]\n",
    "        reswords = []\n",
    "    \n",
    "        for w in words:\n",
    "            wordform = self.morph.parse(w)[0]\n",
    "            try:\n",
    "                if wordform.tag.POS in ['ADJF', 'NOUN', 'VERB', 'PRTF', 'GRND']:\n",
    "                    if needPos != None:\n",
    "                        reswords.append(wordform.normal_form+'_'+wordform.tag.POS)\n",
    "                    else:\n",
    "                        reswords.append(wordform.normal_form)\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "        stat = Counter(reswords)\n",
    "        # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ —Å–ª–æ–≤–∞ —Å —á–∞—Å—Ç–æ—Ç–æ–π –±–æ–ª—å—à–µ 1.\n",
    "        stat = {a: stat[a] for a in stat.keys() if stat[a]>1}\n",
    "        return stat\n",
    "\n",
    "    # –ü–æ—Å—á–∏—Ç–∞–µ–º –≤–µ–∫—Ç–æ—Ä–∞ –¥–ª—è –≤—Å–µ—Ö —Å—Ç–∞—Ç–µ–π.\n",
    "    def calcArticleDictionaries(self, needPos=None):\n",
    "        self.dictionaries = []\n",
    "        for a in self.articles:\n",
    "            self.dictionaries.append(self.getArticleDictionary(a.text, needPos))\n",
    "            \n",
    "    @abstractmethod\n",
    "    def getPeriod(self, start, finish):\n",
    "        pass\n",
    "    \n",
    "    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç–∞—Ç—å–∏ –≤ —Ñ–∞–π–ª.\n",
    "    def saveArticles(self, filename):\n",
    "        \"\"\" Saves all articles to a file with a filename. \"\"\"\n",
    "        newsfile = open(filename, \"w\")\n",
    "        for art in self.articles:\n",
    "            newsfile.write('\\n=====\\n'+art.title)\n",
    "            newsfile.write('\\n-----\\n'+art.text)\n",
    "        newsfile.close()\n",
    "\n",
    "    # –ß–∏—Ç–∞–µ–º —Å—Ç–∞—Ç—å–∏ –∏–∑ —Ñ–∞–π–ª–∞.\n",
    "    def loadArticles(self, filename):\n",
    "        \"\"\" Loads and replaces all articles from a file with a filename. \"\"\"\n",
    "        newsfile = open(filename, encoding=\"utf-8\")\n",
    "        text = newsfile.read()\n",
    "        loaded = text.split('\\n=====\\n')[1:]\n",
    "        self.articles = []\n",
    "        for i, a in enumerate(loaded):\n",
    "            self.articles.append(BaseArticle())\n",
    "            b, self.articles[i].text = a.split('\\n-----\\n')\n",
    "            self.articles[i].title = b\n",
    "        newsfile.close()\n",
    "        \n",
    "class GetLenta(BaseGetNewsPaper):\n",
    "    # –ó–∞–≥—Ä—É–∑–∫–∞ —Å—Ç–∞—Ç—å–∏ –ø–æ URL.\n",
    "    def getLentaArticle(self, url):\n",
    "        \"\"\" getLentaArticle gets the body of an article from Lenta.ru\"\"\"\n",
    "        # –ü–æ–ª—É—á–∞–µ—Ç —Ç–µ–∫—Å—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—ã.\n",
    "        resp = requests.get(url)\n",
    "        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–µ–∫—Å—Ç –≤ –æ–±—ä–µ–∫—Ç —Ç–∏–ø–∞ BeautifulSoup.\n",
    "        bs = BeautifulSoup(resp.text, \"html5lib\") \n",
    "        \n",
    "        art = BaseArticle()\n",
    "        # –ü–æ–ª—É—á–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Å—Ç–∞—Ç—å–∏.\n",
    "        art.title = bs.h1.text.replace(\"\\xa0\", \" \")\n",
    "        # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç —Å—Ç–∞—Ç—å–∏.\n",
    "        art.text = BeautifulSoup(\" \".join([p.text for p in \n",
    "                                           bs.find_all(\"p\")]), \"html5lib\").get_text().replace(\"\\xa0\", \" \")\n",
    "        return art\n",
    "\n",
    "    # –ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö —Å—Ç–∞—Ç–µ–π –∑–∞ –æ–¥–∏–Ω –¥–µ–Ω—å.\n",
    "    def getLentaDay(self, url):\n",
    "        \"\"\" Gets all URLs for a given day and gets all texts. \"\"\"\n",
    "        try:\n",
    "            # –ì—Ä—É–∑–∏–º —Å—Ç—Ä–∞–Ω–∏—Ü—É —Å–æ —Å–ø–∏—Å–∫–æ–º –≤—Å–µ—Ö —Å—Ç–∞—Ç–µ–π.\n",
    "            day = requests.get(url) \n",
    "            # –ü–æ–ª—É—á–∞–µ–º —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã —Å –Ω—É–∂–Ω—ã–º–∏ –Ω–∞–º –∞–¥—Ä–µ—Å–∞–º–∏ —Å—Ç–∞—Ç–µ–π.\n",
    "            h3s = BeautifulSoup(day.text, \"html5lib\").find_all(\"h3\")\n",
    "            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∞–¥—Ä–µ—Å–∞ –Ω–∞ —Å—Ç–∞—Ç—å–∏ –∑–∞ –¥–µ–Ω—å.\n",
    "            links = [\"http://lenta.ru\"+l.find_all(\"a\")[0][\"href\"] for l in h3s]\n",
    "            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—Ç–∞—Ç—å–∏.\n",
    "            for l in links:\n",
    "                art = self.getLentaArticle(l)\n",
    "                self.articles.append(art)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # –ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö —Å—Ç–∞—Ç–µ–π –∑–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ –¥–Ω–µ–π.\n",
    "    def getLentaPeriod(self, start, finish):\n",
    "        curdate = start\n",
    "        while curdate <= finish:\n",
    "            print(curdate.strftime('%Y/%m/%d')) # Just in case.\n",
    "            # –°–ø–∏—Å–æ–∫ —Å—Ç–∞—Ç–µ–π –≥—Ä—É–∑–∏—Ç—Å—è —Å –≤–æ—Ç —Ç–∞–∫–æ–≥–æ –∞–¥—Ä–µ—Å–∞.\n",
    "            self.getLentaDay('https://lenta.ru/news/'+curdate.strftime('%Y/%m/%d'))\n",
    "            curdate += datetime.timedelta(days=1)\n",
    "\n",
    "    def getPeriod(self, start, finish):\n",
    "        self.getLentaPeriod(start, finish)\n",
    "    \n",
    "\n",
    "class GetNPlus1(BaseGetNewsPaper):\n",
    "    def getArticleTextNPlus1(self, adr):\n",
    "        r = requests.get(adr)\n",
    "        #print(r.text)\n",
    "        art = NPlus1Article()\n",
    "        tables = re.split(\"</div>\",re.split('=\"tables\"', r.text)[1])[0]\n",
    "        t1 = re.split(\"</time>\", re.split(\"<time\", tables)[1])[0]\n",
    "        art.time = re.split(\"</span>\", re.split(\"<span>\", t1)[1])[0]\n",
    "        art.date = re.split(\"</span>\", re.split(\"<span>\", t1)[2])[0]\n",
    "        art.rubr = re.findall(\"<a data-rubric.+?>(.+?)</a>\", r.text)[0]\n",
    "        art.diff = re.split(\"</span>\", re.split('\"difficult-value\">', tables)[1])[0]\n",
    "        art.title = re.findall(\"<h1>(.+?)</h1>\", r.text)[0]\n",
    "        art.author = re.split('\" />',re.split('<meta name=\"author\" content=\"', r.text)[1])[0]\n",
    "        art.text = re.split(\"</div>\", re.split(\"</figure>\", re.split('</article>',re.split('<article', r.text)[1])[0])[1])[1]    \n",
    "\n",
    "        beaux_text = BeautifulSoup(art.text, \"html5lib\")\n",
    "        art.text = delcom.sub(\"\", beaux_text.get_text() )\n",
    "        art.text = art.text.replace('\\xa0', ' ')\n",
    "        return art\n",
    "\n",
    "    def getNPlus1Day(self, adr):\n",
    "        r = requests.get(adr)\n",
    "        titles = BeautifulSoup(r.text, \"html5lib\")(\"article\")\n",
    "        addrs = [\"https://nplus1.ru/\"+a(\"a\")[0][\"href\"] for a in titles]\n",
    "        for adr in addrs:\n",
    "            aa = self.getArticleTextNPlus1(adr)\n",
    "            self.articles.append(aa)\n",
    "        \n",
    "    # –ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö —Å—Ç–∞—Ç–µ–π –∑–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ –¥–Ω–µ–π.\n",
    "    def getNPlus1Period(self, start, finish):\n",
    "        curdate = start\n",
    "        while curdate <= finish:\n",
    "            print(curdate.strftime('%Y/%m/%d')) # Just in case.\n",
    "            # –°–ø–∏—Å–æ–∫ —Å—Ç–∞—Ç–µ–π –≥—Ä—É–∑–∏—Ç—Å—è —Å –≤–æ—Ç —Ç–∞–∫–æ–≥–æ –∞–¥—Ä–µ—Å–∞.\n",
    "            self.getNPlus1Day('https://nplus1.ru/news/'+curdate.strftime('%Y/%m/%d'))\n",
    "            curdate += datetime.timedelta(days=1)\n",
    "\n",
    "    def getPeriod(self, start, finish):\n",
    "        self.getNPlus1Period(start, finish)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Can't instantiate abstract class BaseGetNewsPaper with abstract method getPeriod",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_75332/3146278358.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# –°–æ–∑–¥–∞—Ç—å –Ω–µ –ø–æ–ª—É—á–∏—Ç—Å—è - —Ç–µ–ø–µ—Ä—å —ç—Ç–æ –∞–±—Å—Ç—Ä–∞–∫—Ç–Ω—ã–π –∫–ª–∞—Å—Å.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBaseGetNewsPaper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: Can't instantiate abstract class BaseGetNewsPaper with abstract method getPeriod"
     ]
    }
   ],
   "source": [
    "# –°–æ–∑–¥–∞—Ç—å –Ω–µ –ø–æ–ª—É—á–∏—Ç—Å—è - —Ç–µ–ø–µ—Ä—å —ç—Ç–æ –∞–±—Å—Ç—Ä–∞–∫—Ç–Ω—ã–π –∫–ª–∞—Å—Å.\n",
    "nn = BaseGetNewsPaper()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ê –∑–¥–µ—Å—å –≤—Å—ë –≤ –ø–æ—Ä—è–¥–∫–µ.\n",
    "n1 = GetLenta()\n",
    "n2 = GetNPlus1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1.getPeriod(datetime.date(2018, 2, 1), datetime.date(2018, 2, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## @staticmethod –∏ @classmethod "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–¢–µ–ø–µ—Ä—å –¥–æ–±–∞–≤–∏–º —ç—Ç–∏–º –∫–ª–∞—Å—Å–∞–º –Ω–∞–±–æ—Ä –æ–ø–µ—Ä–∞—Ç–æ—Ä–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ —Å–¥–µ–ª–∞—é—Ç —Ä–∞–±–æ—Ç—É –Ω–∏–º–∏ –±–æ–ª–µ–µ —É–¥–æ–±–Ω–æ–π. –•–æ—Ç—è –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –æ–ø–µ—Ä–∞—Ç–æ—Ä—ã —Å–∫–æ—Ä–µ–µ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –ø–µ—Ä–µ–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ç–æ—Ä–æ–≤.\n",
    "\n",
    "–¢–∞–∫–∂–µ –ø—Ä–∏ –ø–æ–º–æ—â–∏ `@staticmethod` –¥–æ–±–∞–≤–∏–º —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏–π –º–µ—Ç–æ–¥ - –º–µ—Ç–æ–¥, –∫–æ—Ç–æ—Ä—ã–π –º–æ–∂–Ω–æ –≤—ã–∑—ã–≤–∞—Ç—å –±–µ–∑ —Å–æ–∑–¥–∞–Ω–∏—è –æ–±—ä–µ–∫—Ç–∞ –¥–∞–Ω–Ω–æ–≥–æ –∫–ª–∞—Å—Å–∞. –î–ª—è —ç—Ç–æ–≥–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –ª–∏—à—å –Ω–∞–ø–∏—Å–∞—Ç—å –ø–µ—Ä–µ–¥ –≤—ã–∑–æ–≤–æ–º –∏–º—è –∫–ª–∞—Å—Å–∞, –∫ –∫–æ—Ç–æ—Ä–æ–º—É –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –º–µ—Ç–æ–¥. \n",
    "\n",
    "–ü–æ–º–∏–º–æ —ç—Ç–æ–≥–æ, –º–æ–∂–Ω–æ —Å–æ–∑–¥–∞—Ç—å `@classmethod`. –û–Ω —Ç–∞–∫–∂–µ –≤—ã–∑—ã–≤–∞–µ—Ç—Å—è –±–µ–∑ —Å–æ–∑–¥–∞–Ω–∏—è –æ–±—ä–µ–∫—Ç–∞, –Ω–æ –ø—Ä–∏ —ç—Ç–æ–º –≤ –µ–≥–æ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–µ—Ä–µ–¥–∞–µ—Ç—Å—è –∫–ª–∞—Å—Å, –¥–ª—è –∫–æ—Ç–æ—Ä–æ–≥–æ –≤—ã–∑—ã–≤–∞–µ—Ç—Å—è –¥–∞–Ω–Ω—ã–π –º–µ—Ç–æ–¥. –ö–∞–∫ —Å–ª–µ–¥—Å—Ç–≤–∏–µ, –æ–Ω –∏–º–µ–µ—Ç –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –¥–æ—Å—Ç—É–ø–∞ –∫ —Å–≤–æ–π—Å—Ç–≤–∞–º –∫–ª–∞—Å—Å–∞ (–ø—Ä–∞–≤–¥–∞, –º—ã –≤–∏–¥–µ–ª–∏, —á—Ç–æ –º–æ–∂–Ω–æ –∏ —Ç–∞–∫ –ø–æ–ª—É—á–∏—Ç—å –∫ –Ω–∏–º –¥–æ—Å—Ç—É–ø, –Ω–æ —Ä–∞–∑–Ω–∏—Ü–∞ –ø–æ—è–≤–∏—Ç—Å—è –¥–ª—è –∑–∞–∫—Ä—ã—Ç—ã—Ö —á–ª–µ–Ω–æ–≤)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pymorphy2.analyzer.MorphAnalyzer"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = pymorphy2.MorphAnalyzer()\n",
    "type(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å —Å—Ç–∞—Ç—å–∏, –æ–Ω –∂–µ –∫–ª–∞—Å—Å —Å—Ç–∞—Ç—å–∏ –¥–ª—è –õ–µ–Ω—Ç—ã.—Ä—É\n",
    "class BaseArticle:\n",
    "    def __init__(self, _title=None, _text=None):\n",
    "        \"\"\"–ö–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä –¥–ª—è –±–∞–∑–æ–≤–æ–≥–æ –∫–ª–∞—Å—Å–∞ —Å—Ç–∞—Ç—å–∏. –ó–∞–≤–æ–¥–∏—Ç –ø–æ–ª—è title –∏ text.\"\"\"\n",
    "        if isinstance(_title, str) and isinstance(_text, str):\n",
    "            self.title=_title\n",
    "            self.text=_text\n",
    "        else:\n",
    "            self.title=\"\"\n",
    "            self.text=\"\"\n",
    "        \n",
    "    # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ JSON.\n",
    "    def toJSON(self):\n",
    "        \"\"\"–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –±–∞–∑–æ–≤–æ–π —Å—Ç–∞—Ç—å–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ —Å—Ç—Ä–æ–∫–∏ JSON.\"\"\"\n",
    "        res='{\"title\":\"'+self.title.replace('\"', '\\\\\"')+'\",\"text\":\"'+self.text.replace('\"', '\\\\\"')+'\"}'\n",
    "        return res\n",
    "\n",
    "    # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ —Å–ª–æ–≤–∞—Ä—å.\n",
    "    def toDict(self):\n",
    "        \"\"\"–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –±–∞–∑–æ–≤–æ–π —Å—Ç–∞—Ç—å–∏ –≤ –≤–∏–¥–µ —Å–ª–æ–≤–∞—Ä—è.\"\"\"\n",
    "        res={\"title\":self.title.replace('\"', '\\\\\"'), \"text\":self.text.replace('\"', '\\\\\"')}\n",
    "        return res\n",
    "    \n",
    "    # –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç—Ä–æ–∫–æ–≤–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—å–∏ –µ—Å–ª–∏ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç—Å—è –∫ —Å—Ç—Ä–æ–∫–µ –ø—Ä–∏ –ø–æ–º–æ—â–∏ str(article)\n",
    "    # –∏–ª–∏ print(article).\n",
    "    def __str__(self):\n",
    "        \"\"\"–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç—Ä–æ–∫—É –∏–∑ 200 –ø–µ—Ä–≤—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤ –∑–∞–≥–æ–ª–æ–≤–∫–∞ —Å—Ç–∞—Ç—å–∏ –∏ 200 –ø–µ—Ä–≤—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤ —Å–∞–º–æ–π —Å—Ç–∞—Ç—å–∏.\"\"\"\n",
    "        return '<title: '+self.title[:200]+'\\ntext: '+self.text[:200]+'... >'\n",
    "\n",
    "    # –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç—Ä–æ–∫–æ–≤–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—å–∏ –µ—Å–ª–∏ –º—ã –ø—Ä–æ—Å–∏–º —Å—Ä–µ–¥—É –æ—Ç–æ–±—Ä–∞–∑–∏—Ç—å —Å—Ç–∞—Ç—å—é —å–µ–∑ print.\n",
    "    def __repr__(self):\n",
    "        \"\"\"–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç—Ä–æ–∫—É –∏–∑ 100 –ø–µ—Ä–≤—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤ –∑–∞–≥–æ–ª–æ–≤–∫–∞ –∫–∞–∫ –∫—Ä–∞—Ç–∫–æ–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—å–∏.\"\"\"\n",
    "        return '<Base Article on \"'+self.title[:100]+'\">'\n",
    "    \n",
    "    \n",
    "class NPlus1Article(BaseArticle):\n",
    "    def __init__(self):\n",
    "        \"\"\"–ö–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä –¥–ª—è –±–∞–∑–æ–≤–æ–≥–æ –∫–ª–∞—Å—Å–∞ —Å—Ç–∞—Ç—å–∏. –ó–∞–≤–æ–¥–∏—Ç –ø–æ–ª—è title, text, date, time, rubr, diff –∏ author.\"\"\"\n",
    "        # –í—ã–∑—ã–≤–∞–µ–º –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä –æ—Ç –±–∞–∑–æ–≤–æ–≥–æ –∫–ª–∞—Å—Å–∞.\n",
    "        super().__init__()\n",
    "        self.time = \"\"\n",
    "        self.date = \"\"\n",
    "        self.rubr = \"\"\n",
    "        self.diff = \"\"\n",
    "        self.author = \"\"\n",
    "        \n",
    "    # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ JSON.\n",
    "    def toJSON(self):\n",
    "        \"\"\"–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –±–∞–∑–æ–≤–æ–π —Å—Ç–∞—Ç—å–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ —Å—Ç—Ä–æ–∫–∏ JSON.\"\"\"\n",
    "        res = f'{{\"date\":\"{self.date}\", \"time\":\"{self.time}\", \"rubrics\":\"{self.rubr}\", \"difficulty\":\"'\n",
    "        res += f'{self.diff}\", \"title\":\"{self.title}\", \"author\":\"{self.author}\",\"text\":\"'\n",
    "        res += self.text.replace('\"', '\\\\\"')+'\"}'\n",
    "        return res\n",
    "\n",
    "    # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ —Å–ª–æ–≤–∞—Ä—å.\n",
    "    def toDict(self):\n",
    "        \"\"\"–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –±–∞–∑–æ–≤–æ–π —Å—Ç–∞—Ç—å–∏ –≤ –≤–∏–¥–µ —Å–ª–æ–≤–∞—Ä—è.\"\"\"\n",
    "        res = {\"date\":self.date, \"time\":self.time, \"rubrics\":self.rubr, \"difficulty\":self.diff,\\\n",
    "               \"title\":self.title, \"author\":self.author,\"text\":self.text.replace('\"', '\\\\\"')}\n",
    "        return res\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\"–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç—Ä–æ–∫—É –∏–∑ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –æ —Å—Ç–∞—Ç—å–µ, 200 –ø–µ—Ä–≤—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤ –∑–∞–≥–æ–ª–æ–≤–∫–∞ —Å—Ç–∞—Ç—å–∏ \n",
    "           –∏ 200 –ø–µ—Ä–≤—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤ —Å–∞–º–æ–π —Å—Ç–∞—Ç—å–∏.\"\"\"\n",
    "        res = f'<date:\"{self.date} : {self.time}\\nrubrics: {self.rubr}\\ndifficulty: {self.diff}'\n",
    "              f'\\nauthor: {self.author}\\ntitle: {self.title[:100]}\\ntext: {self.text[:100]}>'\n",
    "        return res\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç—Ä–æ–∫—É –∏–∑ 100 –ø–µ—Ä–≤—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤ –∑–∞–≥–æ–ª–æ–≤–∫–∞ –∫–∞–∫ –∫—Ä–∞—Ç–∫–æ–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—å–∏.\"\"\"\n",
    "        return '<NPlus1 Article on \"' + self.title[:100] + '\">'\n",
    "    \n",
    "    \n",
    "# –ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è –∑–∞–≥—Ä—É–∑—á–∏–∫–æ–≤ –Ω–æ–≤–æ—Å—Ç–µ–π.\n",
    "# –í –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö —Ü–µ–ª—è—Ö —Å–¥–µ–ª–∞–Ω –∫–∞–∫ –∞–±—Å—Ç—Ä–∞–∫—Ç–Ω—ã–π –∫–ª–∞—Å—Å, —Ç–æ –µ—Å—Ç—å –∫–ª–∞—Å—Å, –æ–±—ä–µ–∫—Ç—ã –∫–æ—Ç–æ—Ä–æ–≥–æ –Ω–µ–ª—å–∑—è —Å–æ–∑–¥–∞–≤–∞—Ç—å.\n",
    "# –ú–æ–∂–Ω–æ —É–Ω–∞—Å–ª–µ–¥–æ–≤–∞—Ç—å—Å—è, –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∞–±—Å—Ç—Ä–∞–∫—Ç–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ (–æ—Ç–º–µ—á–µ–Ω—ã –¥–µ–∫–æ—Ä–∞—Ç–æ—Ä–æ–º @abstractmethod).\n",
    "# –ü–æ-—Ö–æ—Ä–æ—à–µ–º—É, –º–æ–∂–Ω–æ –±—ã–ª–æ –±—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–ª—è —Ç–æ–≥–æ, —á—Ç–æ–±—ã –ø—Ä–æ—á–∏—Ç–∞—Ç—å –Ω–æ–≤–æ—Å—Ç–∏ –∏ —Ä–∞–±–æ—Ç–∞—Ç—å —Å –Ω–∏–º–∏.\n",
    "# –£–º–µ–µ—Ç –ø–æ—Å—á–∏—Ç–∞—Ç—å —á–∞—Å—Ç–æ—Ç–Ω—ã–µ –≤–µ–∫—Ç–æ—Ä–∞ —Å—Ç–∞—Ç–µ–π.\n",
    "class BaseGetNewsPaper(ABC):\n",
    "        \n",
    "    cntr = 0 # !!! –≠—Ç–æ —á–ª–µ–Ω –∫–ª–∞—Å—Å–∞ !!!\n",
    "    \n",
    "    # –ö–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä - –≤—ã–∑—ã–≤–∞–µ—Ç—Å—è –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –æ–±—ä–µ–∫—Ç–∞ –∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –µ–≥–æ.\n",
    "    def __init__(self, data=None):\n",
    "        \"\"\"–ö–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä –æ–±—ä–µ–∫—Ç–æ–≤ –∫–ª–∞—Å—Å–∞ BaseGetNewsPaper. \n",
    "           –ú–æ–∂–µ—Ç –ø—Ä–∏–Ω–∏–º–∞—Ç—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—â–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Ç–∏–ø–∞ BaseGetNewsPaper (—Å–æ–∑–¥–∞–µ—Ç –∫–æ–ø–∏—é)\n",
    "           –∏ list (–≤ —ç—Ç–æ–º —Å–ª—É—á–∞–µ –æ—Å—Ç–∞–≤–ª—è–µ—Ç –∑–∞–≥–æ–ª–æ–≤–∫–∏ –ø—É—Å—Ç—ã–º–∏).\"\"\"\n",
    "        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏–ø –ø–µ—Ä–µ–¥–∞–Ω–Ω–æ–≥–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ –∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –Ω–µ–≥–æ –ø–æ-—Ä–∞–∑–Ω–æ–º—É –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –æ–±—ä–µ–∫—Ç.\n",
    "        if data == None:\n",
    "            self.articles = []\n",
    "            self.dictionaries = []\n",
    "        if isinstance(data, BaseGetNewsPaper):\n",
    "            self.articles = copy(data.articles)\n",
    "            self.dictionaries = copy(data.dictionaries)\n",
    "        elif isinstance(data, list):\n",
    "            self.articles = copy(data)\n",
    "            self.dictionaries = []\n",
    "        # –í –ª—é–±–æ–º —Å–ª—É—á–∞–µ —Å–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç –º–æ—Ä—Ñ–æ–ª–æ–≥–∏–∏ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —á–∞—Å—Ç–æ—Ç–Ω—ã—Ö –≤–µ–∫—Ç–æ—Ä–æ–≤.\n",
    "        self.__morph = pymorphy2.MorphAnalyzer()\n",
    "        self.__ttt = 1\n",
    "        \n",
    "        BaseGetNewsPaper.cntr += 1\n",
    "        \n",
    "    @classmethod\n",
    "    def getCounter(cls):\n",
    "        return cls.cntr\n",
    "\n",
    "    # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–∞ –¥–ª—è —Å—Ç–∞—Ç—å–∏.\n",
    "    def getArticleDictionary(self, text, needPos=None):\n",
    "        \"\"\"–°—Ç—Ä–æ–∏—Ç —á–∞—Å—Ç–æ—Ç–Ω—ã–µ –≤–µ–∫—Ç–æ—Ä—ã –¥–ª—è —Ç–µ–∫—Å—Ç–∞ —Å—Ç–∞—Ç—å–∏, –±–µ—Ä–µ—Ç —Ç–æ–ª—å–∫–æ –∑–Ω–∞—á–∏–º—ã–µ —á–∞—Å—Ç–∏ —Ä–µ—á–∏.\"\"\"\n",
    "        words=[a[0] for a in re.findall(\"([–ê-–Ø–Å–∞-—è—ë]+(-[–ê-–Ø–Å–∞-—è—ë]+)*)\", text)]\n",
    "        reswords=[]\n",
    "    \n",
    "        for w in words:\n",
    "            wordform=self.morph.parse(w)[0]\n",
    "            try:\n",
    "                if wordform.tag.POS in ['ADJF', 'NOUN', 'VERB', 'PRTF', 'GRND']:\n",
    "                    if needPos!=None:\n",
    "                        reswords.append(wordform.normal_form+'_'+wordform.tag.POS)\n",
    "                    else:\n",
    "                        reswords.append(wordform.normal_form)\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "        stat=Counter(reswords)\n",
    "        # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ —Å–ª–æ–≤–∞ —Å —á–∞—Å—Ç–æ—Ç–æ–π –±–æ–ª—å—à–µ 1.\n",
    "        stat={a: stat[a] for a in stat.keys() if stat[a]>1}\n",
    "        return stat\n",
    "\n",
    "    @staticmethod\n",
    "    def getIPoS():\n",
    "        return ['ADJF', 'NOUN', 'VERB', 'PRTF', 'GRND']\n",
    "    \n",
    "    def getIPoS2():\n",
    "        return ['ADJF', 'NOUN', 'VERB', 'PRTF', 'GRND']\n",
    "    \n",
    "    # –ü–æ—Å—á–∏—Ç–∞–µ–º –≤–µ–∫—Ç–æ—Ä–∞ –¥–ª—è –≤—Å–µ—Ö —Å—Ç–∞—Ç–µ–π.\n",
    "    def calcArticleDictionaries(self, needPos=None):\n",
    "        \"\"\"–°—Ç—Ä–æ–∏—Ç —á–∞—Å—Ç–æ—Ç–Ω—ã–µ –≤–µ–∫—Ç–æ—Ä–∞ –¥–ª—è –≤—Å–µ—Ö —Å—Ç–∞—Ç–µ–π –≤ –∫–æ–ª–ª–µ–∫—Ü–∏–∏.\n",
    "           !!! –ù–µ —è—Å–Ω–æ —á—Ç–æ –¥–µ–ª–∞—Ç—å, –∫–æ–≥–¥–∞ –ø–æ–ø–æ–ª–Ω—è–µ–º. \n",
    "               –ü–æ-—Ö–æ—Ä–æ—à–µ–º—É –Ω–∞–¥–æ —Ö—Ä–∞–Ω–∏—Ç—å —Å–≤–æ–π—Å—Ç–≤–æ, –∫–æ—Ç–æ—Ä–æ–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç \n",
    "               –Ω–∞–¥–æ –ª–∏ –∏—Ö —Å—á–∏—Ç–∞—Ç—å –¥–ª—è –≤—Å–µ—Ö —Å—Ç–∞—Ç–µ–π –ø—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ –∏–ª–∏ –Ω–µ—Ç. !!!\"\"\"\n",
    "        self.dictionaries=[]\n",
    "        for a in self.articles:\n",
    "            self.dictionaries.append(self.getArticleDictionary(a.text, needPos))\n",
    "            \n",
    "    # –ê–±—Å—Ç—Ä–∞–∫—Ç–Ω—ã–π –º–µ—Ç–æ–¥ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –Ω–æ–≤–æ—Å—Ç–µ–π –∑–∞ –∑–∞–¥–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥.\n",
    "    # –î–æ–ª–∂–µ–Ω –±—ã—Ç—å —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω –≤ –¥–æ—á–µ—Ä–Ω–µ–º –∫–ª–∞—Å—Å–µ.\n",
    "    @abstractmethod\n",
    "    def getPeriod(self, start, finish):\n",
    "        \"\"\"–ê–±—Å—Ç—Ä–∞–∫—Ç–Ω—ã–π –º–µ—Ç–æ–¥ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –Ω–æ–≤–æ—Å—Ç–µ–π –∑–∞ –∑–∞–¥–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥.\n",
    "           –î–æ–ª–∂–µ–Ω –±—ã—Ç—å —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω –≤ –¥–æ—á–µ—Ä–Ω–µ–º –∫–ª–∞—Å—Å–µ.\"\"\"\n",
    "        pass\n",
    "\n",
    "    # –ê–±—Å—Ç—Ä–∞–∫—Ç–Ω—ã–π –º–µ—Ç–æ–¥ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –æ–¥–Ω–æ–π –Ω–æ–≤–æ—Å—Ç–∏ –ø–æ –µ–µ –∞–¥—Ä–µ—Å—É.\n",
    "    # –î–æ–ª–∂–µ–Ω –±—ã—Ç—å —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω –≤ –¥–æ—á–µ—Ä–Ω–µ–º –∫–ª–∞—Å—Å–µ.\n",
    "    @abstractmethod\n",
    "    def getArticle(self, url):\n",
    "        \"\"\"–ê–±—Å—Ç—Ä–∞–∫—Ç–Ω—ã–π –º–µ—Ç–æ–¥ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –æ–¥–Ω–æ–π –Ω–æ–≤–æ—Å—Ç–∏ –ø–æ –µ–µ –∞–¥—Ä–µ—Å—É.\n",
    "        –î–æ–ª–∂–µ–Ω –±—ã—Ç—å —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω –≤ –¥–æ—á–µ—Ä–Ω–µ–º –∫–ª–∞—Å—Å–µ.\"\"\"\n",
    "        pass\n",
    "\n",
    "    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç–∞—Ç—å–∏ –≤ —Ñ–∞–π–ª.\n",
    "    def saveArticles(self, filename):\n",
    "        \"\"\"–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å—Ç–∞—Ç—å—é –≤ —Ñ–∞–π–ª —Å –∏–º–µ–Ω–µ–º filename. \n",
    "           –°—Ç–∞—Ç—å–∏ –æ—Ç–¥–µ–ª–µ–Ω—ã –¥—Ä—É–≥ –æ—Ç –¥—Ä—É–≥–∞ —Å—Ç—Ä–æ–∫–æ–π \"=====\", –∑–∞–≥–æ–ª–æ–≤–æ–∫ –æ—Ç —Å—Ç–∞—Ç—å–∏ —Å—Ç—Ä–æ–∫–æ–π \"-----\". \"\"\"\n",
    "        newsfile = open(filename, \"w\")\n",
    "        for art in self.articles:\n",
    "            newsfile.write('\\n=====\\n'+art.title)\n",
    "            newsfile.write('\\n-----\\n'+art.text)\n",
    "        newsfile.close()\n",
    "\n",
    "    # –ß–∏—Ç–∞–µ–º —Å—Ç–∞—Ç—å–∏ –∏–∑ —Ñ–∞–π–ª–∞.\n",
    "    def loadArticles(self, filename):\n",
    "        \"\"\" Loads and replaces all articles from a file with a filename. \"\"\"\n",
    "        newsfile = open(filename, encoding=\"utf-8\")\n",
    "        text = newsfile.read()\n",
    "        loaded = text.split('\\n=====\\n')[1:]\n",
    "        self.articles=[]\n",
    "        for i, a in enumerate(loaded):\n",
    "            self.articles.append(BaseArticle())\n",
    "            b, self.articles[i].text = a.split('\\n-----\\n')\n",
    "            self.articles[i].title = b\n",
    "        newsfile.close()\n",
    "        \n",
    "    # –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å–∫–æ–ª—å–∫–æ —Å—Ç–∞—Ç–µ–π –∑–∞–≥—Ä—É–∂–µ–Ω–æ.\n",
    "    def __len__(self):\n",
    "        return len(self.articles)\n",
    "    \n",
    "    # –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç—å—é, –µ—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω–æ —Ü–µ–ª–æ–µ —á–∏—Å–ª–æ –∏–ª–∏ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ —Å—Ç–∞—Ç–µ–π, –µ—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω slice.\n",
    "    def __getitem__(self, index):\n",
    "        if type(index)==slice:\n",
    "            return type(self)(self.articles[index])\n",
    "        else:\n",
    "            return self.articles[index]\n",
    "        \n",
    "    def __getattr__(self, prop):\n",
    "        if len(prop)==1:\n",
    "            if prop==prop.lower():\n",
    "                return self.articles[ord(prop)-ord('a')].text\n",
    "            else:\n",
    "                return self.articles[ord(prop)-ord('A')].title\n",
    "            \n",
    "    def __lshift__(self, art):\n",
    "        # –ó–¥–µ—Å—å –Ω–∞–¥–æ —á—Ç–æ-—Ç–æ –¥–µ–ª–∞—Ç—å —Å–æ —Å–ª–æ–≤–∞—Ä—è–º–∏.\n",
    "        if isinstance(art, BaseArticle):\n",
    "            self.articles.append(art)\n",
    "        elif isinstance(art, str):\n",
    "            a1=BaseArticle()\n",
    "            a1.text=art\n",
    "            a1.title=\"No Title\"\n",
    "            self.articles.append(a1)\n",
    "        else:\n",
    "            raise NotImplementedError(\"Should be String or BaseArticle\")\n",
    "        return self\n",
    "        \n",
    "    def __iadd__(self, art):\n",
    "        return self<<art\n",
    "    \n",
    "    def __add__(self, art):\n",
    "        t=type(self)(self) # mtype=type(self), t=mtype(), t=self\n",
    "        t+=art\n",
    "        return t\n",
    "\n",
    "    def __radd__(self, art):\n",
    "        t=type(self)(self)\n",
    "        t+=art\n",
    "        return t\n",
    "    \n",
    "    @abstractmethod\n",
    "    def __str__(self):\n",
    "        pass\n",
    "    \n",
    "    def __call__(self):\n",
    "        return len(self.articles)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for art in self.articles:\n",
    "            yield art\n",
    "        return\n",
    "    \n",
    "    @property\n",
    "    def morph(self):\n",
    "        return self.__morph\n",
    "\n",
    "    @morph.setter\n",
    "    def morph(self, m):\n",
    "        if type(m) == pymorphy2.analyzer.MorphAnalyzer:\n",
    "            self.__morph = m\n",
    "            \n",
    "\n",
    "class GetLenta(BaseGetNewsPaper):\n",
    "    # –ó–∞–≥—Ä—É–∑–∫–∞ —Å—Ç–∞—Ç—å–∏ –ø–æ URL.\n",
    "    def getLentaArticle(self, url):\n",
    "        \"\"\" getLentaArticle gets the body of an article from Lenta.ru\"\"\"\n",
    "        # –ü–æ–ª—É—á–∞–µ—Ç —Ç–µ–∫—Å—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—ã.\n",
    "        resp=requests.get(url)\n",
    "        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–µ–∫—Å—Ç –≤ –æ–±—ä–µ–∫—Ç —Ç–∏–ø–∞ BeautifulSoup.\n",
    "        bs=BeautifulSoup(resp.text, \"html5lib\") \n",
    "        \n",
    "        art=BaseArticle()\n",
    "        # –ü–æ–ª—É—á–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Å—Ç–∞—Ç—å–∏.\n",
    "        art.title=bs.h1.text.replace(\"\\xa0\", \" \")\n",
    "        # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç —Å—Ç–∞—Ç—å–∏.\n",
    "        art.text=BeautifulSoup(\" \".join([p.text for p in bs.find_all(\"p\")]), \"html5lib\").get_text().replace(\"\\xa0\", \" \")\n",
    "        return art\n",
    "\n",
    "    # –ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö —Å—Ç–∞—Ç–µ–π –∑–∞ –æ–¥–∏–Ω –¥–µ–Ω—å.\n",
    "    def getLentaDay(self, url):\n",
    "        \"\"\" Gets all URLs for a given day and gets all texts. \"\"\"\n",
    "        try:\n",
    "            # –ì—Ä—É–∑–∏–º —Å—Ç—Ä–∞–Ω–∏—Ü—É —Å–æ —Å–ø–∏—Å–∫–æ–º –≤—Å–µ—Ö —Å—Ç–∞—Ç–µ–π.\n",
    "            day = requests.get(url) \n",
    "            # –ü–æ–ª—É—á–∞–µ–º —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã —Å –Ω—É–∂–Ω—ã–º–∏ –Ω–∞–º –∞–¥—Ä–µ—Å–∞–º–∏ —Å—Ç–∞—Ç–µ–π.\n",
    "            h3s=BeautifulSoup(day.text, \"html5lib\").find_all(\"h3\")\n",
    "            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∞–¥—Ä–µ—Å–∞ –Ω–∞ —Å—Ç–∞—Ç—å–∏ –∑–∞ –¥–µ–Ω—å.\n",
    "            links=[\"http://lenta.ru\"+l.find_all(\"a\")[0][\"href\"] for l in h3s]\n",
    "            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—Ç–∞—Ç—å–∏.\n",
    "            for l in links:\n",
    "                art=self.getLentaArticle(l)\n",
    "                self.articles.append(art)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # –ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö —Å—Ç–∞—Ç–µ–π –∑–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ –¥–Ω–µ–π.\n",
    "    def getLentaPeriod(self, start, finish):\n",
    "        curdate=start\n",
    "        while curdate<=finish:\n",
    "            print(curdate.strftime('%Y/%m/%d')) # Just in case.\n",
    "            # –°–ø–∏—Å–æ–∫ —Å—Ç–∞—Ç–µ–π –≥—Ä—É–∑–∏—Ç—Å—è —Å –≤–æ—Ç —Ç–∞–∫–æ–≥–æ –∞–¥—Ä–µ—Å–∞.\n",
    "            self.getLentaDay('https://lenta.ru/news/'+curdate.strftime('%Y/%m/%d'))\n",
    "            curdate+=datetime.timedelta(days=1)\n",
    "\n",
    "    def getPeriod(self, start, finish):\n",
    "        self.getLentaPeriod(start, finish)\n",
    "        \n",
    "    def __str__(self):\n",
    "        return \"<Lenta.ru scrapper: \"+str(len(self.articles))+\" articles loaded>\"\n",
    "    \n",
    "    def getArticle(self, url):\n",
    "        if \"lenta.ru\" in url.lower():\n",
    "            self.lower().getLentaArticle(url)\n",
    "        else:\n",
    "            raise NotImplementedError(\"I can download from Lenta.ru site only.\")\n",
    "            \n",
    "\n",
    "class GetNPlus1(BaseGetNewsPaper):\n",
    "    def getArticleTextNPlus1(self, adr):\n",
    "        r = requests.get(adr)\n",
    "        #print(r.text)\n",
    "        art = NPlus1Article()\n",
    "        tables = re.split(\"</div>\",re.split('=\"tables\"', r.text)[1])[0]\n",
    "        t1 = re.split(\"</time>\", re.split(\"<time\", tables)[1])[0]\n",
    "        art.time = re.split(\"</span>\", re.split(\"<span>\", t1)[1])[0]\n",
    "        art.date = re.split(\"</span>\", re.split(\"<span>\", t1)[2])[0]\n",
    "        art.rubr = re.findall(\"<a data-rubric.+?>(.+?)</a>\", r.text)[0]\n",
    "        art.diff = re.split(\"</span>\", re.split('\"difficult-value\">', tables)[1])[0]\n",
    "        art.title = re.findall(\"<h1>(.+?)</h1>\", r.text)[0]\n",
    "        art.author = re.split('\" />',re.split('<meta name=\"author\" content=\"', r.text)[1])[0]\n",
    "        art.text = re.split(\"</div>\", re.split(\"</figure>\", re.split('</article>',re.split('<article', r.text)[1])[0])[1])[1]    \n",
    "\n",
    "        beaux_text = BeautifulSoup(art.text, \"html5lib\")\n",
    "        art.text = delcom.sub(\"\", beaux_text.get_text() )\n",
    "        art.text = art.text.replace('\\xa0', ' ')\n",
    "        return art\n",
    "\n",
    "    def getNPlus1Day(self, adr):\n",
    "        r = requests.get(adr)\n",
    "        titles = BeautifulSoup(r.text, \"html5lib\")(\"article\")\n",
    "        addrs = [\"https://nplus1.ru/\"+a(\"a\")[0][\"href\"] for a in titles]\n",
    "        for adr in addrs:\n",
    "            aa=self.getArticleTextNPlus1(adr)\n",
    "            self.articles.append(aa)\n",
    "        \n",
    "    # –ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö —Å—Ç–∞—Ç–µ–π –∑–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ –¥–Ω–µ–π.\n",
    "    def getNPlus1Period(self, start, finish):\n",
    "        curdate=start\n",
    "        while curdate<=finish:\n",
    "            print(curdate.strftime('%Y/%m/%d')) # Just in case.\n",
    "            # –°–ø–∏—Å–æ–∫ —Å—Ç–∞—Ç–µ–π –≥—Ä—É–∑–∏—Ç—Å—è —Å –≤–æ—Ç —Ç–∞–∫–æ–≥–æ –∞–¥—Ä–µ—Å–∞.\n",
    "            self.getNPlus1Day('https://nplus1.ru/news/'+curdate.strftime('%Y/%m/%d'))\n",
    "            curdate+=datetime.timedelta(days=1)\n",
    "\n",
    "    def getPeriod(self, start, finish):\n",
    "        self.getNPlus1Period(start, finish)\n",
    "        \n",
    "    def __str__(self):\n",
    "        return \"<NPlus1.ru scrapper: \"+str(len(self.articles))+\" articles loaded>\"\n",
    "\n",
    "    def getArticle(self, url):\n",
    "        if \"nplus1.ru\" in url.lower():\n",
    "            return self.getArticleTextNPlus1(url)\n",
    "        else:\n",
    "            raise NotImplementedError(\"I can download from Lenta.ru site only.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BaseGetNewsPaper.cntr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 = GetNPlus1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n1.cntr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "getIPoS2() takes 0 positional arguments but 1 was given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_864515/3105283710.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# BaseGetNewsPaper.getIPoS()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mn1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetIPoS2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: getIPoS2() takes 0 positional arguments but 1 was given"
     ]
    }
   ],
   "source": [
    "# BaseGetNewsPaper.getIPoS()\n",
    "n1.getIPoS2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ADJF', 'NOUN', 'VERB', 'PRTF', 'GRND']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BaseGetNewsPaper.getIPoS2()\n",
    "# n1.getIPoS2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pymorphy2.analyzer.MorphAnalyzer object at 0x7f9694b7ff70>\n",
      "<pymorphy2.analyzer.MorphAnalyzer object at 0x7f9694b7ff70>\n"
     ]
    }
   ],
   "source": [
    "print(n1.morph)\n",
    "n1.morph = 1\n",
    "print(n1.morph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title: 123\n",
      "text: ... > <title: 321\n",
      "text: ... >\n",
      "<title: \n",
      "text: ... >\n"
     ]
    }
   ],
   "source": [
    "a1=BaseArticle()\n",
    "a2=BaseArticle()\n",
    "a1.title=\"123\"\n",
    "a2.title=\"321\"\n",
    "print(a1, a2)\n",
    "a3=BaseArticle(a1, a2)\n",
    "print(a3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title: –ë–µ—Å–ø–∏–ª–æ—Ç–Ω—ã–µ –∞–≤—Ç–æ–º–æ–±–∏–ª–∏ Waymo –æ–∫–∞–∑–∞–ª–∏—Å—å —Å–∞–º—ã–º–∏ —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω—ã–º–∏\n",
      "text: –ë–µ—Å–ø–∏–ª–æ—Ç–Ω—ã–µ –∞–≤—Ç–æ–º–æ–±–∏–ª–∏ –∫–æ–º–ø–∞–Ω–∏–∏ Waymo –æ–∫–∞–∑–∞–ª–∏—Å—å —Å–∞–º—ã–º–∏ —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω—ã–º–∏ –≤ 2017 –≥–æ–¥—É ‚Äî –≤ —Å—Ä–µ–¥–Ω–µ–º –≤–æ–¥–∏—Ç–µ–ª—è–º-–∏—Å–ø—ã—Ç–∞—Ç–µ–ª—è–º –ø—Ä–∏—Ö–æ–¥–∏–ª–æ—Å—å –ø–µ—Ä–µ—Ö–≤–∞—Ç—ã–≤–∞—Ç—å —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –æ–¥–∏–Ω —Ä–∞–∑ –≤ –ø–æ—á—Ç–∏ –¥–µ–≤—è—Ç—å —Ç—ã—Å—è—á –∫–∏–ª–æ–º–µ—Ç—Ä–æ–≤, –≤ —Ç... > \n",
      "\n",
      "<title: –ù–µ—É–ø–æ—Ä—è–¥–æ—á–µ–Ω–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ —à–µ–ª–∫–∞ —Å–¥–µ–ª–∞–ª–∞ –µ–≥–æ –±–ª–µ—Å—Ç—è—â–∏–º –∏ —Ö–æ–ª–æ–¥–Ω—ã–º\n",
      "text: –§–∏–∑–∏–∫–∏ –æ–±–Ω–∞—Ä—É–∂–∏–ª–∏, —á—Ç–æ –±–ª–µ—Å–∫ —à–µ–ª–∫–∞ –≤–æ–∑–Ω–∏–∫–∞–µ—Ç –∏–∑-–∑–∞ –Ω–∞–ª–∏—á–∏—è –≤ –Ω–∏—Ç—è—Ö –Ω–µ—É–ø–æ—Ä—è–¥–æ—á–µ–Ω–Ω—ã—Ö –ø–æ–ª–æ—Å—Ç–µ–π –Ω–∞–Ω–æ–º–µ—Ç—Ä–æ–≤–æ–π —Ç–æ–ª—â–∏–Ω—ã,–Ω–∞ –∫–æ—Ç–æ—Ä—ã—Ö –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –∏–Ω—Ç–µ—Ä—Ñ–µ—Ä–µ–Ω—Ü–∏—è —Å–≤–µ—Ç–∞. –¢–∞ –∂–µ –ø—Ä–∏—á–∏–Ω–∞ –æ–±—ä—è—Å–Ω—è–µ—Ç –∏ —Ç–µ–ø–ª–æ–æ–±–º–µ–Ω –≤ –Ω–∏—Ç—è—Ö... > \n",
      "\n",
      "<title: –ë–µ—Å–ø–∏–ª–æ—Ç–Ω—ã–π –∞–≤—Ç–æ–º–æ–±–∏–ª—å –∏—Å–ø—ã—Ç–∞—é—Ç –±—Ä–∏—Ç–∞–Ω—Å–∫–∏–º–∏ –¥–æ—Ä–æ–≥–∞–º–∏\n",
      "text: –ê–≤—Ç–æ–º–æ–±–∏–ª—å–Ω—ã–µ –∫–æ–º–ø–∞–Ω–∏–∏ Nissan, Renault –∏ Mitsubishi —Å–æ–≤–º–µ—Å—Ç–Ω–æ —Å –£–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç–æ–º –ö—Ä—ç–Ω—Ñ–∏–ª–¥–∞ –∏ —É–ø—Ä–∞–≤–ª—è—é—â–µ–π –∫–æ–º–ø–∞–Ω–∏–µ–π Highways England –æ–±—ä—è–≤–∏–ª–∏ –æ –Ω–∞–º–µ—Ä–µ–Ω–∏–∏ –ø—Ä–æ–≤–µ—Å—Ç–∏ –∏—Å–ø—ã—Ç–∞–Ω–∏—è –±–µ—Å–ø–∏–ª–æ—Ç–Ω–æ–≥–æ –∞–≤—Ç–æ–º–æ–±–∏–ª—è –ª–µ–≤–æ—Å—Ç–æ... > \n",
      "\n",
      "<title: CRISPR –∑–∞—Å—Ç–∞–≤–∏—Ç –±–∏—Ç—å—Å—è —Å–µ—Ä–¥—Ü–∞ –±–æ–ª—å–Ω—ã—Ö –º—ã—à–µ—á–Ω–æ–π –¥–∏—Å—Ç—Ä–æ—Ñ–∏–µ–π –î—é—à–µ–Ω–Ω–∞\n",
      "text: –ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –æ—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–ª–∏ –∫–ª–µ—Ç–∫–∏ —Å–µ—Ä–¥–µ—á–Ω–æ–π –º—ã—à—Ü—ã —Å –º—É—Ç–∞—Ü–∏—è–º–∏, –ø—Ä–∏–≤–æ–¥—è—â–∏–º–∏ –∫ —Ä–∞–∑–≤–∏—Ç–∏—é –º–∏–æ–¥–∏—Å—Ç—Ä–æ—Ñ–∏–∏ –î—é—à–µ–Ω–Ω–∞. –ü—Ä–∏ –ø–æ–º–æ—â–∏ —Å–∏—Å—Ç–µ–º—ã CRISPR-Cas9 –º—É—Ç–∞–Ω—Ç–Ω—ã–µ —É—á–∞—Å—Ç–∫–∏ –≥–µ–Ω–∞ ¬´–≤—ã–±—Ä–æ—Å–∏–ª–∏¬ª\n",
      "–∏–∑ –º–†–ù–ö, –∞ –∏–∑ –∫–ª–µ—Ç–æ–∫ —Å ... > \n",
      "\n",
      "<title: –ü–æ—Ç—Ä–µ–±–∏—Ç–µ–ª—å—Å–∫–∏–µ –¥—Ä–æ–Ω—ã –ø–æ–ª—É—á–∞—Ç —Ä–∞–¥–∞—Ä—ã –¥–ª—è —É–∫–ª–æ–Ω–µ–Ω–∏—è –æ—Ç —Å—Ç–æ–ª–∫–Ω–æ–≤–µ–Ω–∏–π\n",
      "text: –ê–º–µ—Ä–∏–∫–∞–Ω—Å–∫–∏–µ –∫–æ–º–ø–∞–Ω–∏–∏ Aurora Flight Sciences –∏ Socionext –∑–∞–Ω—è–ª–∏—Å—å —Å–æ–≤–º–µ—Å—Ç–Ω–æ–π —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–æ–π —Ä–∞–¥–∞—Ä–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã —É–∫–ª–æ–Ω–µ–Ω–∏—è –æ—Ç —Å—Ç–æ–ª–∫–Ω–æ–≤–µ–Ω–∏–π –¥–ª—è –Ω–µ–±–æ–ª—å—à–∏—Ö –ø–æ—Ç—Ä–µ–±–∏—Ç–µ–ª—å—Å–∫–∏—Ö –¥—Ä–æ–Ω–æ–≤. –°–æ–≥–ª–∞—Å–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏—é Aurora Flig... > \n",
      "\n",
      "<title: Amazon –∑–∞–ø–∞—Ç–µ–Ω—Ç–æ–≤–∞–ª–∞ —Å–ª–µ–¥—è—â–∏–π –∑–∞ —Ä—É–∫–∞–º–∏ —Ä–∞–±–æ—Ç–Ω–∏–∫–æ–≤ –±—Ä–∞—Å–ª–µ—Ç\n",
      "text: –ö–æ–º–ø–∞–Ω–∏—è Amazon –∑–∞–ø–∞—Ç–µ–Ω—Ç–æ–≤–∞–ª–∞ –Ω–∞—Ä—É—á–Ω—ã–π –±—Ä–∞—Å–ª–µ—Ç, –∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ—Ç –æ—Ç—Å–ª–µ–∂–∏–≤–∞—Ç—å –ø–æ–ª–æ–∂–µ–Ω–∏–µ —Ä—É–∫ —Ä–∞–±–æ—Ç–Ω–∏–∫–æ–≤ —Å–∫–ª–∞–¥–∞ –∏ –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä–æ–≤–∞—Ç—å –∏—Ö –¥–µ–π—Å—Ç–≤–∏—è. –ï—Å–ª–∏ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫ –Ω–∞—á–Ω–µ—Ç –∫–ª–∞—Å—Ç—å —Ç–æ–≤–∞—Ä –≤ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä, —Ç–∞–∫... > \n",
      "\n",
      "<title: SpaceX –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–ª–∞ –ø–æ—Å–∞–¥–∫—É –ø–µ—Ä–≤–æ–π —Å—Ç—É–ø–µ–Ω–∏ Falcon 9 –Ω–∞ —Ç—Ä–µ—Ö –¥–≤–∏–≥–∞—Ç–µ–ª—è—Ö\n",
      "text: SpaceX –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–ª–∞ —Ä–µ–∂–∏–º –ø–æ—Å–∞–¥–∫–∏ –ø–µ—Ä–≤–æ–π —Å—Ç—É–ø–µ–Ω–∏ —Ä–∞–∫–µ—Ç—ã Falcon 9 —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Ç—Ä–µ—Ö –¥–≤–∏–≥–∞—Ç–µ–ª–µ–π, —Å–æ–æ–±—â–∏–ª –ò–ª–æ–Ω –ú–∞—Å–∫ –≤ —Ç–≤–∏—Ç—Ç–µ—Ä–µ. –ü–æ—Å–∫–æ–ª—å–∫—É –ø–æ—Å–∞–¥–∫–∞ –±—ã–ª–∞ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω–æ–π, —Å—Ç—É–ø–µ–Ω—å –Ω–µ —Å–∞–∂–∞–ª–∏ –Ω–∞ –ø–ª–∞—Ç—Ñ–æ... > \n",
      "\n",
      "<title: –ê–º–µ—Ä–∏–∫–∞–Ω—Å–∫–∏–π —Ñ–ª–æ—Ç –ø–æ–ª—É—á–∏–ª —Ä–æ–±–æ—Ç–∞ ‚Äî –æ—Ö–æ—Ç–Ω–∏–∫–∞ –∑–∞ –ø–æ–¥–ª–æ–¥–∫–∞–º–∏\n",
      "text: –ê–≥–µ–Ω—Ç—Å—Ç–≤–æ –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–Ω—ã—Ö –æ–±–æ—Ä–æ–Ω–Ω—ã—Ö —Ä–∞–∑—Ä–∞–±–æ—Ç–æ–∫ (DARPA) –º–∏–Ω–∏—Å—Ç–µ—Ä—Å—Ç–≤–∞ –æ–±–æ—Ä–æ–Ω—ã –°–®–ê –∑–∞–≤–µ—Ä—à–∏–ª–æ —Å–≤–æ—é —á–∞—Å—Ç—å –ø—Ä–æ–µ–∫—Ç–∞ ACTUV –ø–æ —Å–æ–∑–¥–∞–Ω–∏—é –ø–æ–ª–Ω–æ—Å—Ç—å—é –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–≥–æ –Ω–∞–¥–≤–æ–¥–Ω–æ–≥–æ —Ä–æ–±–æ—Ç–∞, –ø—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω–Ω–æ–≥–æ –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –∏... > \n",
      "\n"
     ]
    }
   ],
   "source": [
    "n1=GetNPlus1()\n",
    "n1.loadArticles(\"data/nplus1_test.txt\")\n",
    "# –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç __len__()\n",
    "#len(n1)\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∫ —Ä–∞–±–æ—Ç–∞—é—Ç —Å—Ä–µ–∑—ã.\n",
    "#len(n1[1:5])\n",
    "#type(n1[1:5])\n",
    "#n1[1].title\n",
    "\n",
    "# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—â–∏–π –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä.\n",
    "#n2=GetNPlus1(n1)\n",
    "#n2.articles[0].title, n1.articles[0].title\n",
    "\n",
    "# –í—ã–¥–∞—á–∞ —Å–≤–æ–π—Å—Ç–≤, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç —É –æ–±—ä–µ–∫—Ç–∞ - —Å–ø–æ—Ä–Ω–∞—è –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∞—è –∑–Ω–∞—á–∏–º–æ—Å—Ç—å –∏ –æ—á–µ–≤–∏–¥–Ω–æ—Å—Ç—å –∫–æ–¥–∞.\n",
    "#n1.A, n1.b\n",
    "\n",
    "# –†–∞–±–æ—Ç–∞ —Å @property\n",
    "#print(n1.morph)\n",
    "#print(n1.__morph)\n",
    "\n",
    "# –û–ø–µ—Ä–∞—Ç–æ—Ä—ã —Å–¥–≤–∏–≥–∞ –∏ —Å–ª–æ–∂–µ–Ω–∏—è –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤.\n",
    "#n1<<n1[0]\n",
    "#n1+=n1[0]\n",
    "#n1<<1\n",
    "#print(\"\", n1.A, \"\\n\", n1[-1].title)\n",
    "\n",
    "# \"–õ–µ–≤–æ–µ\" —Å–ª–æ–∂–µ–Ω–∏–µ –ø—Ä–æ—Ç–∏–≤ \"–ø—Ä–∞–≤–æ–≥–æ\".\n",
    "#n2=n1+n1[0]\n",
    "#n2=n1[0]+n1\n",
    "#print(\"\", n2.A, \"\\n\", n2[-1].title)\n",
    "\n",
    "# –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∫ —Å—Ç—Ä–æ–∫–µ.\n",
    "#print(n1)\n",
    "\n",
    "# \"–í—ã–∑–æ–≤\" —Ñ—É–Ω–∫—Ü–∏–∏ –∫–∞–∫ –æ–±—ä–µ–∫—Ç–∞.\n",
    "#n1()\n",
    "\n",
    "# –¢–µ—Å—Ç–∏—Ä—É–µ–º __str__()\n",
    "#print(n1.getArticle(\"https://nplus1.ru/news/2019/02/20/deep-sqeak\"))\n",
    "# –¢–µ—Å—Ç–∏—Ä—É–µ–º __repr__()\n",
    "#n1[0]\n",
    "\n",
    "# –¢–µ—Å—Ç–∏—Ä—É–µ–º –∫–æ–ª–ª–µ–∫—Ü–∏—é —Å—Ç–∞—Ç–µ–π –∫–∞–∫ –∏—Ç–µ—Ä–∏—Ä—É–µ–º—ã–π –æ–±—ä–µ–∫—Ç.\n",
    "for art in n1[2:10]:\n",
    "    print(art, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –°–Ω–æ–≤–∞ –æ–± –∏—Å–∫–ª—é—á–∏—Ç–µ–ª—å–Ω—ã—Ö —Å–∏—Ç—É–∞—Ü–∏—è—Ö\n",
    "\n",
    "–ö—Å—Ç–∞—Ç–∏, –º–æ–∂–Ω–æ —Å–æ–∑–¥–∞–≤–∞—Ç—å —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–µ –∫–ª–∞—Å—Å—ã –∏—Å–∫–ª—é—á–∏—Ç–µ–ª—å–Ω—ã—Ö —Å–∏—Ç—É–∞—Ü–∏–π. –û–Ω–∏ –¥–æ–ª–∂–Ω—ã –Ω–∞—Å–ª–µ–¥–æ–≤–∞—Ç—å—Å—è –æ—Ç `Exception`. –¢–æ –µ—Å—Ç—å –ø–æ-—Ö–æ—Ä–æ—à–µ–º—É, `try ... except ...` —Ä–∞–±–æ—Ç–∞–µ—Ç —Ç–æ–ª—å–∫–æ —Å –Ω–∞—Å–ª–µ–¥–Ω–∏–∫–∞–º–∏ —ç—Ç–æ–≥–æ –∫–ª–∞—Å—Å–∞, –∞ –æ–Ω, –≤ —Å–≤–æ—é –æ—á–µ—Ä–µ–¥—å, –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –∏–º –µ–¥–∏–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ü—Ä–∏–Ω—Ü–∏–ø—ã SOLID –ø—Ä–∏ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ –ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ–≥–æ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è\n",
    "\n",
    "> –ï—Å–ª–∏ –≤—ã –æ–±–Ω–∞—Ä—É–∂–∏–ª–∏, —á—Ç–æ –≤ –±–ª–æ–∫–µ –∫–æ–¥–∞, –∫–æ—Ç–æ—Ä—ã–π –≤—ã —Ö–æ—Ç–∏—Ç–µ –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å, –º–Ω–æ–≥–æ –ø–æ–±–æ—á–Ω—ã—Ö —ç—Ñ—Ñ–µ–∫—Ç–æ–≤, –∑–Ω–∞—á–∏—Ç –≤—ã –Ω–∞—Ä—É—à–∞–µ—Ç–µ <a href=\"https://ru.wikipedia.org/wiki/%D0%9F%D1%80%D0%B8%D0%BD%D1%86%D0%B8%D0%BF_%D0%B5%D0%B4%D0%B8%D0%BD%D1%81%D1%82%D0%B2%D0%B5%D0%BD%D0%BD%D0%BE%D0%B9_%D0%BE%D1%82%D0%B2%D0%B5%D1%82%D1%81%D1%82%D0%B2%D0%B5%D0%BD%D0%BD%D0%BE%D1%81%D1%82%D0%B8\">–ü—Ä–∏–Ω—Ü–∏–ø –ï–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω–æ–π –û—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏</a>. –ù–∞—Ä—É—à–µ–Ω–∏–µ –ø—Ä–∏–Ω—Ü–∏–ø–∞ –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω–æ–π –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏ –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç –∫–æ–¥–∞ –¥–µ–ª–∞–µ—Ç —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –≤–µ—â–µ–π –∏ —Ç—Ä–µ–±—É–µ—Ç —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥–∞. –°–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø—Ä–∏–Ω—Ü–∏–ø—É –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω–æ–π –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏ ‚Äî –æ—Ç–ª–∏—á–Ω—ã–π —Å–ø–æ—Å–æ–± –ø—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∫–æ–¥–∞, –¥–ª—è –∫–æ—Ç–æ—Ä–æ–≥–æ –Ω–µ —Å–æ—Å—Ç–∞–≤–∏—Ç —Ç—Ä—É–¥–∞ –ø–∏—Å–∞—Ç—å –ø—Ä–æ—Å—Ç—ã–µ –ø–æ–≤—Ç–æ—Ä—è–µ–º—ã–µ –º–æ–¥—É–ª—å–Ω—ã–µ —Ç–µ—Å—Ç—ã, –∏, –≤ –∫–æ–Ω–µ—á–Ω–æ–º —Å—á–µ—Ç–µ, —Å–æ–∑–¥–∞–Ω–∏—è –Ω–∞–¥–µ–∂–Ω—ã—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π.  \n",
    "\n",
    "<div align=\"right\"><a href=\"https://habr.com/ru/company/otus/blog/433358/\">https://habr.com/ru/company/otus/blog/433358/</a></div>\n",
    "\n",
    "–ü—Ä–∏–Ω—Ü–∏–ø –µ–¥–∏–Ω–æ–π –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏ –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –∫ [–ø—Ä–∏–Ω—Ü–∏–ø–∞–º](https://habr.com/ru/post/446816/) [SOLID](https://habr.com/ru/company/ruvds/blog/426413/) ([–∏ –≤–æ—Ç –µ—â—ë](https://habr.com/ru/company/mailru/blog/412699/)), –ø–æ–º–æ–≥–∞—é—â–∏–º –ø–∏—Å–∞—Ç—å —Ö–æ—Ä–æ—à–∏–π –∫–æ–¥ –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–±—ä–µ–∫—Ç–Ω–æ-–æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –ø–∞—Ä–∞–¥–∏–≥–º—ã.\n",
    "\n",
    "![](img/lbzrqyibpifgxpgagwl44tgw7gu.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
